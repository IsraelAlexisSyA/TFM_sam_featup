{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Mask Path: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/cut/006_mask.png\n",
      "Cargando datos del coreset...\n",
      "Coreset cargado. Dimensión: torch.Size([10009, 384])\n",
      "NearestNeighbors finder inicializado.\n",
      "Cargando modelo DINOv2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imercatoma/FeatUp/featup/featurizers/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/imercatoma/FeatUp/featup/featurizers/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/imercatoma/FeatUp/featup/featurizers/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "Using cache found in /home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo DINOv2 cargado.\n",
      "Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\n",
      "Modelo SAM2 cargado.\n",
      "\n",
      "--- Procesando imagen: 006.png ---\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "Tiempo para calcular distancias KNN: 0.7916 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imercatoma/miniconda3/envs/sam2_featup_env/lib/python3.10/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas para la imagen de consulta: 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 030.png ---\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 232.png ---\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 127.png ---\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 18.7916 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/processed_masks/query_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Shape de masks_data_query_image: 1\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "\n",
      "Los plots de Mapas de Características de Objeto se guardarán en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/object_feature_map_plots\n",
      "\n",
      "Generando visualizaciones de Mapas de Características de Objeto para la consulta...\n",
      "\n",
      "Generando visualizaciones de Mapas de Características de Objeto para las imágenes similares...\n",
      "\n",
      "Generando visualizaciones de Mapas de Características de Objeto para los vecinos...\n",
      "\n",
      "Visualización de Mapas de Características de Objeto completada.\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.028469085693359\n",
      "Mínimo de fobj_q_pooled: 0.0\n",
      "Máximo de d_M_q: 0.17385010421276093\n",
      "Mínimo de d_M_q: 0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9167, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[9579.8350, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9194, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[9838.5176, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9177, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[9670.6543, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5209]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5209, 0.4791],\n",
      "        [0.4791, 0.5209]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5209, 0.4791, 1.0000],\n",
      "        [0.4791, 0.5209, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5209 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4791\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5242]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5242, 0.4758],\n",
      "        [0.4758, 0.5242]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5242, 0.4758, 1.0000],\n",
      "        [0.4758, 0.5242, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5242 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4758\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5221]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5221, 0.4779],\n",
      "        [0.4779, 0.5221]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5221, 0.4779, 1.0000],\n",
      "        [0.4779, 0.5221, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5221 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4779\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "\n",
      "--- Calculando Matching Score Maps (Valores RAW de Mahalanobis) ---\n",
      "✅ Objeto de consulta 0 emparejado con 3 referencias. Max RAW=197.7937, Min RAW=0.0000\n",
      "Rango global de Mahalanobis RAW para 'Matched': Min=0.0000, Max=197.7937\n",
      "matched_maha_range_global recibidos: (0.0, 197.79373168945312)\n",
      "\n",
      "--- Calculando Unmatched Score Maps (Valores RAW de Mahalanobis) ---\n",
      "✅ Objeto de consulta 0 ya emparejado. Unmatched map puesto a cero y saltado.\n",
      "\n",
      "--- Construyendo el Global Matched Anomaly Map (RAW Mahalanobis) ---\n",
      "Dimensiones del Global Matched Anomaly Map (RAW Mahalanobis) final: torch.Size([1024, 1024])\n",
      "✅ Visualización del Global Matched Anomaly Map (RAW Mahalanobis) guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/global_matched_anomaly_raw.png\n",
      "\n",
      "--- Construyendo el Global Unmatched Anomaly Map (RAW Mahalanobis) ---\n",
      "Dimensiones del Global Unmatched Anomaly Map (RAW Mahalanobis) final: torch.Size([1024, 1024])\n",
      "✅ Visualización del Global Unmatched Anomaly Map (RAW Mahalanobis) guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/global_unmatched_anomaly_raw.png\n",
      "\n",
      "--- Proceso de combinación de mapas RAW completado. ---\n",
      "\n",
      "--- Construyendo el Global Total Anomaly Map (Sum of RAW Mahalanobis) ---\n",
      "Dimensiones del Global Total Anomaly Map (Sum of RAW Mahalanobis) final: torch.Size([1024, 1024])\n",
      "✅ Visualización del Global Total Anomaly Map (Sum of RAW Mahalanobis) guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/global_total_anomaly_raw.png\n",
      "\n",
      "--- Superponiendo el mapa de anomalía final sobre la imagen original ---\n",
      "✅ Visualización superpuesta guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/global_matched_overlay_raw.png\n",
      "\n",
      "--- Superponiendo el mapa de anomalía final sobre la imagen original ---\n",
      "✅ Visualización superpuesta guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/global_unmatched_overlay_raw.png\n",
      "\n",
      "--- Superponiendo el mapa de anomalía final sobre la imagen original ---\n",
      "✅ Visualización superpuesta guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/global_total_anomaly_overlay_raw.png\n",
      "\n",
      "--- Proceso de generación y visualización de todos los mapas globales completado. ---\n",
      "Revisa la carpeta '/home/imercatoma/FeatUp/plots_final_eval/cut/cut_006' para las visualizaciones.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "\n",
    "# FeatUp utilities\n",
    "from featup.util import norm, unnorm\n",
    "from featup.plotting import plot_feats\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Anomaly region detection and visualization\n",
    "from skimage import measure\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# SAM2 imports\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import cv2\n",
    "\n",
    "# PCA for manual visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Configuración ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224  # DINOv2 input size\n",
    "BACKBONE_PATCH_SIZE = 14  # DINOv2 ViT-S/14 patch size\n",
    "use_norm = True\n",
    "\n",
    "H_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "W_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "\n",
    "# Directorios\n",
    "TRAIN_GOOD_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/train/good'\n",
    "PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/plots_final_eval/cut/cut_006'\n",
    "# --- Imagen de Consulta ---\n",
    "query_image_path = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/cut/006.png'\n",
    "# IMPORTANT: You'll need the ground truth mask for pixel-level evaluation\n",
    "# Assuming the ground truth mask follows MVTec AD dataset structure:\n",
    "# 'test/cut/006.png' -> 'ground_truth/cut/006_mask.png'\n",
    "gt_mask_path = query_image_path.replace('test', 'ground_truth').replace('.png', '_mask.png')\n",
    "print(f\"Ground Truth Mask Path: {gt_mask_path}\")\n",
    "\n",
    "\n",
    "os.makedirs(PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "HEATMAPS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'individual_heatmaps')\n",
    "os.makedirs(HEATMAPS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "ANOMALY_REGIONS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'detected_anomaly_regions')\n",
    "os.makedirs(ANOMALY_REGIONS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "FEATUP_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'featup_feature_plots')\n",
    "os.makedirs(FEATUP_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Coreset file paths\n",
    "core_bank_filenames_file = os.path.join(TRAIN_GOOD_DIR, 'core_bank_filenames.pt')\n",
    "coreset_relevant_flat_features_bank_file = os.path.join(TRAIN_GOOD_DIR, 'coreset_relevant_flat_features_bank.pt')\n",
    "template_features_bank_coreset_file = os.path.join(TRAIN_GOOD_DIR, 'template_features_bank_coreset.pt')\n",
    "\n",
    "# --- Cargar Datos del Coreset ---\n",
    "print(\"Cargando datos del coreset...\")\n",
    "try:\n",
    "    coreset_relevant_filenames = torch.load(core_bank_filenames_file)\n",
    "    coreset_relevant_flat_features_bank = torch.load(coreset_relevant_flat_features_bank_file).to(device)\n",
    "    coreset_features = torch.load(template_features_bank_coreset_file).to(device)\n",
    "    print(f\"Coreset cargado. Dimensión: {coreset_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar archivos del coreset: {e}. Asegúrate de que la Etapa 1 se ejecutó.\")\n",
    "    exit()\n",
    "\n",
    "# Mover coreset a CPU para sklearn's NearestNeighbors\n",
    "coreset_features_cpu = coreset_features.cpu().numpy()\n",
    "# se calcula la distancia coseno == 1 - similitud coseno [0,1] 0 identico, 1 completamente diferente\n",
    "nn_finder = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='cosine').fit(coreset_features_cpu)\n",
    "print(\"NearestNeighbors finder inicializado.\")\n",
    "\n",
    "# --- Cargar Modelo DINOv2 ---\n",
    "print(\"Cargando modelo DINOv2...\")\n",
    "featup_local_path = \"/home/imercatoma/FeatUp\"\n",
    "upsampler = torch.hub.load(featup_local_path, 'dinov2', use_norm=use_norm, source='local').to(device)\n",
    "\n",
    "dinov2_model = upsampler.model\n",
    "dinov2_model.eval()\n",
    "print(\"Modelo DINOv2 cargado.\")\n",
    "\n",
    "# --- Transformación de Imagen ---\n",
    "transform = T.Compose([\n",
    "    T.Resize(input_size),\n",
    "    T.CenterCrop((input_size, input_size)),\n",
    "    T.ToTensor(),\n",
    "    norm\n",
    "])\n",
    "\n",
    "# --- Carga del Modelo SAM2 ---\n",
    "print(f\"Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\")\n",
    "checkpoint = \"/home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt\"\n",
    "model_cfg_name = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_model = build_sam2(model_cfg_name, checkpoint, device=device, apply_postprocessing=True)\n",
    "sam2_model.eval()\n",
    "print(\"Modelo SAM2 cargado.\")\n",
    "\n",
    "base_image_name = os.path.basename(query_image_path)\n",
    "print(f\"\\n--- Procesando imagen: {base_image_name} ---\")\n",
    "\n",
    "query_img_pil = Image.open(query_image_path).convert(\"RGB\")\n",
    "input_tensor = transform(query_img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    features_lr = dinov2_model(input_tensor)\n",
    "\n",
    "query_lr_features = features_lr\n",
    "\n",
    "# --- Función para buscar imágenes similares usando KNN ---\n",
    "def buscar_imagenes_similares_knn(query_feature_map, pre_flattened_features_bank, k=3, nombres_archivos=None):\n",
    "    query_feat_flatten = query_feature_map.flatten().cpu().numpy()\n",
    "    features_bank_for_knn = pre_flattened_features_bank.cpu().numpy() if isinstance(pre_flattened_features_bank, torch.Tensor) else pre_flattened_features_bank\n",
    "\n",
    "    start_time_knn_dist = time.time()\n",
    "    distances = euclidean_distances([query_feat_flatten], features_bank_for_knn)\n",
    "    nearest_indices = np.argsort(distances[0])[:k]\n",
    "    end_time_knn_dist = time.time()\n",
    "    print(f\"Tiempo para calcular distancias KNN: {end_time_knn_dist - start_time_knn_dist:.4f} segundos\")\n",
    "\n",
    "    imagenes_similares = []\n",
    "    rutas_imagenes_similares = []\n",
    "    if nombres_archivos:\n",
    "        for idx in nearest_indices:\n",
    "            imagenes_similares.append(nombres_archivos[idx])\n",
    "            rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, nombres_archivos[idx]))\n",
    "    else: # Fallback if no filenames provided (less common for this use case)\n",
    "        for idx in nearest_indices:\n",
    "            imagenes_similares.append(f\"Imagen_Banco_{idx:03d}.png\")\n",
    "            rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, f\"Imagen_Banco_{idx:03d}.png\"))\n",
    "    return imagenes_similares, rutas_imagenes_similares, end_time_knn_dist\n",
    "\n",
    "# --- Búsqueda KNN ---\n",
    "print(\"\\nBuscando imágenes similares usando el banco pre-aplanado del Coreset...\")\n",
    "imagenes_similares, rutas_imagenes_similares, time_knn_dist = buscar_imagenes_similares_knn(\n",
    "    query_lr_features, coreset_relevant_flat_features_bank, nombres_archivos=coreset_relevant_filenames\n",
    ")\n",
    "\n",
    "# --- Aplicar FeatUp para obtener características de alta resolución ---\n",
    "def apply_featup_hr(image_path, featup_upsampler, image_transform, device):\n",
    "    image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = image_transform(image_pil).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        lr_feats = featup_upsampler.model(image_tensor)\n",
    "        hr_feats = featup_upsampler(image_tensor)\n",
    "    return lr_feats.cpu(), hr_feats.cpu()\n",
    "\n",
    "# Características de la imagen de consulta\n",
    "input_query_tensor_original = transform(Image.open(query_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "query_lr_feats_featup, query_hr_feats = apply_featup_hr(query_image_path, upsampler, transform, device)\n",
    "\n",
    "# Características de las imágenes similares\n",
    "similar_hr_feats_list = []\n",
    "for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "    input_similar_tensor_original = transform(Image.open(similar_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    similar_lr_feats, similar_hr_feats = apply_featup_hr(similar_image_path, upsampler, transform, device)\n",
    "    similar_hr_feats_list.append(similar_hr_feats)\n",
    "\n",
    "################################\n",
    "### Aplicando Máscaras SAM query y similares\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders=True):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image_alpha = np.zeros((h, w, 4), dtype=np.float32)\n",
    "    mask_image_alpha[mask > 0] = color\n",
    "    if borders:\n",
    "        mask_uint8 = mask.astype(np.uint8) * 255\n",
    "        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        contour_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=2)\n",
    "        contour_mask = (contour_image.astype(np.float32) / 255.0).sum(axis=-1) > 0\n",
    "        mask_image_alpha[contour_mask > 0, :3] = 1.0\n",
    "        mask_image_alpha[contour_mask > 0, 3] = 0.5\n",
    "    ax.imshow(mask_image_alpha)\n",
    "\n",
    "def process_masks_with_hierarchy(image, masks, output_dir, filename_prefix, overlap_threshold=0.8):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    final_processed_masks_data = [] \n",
    "    original_mask_segments_for_comparison = [mask_data[\"segmentation\"] for mask_data in masks]\n",
    "\n",
    "    print(f\"Procesando jerárquicamente {len(masks)} máscaras...\")\n",
    "\n",
    "    for i, mask_data_a_original in enumerate(masks): \n",
    "        mask_data_a_processed = mask_data_a_original.copy() \n",
    "        mask_a_current_processing = np.copy(mask_data_a_original[\"segmentation\"]) \n",
    "\n",
    "        is_completely_internal_to_another = False \n",
    "        potential_holes_for_mask_a = [] \n",
    "\n",
    "        for j, mask_data_b_comparison in enumerate(masks): \n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            mask_b = original_mask_segments_for_comparison[j] \n",
    "\n",
    "            if np.sum(mask_a_current_processing) > 0 and np.all(np.logical_and(mask_a_current_processing, mask_b) == mask_a_current_processing):\n",
    "                is_completely_internal_to_another = True\n",
    "                break \n",
    "\n",
    "            intersection_ab = np.logical_and(mask_b, mask_a_current_processing)\n",
    "            area_b = np.sum(mask_b)\n",
    "            area_intersection_ab = np.sum(intersection_ab)\n",
    "\n",
    "            if area_b > 0 and (np.all(intersection_ab == mask_b) or \\\n",
    "                               (area_intersection_ab / area_b > overlap_threshold and area_intersection_ab > 0)):\n",
    "                if np.sum(mask_b) < np.sum(mask_a_current_processing) * 0.9: \n",
    "                    potential_holes_for_mask_a.append(mask_b)\n",
    "\n",
    "        if is_completely_internal_to_another:\n",
    "            display_title = f'Máscara {i + 1} (Interna - Sin cambios significativos)'\n",
    "        else:\n",
    "            hollowed = False\n",
    "            for hole_mask in potential_holes_for_mask_a:\n",
    "                mask_a_current_processing = np.logical_and(mask_a_current_processing, np.logical_not(hole_mask))\n",
    "                hollowed = True\n",
    "            \n",
    "            mask_data_a_processed[\"segmentation\"] = mask_a_current_processing \n",
    "            if hollowed:\n",
    "                display_title = f'Máscara {i + 1} (Externa - Hueca)'\n",
    "            else:\n",
    "                display_title = f'Máscara {i + 1} (Externa - Sin huecos significativos)'\n",
    "\n",
    "        final_processed_masks_data.append(mask_data_a_processed) \n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image) \n",
    "        show_mask(mask_data_a_processed[\"segmentation\"], plt.gca(), random_color=True) \n",
    "        plt.axis('off')\n",
    "        plt.title(display_title)\n",
    "        \n",
    "        output_path = os.path.join(output_dir, f\"{filename_prefix}_processed_mask_{i + 1}.png\")\n",
    "        plt.savefig(output_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Máscara procesada {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "    print(\"Procesamiento jerárquico de máscaras completado.\")\n",
    "    return final_processed_masks_data \n",
    "\n",
    "def apply_morphological_closing(masks_list, kernel_size=5):\n",
    "    if not masks_list:\n",
    "        return masks_list\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    print(f\"Aplicando cierre morfológico con kernel {kernel_size}x{kernel_size}...\")\n",
    "    for mask_data in masks_list:\n",
    "        mask_boolean = mask_data['segmentation']\n",
    "        mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "        mask_smoothed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_CLOSE, kernel)\n",
    "        mask_data['segmentation'] = (mask_smoothed_np > 0).astype(bool)\n",
    "    print(\"Suavizado de máscaras completado.\")\n",
    "    return masks_list\n",
    "\n",
    "def apply_morphological_opening(masks_list, kernel_size=5):\n",
    "    if not masks_list:\n",
    "        print(\"La lista de máscaras está vacía, no se aplica la apertura morfológica.\")\n",
    "        return masks_list\n",
    "    \n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    print(f\"Aplicando apertura morfológica con kernel {kernel_size}x{kernel_size}...\")\n",
    "    \n",
    "    for mask_data in masks_list:\n",
    "        mask_boolean = mask_data['segmentation']\n",
    "        if mask_boolean.dtype != bool:\n",
    "            mask_boolean = mask_boolean.astype(bool)\n",
    "\n",
    "        mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "        mask_processed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_OPEN, kernel)\n",
    "        mask_data['segmentation'] = (mask_processed_np > 0).astype(bool)\n",
    "        \n",
    "    print(\"Suavizado (apertura) de máscaras completado.\")\n",
    "    return masks_list\n",
    "\n",
    "try:\n",
    "    image_for_sam_np = np.array(Image.open(query_image_path).convert(\"RGB\"))\n",
    "    print(f\"Dimensiones imagen SAM: {image_for_sam_np.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error procesando imagen para SAM: {e}. Saltando SAM.\")\n",
    "    sam2_model = None\n",
    "    \n",
    "PROCESSED_MASKS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"processed_masks\")\n",
    "\n",
    "if sam2_model is not None:\n",
    "    points_grid_density = 8\n",
    "    min_mask_area_pixels =  80000.0\n",
    "    max_mask_area_pixels = 450000.0\n",
    "\n",
    "    mask_generator_query = SAM2AutomaticMaskGenerator(\n",
    "        model=sam2_model,\n",
    "        points_per_side=points_grid_density,\n",
    "        points_per_batch=256,\n",
    "        pred_iou_thresh=0.9,\n",
    "        stability_score_thresh=0.9,\n",
    "        crop_n_layers=0,\n",
    "        min_mask_region_area=min_mask_area_pixels,\n",
    "    )\n",
    "\n",
    "    print(f\"Generando máscaras para consulta con grid de {points_grid_density}x{points_grid_density} puntos...\")\n",
    "    masks_data_query_image = mask_generator_query.generate(image_for_sam_np)\n",
    "        \n",
    "    print(f\"Número de máscaras generadas para la imagen de consulta: {len(masks_data_query_image)}\")\n",
    "\n",
    "    mask_generator_similar = SAM2AutomaticMaskGenerator( \n",
    "        model=sam2_model,\n",
    "        points_per_side=points_grid_density,\n",
    "        points_per_batch=256,\n",
    "        pred_iou_thresh=0.9,\n",
    "        stability_score_thresh=0.9,\n",
    "        crop_n_layers=0,\n",
    "        min_mask_region_area=min_mask_area_pixels,\n",
    "    )\n",
    "\n",
    "    print(\"\\nGenerando máscaras SAM para imágenes similares...\")\n",
    "    similar_masks_raw_list = []\n",
    "    # Initialize start_time_sam here, outside the loop\n",
    "    start_time_sam = time.time()\n",
    "    for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "        try:\n",
    "            image_np_similar_for_sam = np.array(Image.open(similar_image_path).convert('RGB'))\n",
    "            print(f\"--- Procesando vecino {j+1}: {os.path.basename(similar_image_path)} ---\")\n",
    "            current_similar_masks_data = mask_generator_similar.generate(image_np_similar_for_sam)\n",
    "            processed_masks_similar = process_masks_with_hierarchy(image_np_similar_for_sam, current_similar_masks_data, PROCESSED_MASKS_DIR, f\"similar_{j+1}\")\n",
    "            similar_masks_raw_list.append(processed_masks_similar)\n",
    "            print(f\"Máscaras generadas para vecino {j+1}: {len(current_similar_masks_data)}.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando imagen similar {os.path.basename(similar_image_path)} para SAM: {e}\")\n",
    "\n",
    "    end_time_sam = time.time()\n",
    "    print(f\"Tiempo total de ejecución de SAM: {end_time_sam - start_time_sam:.4f} segundos.\")\n",
    "\n",
    "print(\"\\nAnálisis de detección de anomalías para una sola imagen completado.\")\n",
    "\n",
    "# Llamar a la función para procesar las máscaras de la query\n",
    "processed_masks_query = process_masks_with_hierarchy(image_for_sam_np, masks_data_query_image, PROCESSED_MASKS_DIR, \"query\")\n",
    "masks_data_query_image = processed_masks_query\n",
    "print(\"Shape de masks_data_query_image:\", len(masks_data_query_image))\n",
    "\n",
    "#####################\n",
    "\n",
    "# --- Implementación del punto 3.4.3. Object Feature Map ---\n",
    "def process_masks_to_object_feature_maps(raw_masks, hr_feature_map, target_h, target_w, sam_processed_image_shape):\n",
    "    if not raw_masks:\n",
    "        print(\"Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\")\n",
    "        C_dim = hr_feature_map.shape[0] if hr_feature_map.ndim >= 3 else 0\n",
    "        return torch.empty(0, C_dim, target_h, target_w, device=hr_feature_map.device), \\\n",
    "               torch.empty(0, 1, target_h, target_w, device=hr_feature_map.device)\n",
    "\n",
    "    object_feature_maps_list = []\n",
    "    scaled_mask_append = []\n",
    "    C_dim = hr_feature_map.shape[0] \n",
    "\n",
    "    for mask_info in raw_masks:\n",
    "        mask_np = mask_info['segmentation'].astype(np.float32)\n",
    "        mask_tensor_original_res = torch.from_numpy(mask_np).unsqueeze(0).unsqueeze(0) \n",
    "        mask_tensor_original_res = mask_tensor_original_res.to(hr_feature_map.device)\n",
    "\n",
    "        scaled_mask = F.interpolate(mask_tensor_original_res,\n",
    "                                     size=(target_h, target_w),\n",
    "                                     mode='bilinear',\n",
    "                                     align_corners=False)\n",
    "        scaled_mask = (scaled_mask > 0.5).float()\n",
    "        scaled_mask_append.append(scaled_mask)\n",
    "        \n",
    "        if hr_feature_map.ndim == 3:\n",
    "            hr_feature_map_with_batch = hr_feature_map.unsqueeze(0) \n",
    "        else: \n",
    "            hr_feature_map_with_batch = hr_feature_map\n",
    "\n",
    "        object_feature_map_i = scaled_mask * hr_feature_map_with_batch\n",
    "        object_feature_maps_list.append(object_feature_map_i)\n",
    "\n",
    "    final_object_feature_maps = torch.cat(object_feature_maps_list, dim=0) \n",
    "    final_scaled_masks = torch.cat(scaled_mask_append, dim=0)\n",
    "    \n",
    "    return final_object_feature_maps, final_scaled_masks\n",
    "\n",
    "# --- Visualización de Mapas de Características de Objeto ---\n",
    "def visualize_object_feature_map(original_image_path, sam_mask_info, hr_feature_map_tensor,\n",
    "                                   object_feature_map_tensor, target_h, target_w,\n",
    "                                   plot_save_dir, plot_filename_prefix, mask_idx,\n",
    "                                   sam_processed_image_shape):\n",
    "    try:\n",
    "        original_img = Image.open(original_image_path).convert(\"RGB\")\n",
    "        sam_mask_np = sam_mask_info['segmentation']\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        axes[0].imshow(original_img)\n",
    "        axes[0].set_title(f'Imagen Original\\n{os.path.basename(original_image_path)}')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        mask_display = sam_mask_np \n",
    "        axes[1].imshow(original_img) \n",
    "        show_mask(mask_display, axes[1], random_color=False, borders=True) \n",
    "        axes[1].set_title(f'Máscara SAM {mask_idx}')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        if object_feature_map_tensor.numel() == 0:\n",
    "            axes[2].text(0.5, 0.5, \"No hay características de objeto\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "            axes[2].set_title('Mapa de Características de Objeto (Vacío)')\n",
    "            axes[2].axis('off')\n",
    "        else:\n",
    "            ofm_cpu = object_feature_map_tensor.squeeze().cpu().numpy() \n",
    "            if ofm_cpu.ndim == 3: \n",
    "                C, H, W = ofm_cpu.shape\n",
    "                ofm_reshaped = ofm_cpu.transpose(1, 2, 0).reshape(-1, C) \n",
    "\n",
    "                if C > 3: \n",
    "                    pca = PCA(n_components=3)\n",
    "                    ofm_pca = pca.fit_transform(ofm_reshaped)\n",
    "                    ofm_pca_normalized = (ofm_pca - ofm_pca.min()) / (ofm_pca.max() - ofm_pca.min() + 1e-8)\n",
    "                    ofm_display = ofm_pca_normalized.reshape(H, W, 3)\n",
    "                    axes[2].imshow(ofm_display)\n",
    "                    axes[2].set_title(f'Mapa de Características de Objeto (PCA)\\nMáscara {mask_idx}')\n",
    "                else: \n",
    "                    if C == 1:\n",
    "                        ofm_display = ofm_cpu.squeeze()\n",
    "                        axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                    elif C == 3:\n",
    "                        ofm_display = ofm_cpu.transpose(1, 2, 0) \n",
    "                        ofm_display_norm = (ofm_display - ofm_display.min()) / (ofm_display.max() - ofm_display.min() + 1e-8)\n",
    "                        axes[2].imshow(ofm_display_norm)\n",
    "                    else: \n",
    "                        ofm_display = ofm_cpu[0]\n",
    "                        axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                    axes[2].set_title(f'Mapa de Características de Objeto\\nMáscara {mask_idx}')\n",
    "            else: \n",
    "                axes[2].text(0.5, 0.5, \"Formato de características de objeto inesperado\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                axes[2].set_title('Mapa de Características de Objeto (Error)')\n",
    "\n",
    "            axes[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(plot_save_dir, f\"{plot_filename_prefix}_mask_{mask_idx}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al visualizar el mapa de características de objeto para máscara {mask_idx} de {os.path.basename(original_image_path)}: {e}\")\n",
    "\n",
    "# --- Aplicar el proceso a la imagen de consulta y a las imágenes de referencia ---\n",
    "\n",
    "print(\"\\n--- Generando Mapas de Características de Objeto ---\")\n",
    "\n",
    "TARGET_MASK_H = 8 * H_prime \n",
    "TARGET_MASK_W = 8 * W_prime \n",
    "print(f\"TARGET_MASK_H: {TARGET_MASK_H}\")\n",
    "print(f\"TARGET_MASK_W: {TARGET_MASK_W}\")\n",
    "\n",
    "fobj_q, scaled_masks_query = process_masks_to_object_feature_maps(\n",
    "    masks_data_query_image,\n",
    "    query_hr_feats.squeeze(0), \n",
    "    TARGET_MASK_H,\n",
    "    TARGET_MASK_W,\n",
    "    image_for_sam_np.shape \n",
    ")\n",
    "\n",
    "fobj_q = fobj_q.to(device)\n",
    "\n",
    "print(f\"Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): {fobj_q.shape}\") \n",
    "\n",
    "all_fobj_r_list = [] \n",
    "for i, similar_hr_feats in enumerate(similar_hr_feats_list):\n",
    "    current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "    img_similar_pil = Image.open(rutas_imagenes_similares[i]).convert('RGB') \n",
    "    image_np_similar_for_sam_shape = np.array(img_similar_pil).shape\n",
    "\n",
    "    fobj_r_current, scaled_masks_similar = process_masks_to_object_feature_maps(\n",
    "        current_similar_masks_raw,\n",
    "        similar_hr_feats.squeeze(0), \n",
    "        TARGET_MASK_H,\n",
    "        TARGET_MASK_W,\n",
    "        image_np_similar_for_sam_shape \n",
    "    )\n",
    "    fobj_r_current = fobj_r_current.to(device)\n",
    "    \n",
    "    all_fobj_r_list.append(fobj_r_current)\n",
    "    print(f\"Dimensiones de fobj_r para vecino {i+1}: {fobj_r_current.shape}\") \n",
    "    print(\"\\nTipos de los elementos en all_fobj_r_list:\")\n",
    "    for idx, fobj_r in enumerate(all_fobj_r_list):\n",
    "        print(f\"Vecino {idx + 1}: Tipo de fobj_r:\", type(fobj_r))\n",
    "print(\"\\nProceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\")\n",
    "\n",
    "OFM_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"object_feature_map_plots\")\n",
    "os.makedirs(OFM_PLOTS_DIR, exist_ok=True)\n",
    "print(f\"\\nLos plots de Mapas de Características de Objeto se guardarán en: {OFM_PLOTS_DIR}\")\n",
    "\n",
    "print(\"\\nGenerando visualizaciones de Mapas de Características de Objeto para la consulta...\")\n",
    "for i, mask_info in enumerate(masks_data_query_image):\n",
    "    if i < fobj_q.shape[0]: \n",
    "        visualize_object_feature_map(\n",
    "            query_image_path,\n",
    "            mask_info,\n",
    "            query_hr_feats, \n",
    "            fobj_q[i].unsqueeze(0), \n",
    "            TARGET_MASK_H,\n",
    "            TARGET_MASK_W,\n",
    "            OFM_PLOTS_DIR,\n",
    "            f\"query_{base_image_name.replace('.png', '')}\",\n",
    "            i,\n",
    "            image_for_sam_np.shape\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontró OFM para la máscara de consulta {i}.\")\n",
    "\n",
    "print(\"\\nGenerando visualizaciones de Mapas de Características de Objeto para las imágenes similares...\")\n",
    "for i, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "    current_similar_masks = similar_masks_raw_list[i]\n",
    "    current_fobj_r = all_fobj_r_list[i]\n",
    "    current_similar_hr_feats = similar_hr_feats_list[i] \n",
    "    \n",
    "    img_similar_pil = Image.open(similar_image_path).convert('RGB')\n",
    "    image_np_similar_for_sam_shape = np.array(img_similar_pil).shape\n",
    "\n",
    "    for j, mask_info in enumerate(current_similar_masks):\n",
    "        if j < current_fobj_r.shape[0]:\n",
    "            visualize_object_feature_map(\n",
    "                similar_image_path,\n",
    "                mask_info,\n",
    "                current_similar_hr_feats, \n",
    "                current_fobj_r[j].unsqueeze(0), \n",
    "                TARGET_MASK_H,\n",
    "                TARGET_MASK_W,\n",
    "                OFM_PLOTS_DIR,\n",
    "                f\"similar_{os.path.basename(similar_image_path).replace('.png', '')}\",\n",
    "                j,\n",
    "                image_np_similar_for_sam_shape\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Advertencia: No se encontró OFM para la máscara {j} de la imagen similar {os.path.basename(similar_image_path)}.\")\n",
    "\n",
    "\n",
    "# Visualización para las imágenes de referencia (Ir)\n",
    "print(\"\\nGenerando visualizaciones de Mapas de Características de Objeto para los vecinos...\")\n",
    "for i, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "    current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "    current_similar_hr_feats = similar_hr_feats_list[i]\n",
    "    current_fobj_r = all_fobj_r_list[i]\n",
    "    img_similar_pil_for_shape = Image.open(similar_image_path).convert('RGB')\n",
    "    image_np_similar_for_sam_shape = np.array(img_similar_pil_for_shape).shape\n",
    "\n",
    "    if not current_fobj_r.numel() == 0: # Solo procesar si hay OFMs generados para este vecino\n",
    "        for j, mask_info in enumerate(current_similar_masks_raw):\n",
    "            if j < current_fobj_r.shape[0]: # Asegurarse de que tenemos un OFM para esta máscara\n",
    "                visualize_object_feature_map(\n",
    "                    similar_image_path,\n",
    "                    mask_info,\n",
    "                    current_similar_hr_feats,\n",
    "                    current_fobj_r[j].unsqueeze(0), # OFM de la máscara actual\n",
    "                    TARGET_MASK_H,\n",
    "                    TARGET_MASK_W,\n",
    "                    OFM_PLOTS_DIR,\n",
    "                    f\"neighbor_{i+1}_{os.path.basename(similar_image_path).replace('.png', '')}\",\n",
    "                    j,\n",
    "                    image_np_similar_for_sam_shape\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Advertencia: No se encontró OFM para la máscara {j} del vecino {i+1}.\")\n",
    "    else:\n",
    "        print(f\"No se generaron OFMs para el vecino {i+1} ({os.path.basename(similar_image_path)}), saltando visualización.\")\n",
    "\n",
    "print(\"\\nVisualización de Mapas de Características de Objeto completada.\")\n",
    "\n",
    "\n",
    "\n",
    "# -----------3.5.2 Object matching module-----------------\n",
    "## Matching\n",
    "# --- Definición de la función show_anomalies_on_image ---\n",
    "def show_anomalies_on_image(image_np, masks, anomalous_info, alpha=0.5, save_path=None):\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_np)\n",
    "\n",
    "    for obj_id, similarity in anomalous_info: # Iterate through (id, similarity) tuples\n",
    "        # Extraer la máscara binaria real\n",
    "        mask = masks[obj_id]['segmentation']\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.cpu().numpy()\n",
    "\n",
    "        # Crear máscara en rojo\n",
    "        colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "        colored_mask[mask > 0] = [255, 0, 0]\n",
    "        plt.imshow(colored_mask, alpha=alpha)\n",
    "\n",
    "        # Calcular centroide para colocar el texto\n",
    "        ys, xs = np.where(mask > 0)\n",
    "        if len(xs) > 0 and len(ys) > 0:\n",
    "            cx = int(xs.mean())\n",
    "            cy = int(ys.mean())\n",
    "            \n",
    "            # Create text with index and percentage\n",
    "            text_label = f\"{obj_id} ({similarity*100:.2f}%)\"\n",
    "            plt.text(cx, cy, text_label, color='white', fontsize=10, fontweight='bold', ha='center', va='center',\n",
    "                     bbox=dict(facecolor='red', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "    plt.title(\"Objetos Anómalos en Rojo con Índice y Similitud\") # Updated title for clarity\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Plot de anomalías guardado en: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "# --- Fin de la definición de la función show_anomalies_on_image ---\n",
    "# --- Nuevas funciones de ploteo para la matriz P y P_augmented_full ---\n",
    "def plot_assignment_matrix(P_matrix, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación P\"):\n",
    "    \"\"\"\n",
    "    Visualiza la matriz de asignación P como un mapa de calor.\n",
    "\n",
    "    Args:\n",
    "        P_matrix (torch.Tensor or np.array): La matriz de asignación (M x N).\n",
    "        query_labels (list): Etiquetas para los objetos de consulta (eje Y).\n",
    "        reference_labels (list): Etiquetas para los objetos de referencia (eje X).\n",
    "        save_path (str, optional): Ruta para guardar la imagen del plot.\n",
    "        title (str): Título del plot.\n",
    "    \"\"\"\n",
    "    if isinstance(P_matrix, torch.Tensor):\n",
    "        #P_matrix = P_matrix.cpu().numpy()\n",
    "        P_matrix = P_matrix.detach().cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(P_matrix.shape[1] * 0.8 + 2, P_matrix.shape[0] * 0.8 + 2))\n",
    "    plt.imshow(P_matrix, cmap='viridis', origin='upper', aspect='auto')\n",
    "    plt.colorbar(label='Probabilidad de Asignación')\n",
    "    plt.xticks(np.arange(len(reference_labels)), reference_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(np.arange(len(query_labels)), query_labels)\n",
    "    plt.xlabel('Objetos de Referencia')\n",
    "    plt.ylabel('Objetos de Consulta')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Plot de la matriz de asignación guardado en: {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_augmented_assignment_matrix(P_augmented_full, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación Aumentada (con Trash Bin)\"):\n",
    "    \"\"\"\n",
    "    Visualiza la matriz de asignación aumentada (incluyendo los trash bins) como un mapa de calor.\n",
    "\n",
    "    Args:\n",
    "        P_augmented_full (torch.Tensor or np.array): La matriz de asignación aumentada ((M+1) x (N+1)).\n",
    "        query_labels (list): Etiquetas para los objetos de consulta.\n",
    "        reference_labels (list): Etiquetas para los objetos de referencia.\n",
    "        save_path (str, optional): Ruta para guardar la imagen del plot.\n",
    "        title (str): Título del plot.\n",
    "    \"\"\"\n",
    "    if isinstance(P_augmented_full, torch.Tensor):\n",
    "        #P_augmented_full = P_augmented_full.cpu().numpy()\n",
    "        P_augmented_full = P_augmented_full.detach().cpu().numpy()\n",
    "\n",
    "    # Añadir etiquetas para los trash bins\n",
    "    full_query_labels = [f\"Q_{i}\" for i in query_labels] + [\"Trash Bin (Q)\"]\n",
    "    full_reference_labels = [f\"R_{i}\" for i in reference_labels] + [\"Trash Bin (R)\"]\n",
    "\n",
    "    plt.figure(figsize=(P_augmented_full.shape[1] * 0.8 + 2, P_augmented_full.shape[0] * 0.8 + 2))\n",
    "    plt.imshow(P_augmented_full, cmap='viridis', origin='upper', aspect='auto')\n",
    "    plt.colorbar(label='Probabilidad de Asignación')\n",
    "    plt.xticks(np.arange(len(full_reference_labels)), full_reference_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(np.arange(len(full_query_labels)), full_query_labels)\n",
    "    plt.xlabel('Objetos de Referencia y Trash Bin')\n",
    "    plt.ylabel('Objetos de Consulta y Trash Bin')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Plot de la matriz de asignación aumentada guardado en: {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# --- Fin de las nuevas funciones de ploteo ---\n",
    "\n",
    "## Matching-continue---\n",
    "## Matching\n",
    "start_time_sam_matching = time.time()\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def apply_global_max_pool(feat_map):\n",
    "    return F.adaptive_max_pool2d(feat_map, output_size=1).squeeze(-1).squeeze(-1)\n",
    "\n",
    "class SimpleObjectMatchingModule(nn.Module):\n",
    "    def __init__(self, sinkhorn_iterations=100, sinkhorn_epsilon=0.1, bin_score_value=0.5):\n",
    "        super(SimpleObjectMatchingModule, self).__init__()\n",
    "        self.sinkhorn_iterations = sinkhorn_iterations\n",
    "        self.sinkhorn_epsilon = sinkhorn_epsilon\n",
    "        self.z = nn.Parameter(torch.tensor(bin_score_value, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, d_M_q, d_N_r):\n",
    "        M = d_M_q.shape[0]\n",
    "        N = d_N_r.shape[0]\n",
    "\n",
    "        if M == 0 or N == 0:\n",
    "            return torch.empty(M, N, device=d_M_q.device), \\\n",
    "                   torch.empty(M+1, N+1, device=d_M_q.device)\n",
    "\n",
    "        score_matrix = torch.mm(d_M_q, d_N_r.T)\n",
    "        #print(\"score_matrix (antes de Sinkhorn):\\n\", score_matrix)\n",
    "\n",
    "        S_augmented = torch.zeros((M + 1, N + 1), device=d_M_q.device, dtype=d_M_q.dtype)\n",
    "        S_augmented[:M, :N] = score_matrix\n",
    "        S_augmented[:M, N] = self.z\n",
    "        S_augmented[M, :N] = self.z\n",
    "        S_augmented[M, N] = self.z\n",
    "        print(\"S_augmented antes de Sinkhorn:\\n\", S_augmented)\n",
    "\n",
    "        K = torch.exp(S_augmented / self.sinkhorn_epsilon)\n",
    "        print(\"K (antes de Sinkhorn):\\n\", K)\n",
    "        \n",
    "\n",
    "        for i in range(self.sinkhorn_iterations):\n",
    "            K = K / K.sum(dim=1, keepdim=True)\n",
    "            K = K / K.sum(dim=0, keepdim=True)\n",
    "            #print(f\"Iteración {i+1}: K.shape = {K}\")\n",
    "\n",
    "        P_augmented_full = K\n",
    "        P = P_augmented_full[:M, :N]\n",
    "\n",
    "        return P, P_augmented_full\n",
    "\n",
    "fobj_q_pooled = apply_global_max_pool(fobj_q)\n",
    "print(\"Shape de fobj_q_pooled:\", fobj_q_pooled.shape)\n",
    "print(\"Máximo de fobj_q_pooled:\", torch.max(fobj_q_pooled).item())\n",
    "print(\"Mínimo de fobj_q_pooled:\", torch.min(fobj_q_pooled).item())\n",
    "\n",
    "all_fobj_r_pooled_list = []\n",
    "for fobj_r_current in all_fobj_r_list:\n",
    "    pooled_r = apply_global_max_pool(fobj_r_current)\n",
    "    all_fobj_r_pooled_list.append(pooled_r)\n",
    "    \n",
    "d_M_q = F.normalize(fobj_q_pooled, p=2, dim=1) #shape (M, C)\n",
    "d_N_r_list = [F.normalize(fobj_r_pooled, p=2, dim=1) \n",
    "                              for fobj_r_pooled in all_fobj_r_pooled_list]\n",
    "print(\"Máximo de d_M_q:\", torch.max(d_M_q).item())\n",
    "print(\"Mínimo de d_M_q:\", torch.min(d_M_q).item())\n",
    "\n",
    "object_matching_module = SimpleObjectMatchingModule(\n",
    "    sinkhorn_iterations=100,\n",
    "    sinkhorn_epsilon=0.1,\n",
    "    bin_score_value=0.9 #2.36\n",
    ").to(device)\n",
    "\n",
    "P_matrices = []\n",
    "P_augmented_full_matrices = []\n",
    "\n",
    "for i, d_N_r_current_image in enumerate(d_N_r_list):\n",
    "    d_M_q_cuda = d_M_q.to(device)\n",
    "    d_N_r_current_image_cuda = d_N_r_current_image.to(device)\n",
    "\n",
    "    P_current, P_augmented_current = object_matching_module(d_M_q_cuda, d_N_r_current_image_cuda)\n",
    "    P_matrices.append(P_current)\n",
    "    P_augmented_full_matrices.append(P_augmented_current)\n",
    "\n",
    "\n",
    "print(\"\\n--- Matrices P y P_augmented_full generadas ---\")\n",
    "# --- NUEVOS DICCIONARIOS CONSOLIDADOS ---\n",
    "# Almacenarán para cada query_idx, las referencias que le corresponden de TODOS los vecinos.\n",
    "M = d_M_q.shape[0]\n",
    "all_matched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)} # M es el número de objetos de consulta (Iq)\n",
    "all_closest_unmatched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)}\n",
    "# Imprimir shapes de los diccionarios consolidados\n",
    "#//////\n",
    "print(\"\\n--- Resultados Consolidados ---\")\n",
    "print(\"all_matched_ref_indices_by_query_obj:\")\n",
    "for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Objeto de Consulta {q_idx}: {matches}\")\n",
    "\n",
    "print(\"\\nall_closest_unmatched_ref_indices_by_query_obj:\")\n",
    "for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Objeto de Consulta {q_idx}: {closest_unmatches}\")\n",
    "#/////////////////\n",
    "# Procesar matrices P y P_augmented_full para obtener índices\n",
    "for i, (P, P_augmented_full) in enumerate(zip(P_matrices, P_augmented_full_matrices)):\n",
    "    current_neighbor_key = f\"Vecino_{i+1}\"\n",
    "    N_current = P.shape[1] \n",
    "\n",
    "    print(f\"\\n--- Vecino {current_neighbor_key} ---\")\n",
    "    print(f\"Matriz P (MxN) para el vecino {current_neighbor_key}:\")\n",
    "    print(P)\n",
    "    print(f\"Matriz P_augmented_full (M+1 x N+1) para el vecino {current_neighbor_key}:\")\n",
    "    print(P_augmented_full)\n",
    "\n",
    "    # Imprimir sumas de filas y columnas de P_augmented_full\n",
    "    augmented_with_totals = torch.cat([\n",
    "        torch.cat([P_augmented_full, P_augmented_full.sum(dim=0, keepdim=True)], dim=0),\n",
    "        torch.cat([P_augmented_full.sum(dim=1, keepdim=True), P_augmented_full.sum().unsqueeze(0).unsqueeze(0)], dim=0)\n",
    "    ], dim=1)\n",
    "    print(f\"Matriz P_augmented_full con totales (M+2 x N+2):\\n{augmented_with_totals}\")\n",
    "\n",
    "    print(f\"\\n--- Decisiones de Emparejamiento para el Vecino {current_neighbor_key} ---\")\n",
    "    for obj_idx in range(P.shape[0]):\n",
    "        \n",
    "        # Obtener la probabilidad más alta dentro de P y su índice\n",
    "        if N_current > 0:\n",
    "            max_prob_P = P[obj_idx].max().item()\n",
    "            max_idx_P = P[obj_idx].argmax().item()\n",
    "        else:\n",
    "            max_prob_P = -float('inf')\n",
    "            max_idx_P = -1\n",
    "\n",
    "\n",
    "        trash_bin_prob = P_augmented_full[obj_idx, -1].item() \n",
    "\n",
    "        print(f\"   Objeto de Consulta {obj_idx}:\")\n",
    "        print(f\"     Probabilidad máxima en P: {max_prob_P:.4f} en el índice {max_idx_P}\")\n",
    "        print(f\"     Probabilidad en el 'Trash Bin': {trash_bin_prob:.4f}\")\n",
    "\n",
    "\n",
    "       # Decisión y almacenamiento en los diccionarios consolidados\n",
    "        if trash_bin_prob > max_prob_P:\n",
    "            # Desemparejado: ahora añadimos el 'primer máximo' a la lista de ese objeto de consulta\n",
    "            if max_idx_P != -1: # Solo añadir si hay un 'primer máximo' válido\n",
    "                all_closest_unmatched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "            print(f\"     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto {max_idx_P}\")\n",
    "        else:\n",
    "            # Emparejado: añadir el emparejamiento real a la lista de ese objeto de consulta\n",
    "            all_matched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "            print(f\"     Decisión: EMPAREJADO con objeto de imagen {max_idx_P}\")\n",
    "\n",
    "\n",
    "# --- Resultados Finales Consolidados ---\n",
    "print(\"\\n--- Resultados Finales Consolidados (Índices) ---\")\n",
    "print(\"all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\")\n",
    "for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Query {q_idx}: {matches}\")\n",
    "\n",
    "print(\"\\nall_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\")\n",
    "for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Query {q_idx}: {closest_unmatches}\")\n",
    "\n",
    "\n",
    "# --- AHORA SE NECESITAN ESTOS DICTIONARIOS PARA TU IMPLEMENTACIÓN DE MAHALANOBIS ---\n",
    "\n",
    "print(\"--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\")\n",
    "# ***************************************************************************************************\n",
    "\n",
    "\n",
    "# %%## AMM (Anomaly Map Module) - Tus funciones de Mahalanobis\n",
    "@torch.no_grad()\n",
    "def compute_mahalanobis_map_single(query_fmap, ref_fmaps, regularization=1e-5):\n",
    "    \"\"\"\n",
    "    Calcula el mapa de distancia de Mahalanobis por píxel entre un objeto de consulta\n",
    "    y k objetos de referencia emparejados.\n",
    "    Args:\n",
    "        query_fmap (Tensor): (C, H, W) feature map del objeto de consulta.\n",
    "        ref_fmaps (List[Tensor]): lista de k tensores (C, H, W) de objetos emparejados.\n",
    "        regularization (float): término epsilon * I para la inversa numéricamente estable.\n",
    "    Returns:\n",
    "        maha_map (Tensor): (H, W) mapa escalar con distancia de Mahalanobis por píxel.\n",
    "    \"\"\"\n",
    "    device = query_fmap.device\n",
    "    k = len(ref_fmaps)\n",
    "    C, H, W = query_fmap.shape\n",
    "    \n",
    "    if k < 2: # Necesitamos al menos 2 referencias para calcular covarianza\n",
    "        return torch.zeros(H, W, device=device)\n",
    "\n",
    "    # Stack: (k, C, H, W)\n",
    "    ref_stack = torch.stack(ref_fmaps, dim=0)  # (k, C, H, W)\n",
    "\n",
    "    maha_map = torch.zeros(H, W, device=device)\n",
    "\n",
    "    for x in range(H):\n",
    "        for y in range(W):\n",
    "            vectors = ref_stack[:, :, x, y]          # (k, C)\n",
    "            mu = vectors.mean(dim=0)                 # (C,)\n",
    "            delta = vectors - mu                     # (k, C)\n",
    "            cov = delta.T @ delta / (k - 1)          # (C, C) \n",
    "            cov += regularization * torch.eye(C, device=device)\n",
    "\n",
    "            try:\n",
    "                cov_inv = torch.linalg.inv(cov)      # (C, C)\n",
    "            except RuntimeError:\n",
    "                maha_map[x, y] = 0.0\n",
    "                continue\n",
    "\n",
    "            v_query = query_fmap[:, x, y]            # (C,)\n",
    "            diff = (v_query - mu).unsqueeze(0)       # (1, C)\n",
    "\n",
    "            # Mahalanobis distance squared\n",
    "            maha_val_squared = (diff @ cov_inv @ diff.T).item()\n",
    "            # Aplicar la raíz cuadrada para obtener la distancia\n",
    "            maha_val = torch.sqrt(torch.tensor(maha_val_squared, device=device)).item() # Asegurarse de que sea un tensor para sqrt\n",
    "            maha_map[x, y] = maha_val\n",
    "\n",
    "    return maha_map\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_matching_score_map(\n",
    "    fobj_q,\n",
    "    all_matched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list,\n",
    "    regularization=1e-5,\n",
    "    plot_save_dir=None):\n",
    "    \"\"\"\n",
    "    Calcula los mapas de distancia de Mahalanobis para objetos de consulta\n",
    "    que tienen referencias emparejadas. Devuelve los valores RAW de Mahalanobis.\n",
    "    \"\"\"\n",
    "    matching_maha_maps = []\n",
    "    all_raw_maha_values = [] \n",
    "    print(\"\\n--- Calculando Matching Score Maps (Valores RAW de Mahalanobis) ---\")\n",
    "\n",
    "    for query_idx in range(len(fobj_q)):\n",
    "        query_fmap = fobj_q[query_idx] # (C, H, W)\n",
    "\n",
    "        matched_ref_fmaps_list = []\n",
    "        for neighbor_idx, ref_idx in all_matched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "            ref_fmap = all_fobj_r_list[neighbor_idx][ref_idx] # (C, H, W)\n",
    "            matched_ref_fmaps_list.append(ref_fmap)\n",
    "\n",
    "        if len(matched_ref_fmaps_list) >= 2:\n",
    "            maha_map_raw = compute_mahalanobis_map_single(\n",
    "                query_fmap=query_fmap,\n",
    "                ref_fmaps=matched_ref_fmaps_list,\n",
    "                regularization=regularization\n",
    "            )\n",
    "            \n",
    "            # Agrega los valores brutos a la lista global para min/max\n",
    "            all_raw_maha_values.append(maha_map_raw.flatten().cpu()) \n",
    "            \n",
    "            print(f\"✅ Objeto de consulta {query_idx} emparejado con {len(matched_ref_fmaps_list)} referencias. Max RAW={maha_map_raw.max().item():.4f}, Min RAW={maha_map_raw.min().item():.4f}\")\n",
    "            matching_maha_maps.append(maha_map_raw.cpu()) # Devuelve el mapa RAW\n",
    "        else:\n",
    "            # Si no hay suficientes pares coincidentes, el mapa es cero\n",
    "            print(f\"ℹ️ Objeto de consulta {query_idx} NO tiene suficientes referencias emparejadas para un Matching Score.\")\n",
    "            matching_maha_maps.append(torch.zeros_like(query_fmap[0]).cpu())\n",
    "        \n",
    "        # Visualización (opcional) - Se normaliza solo para la visualización si hay valores.\n",
    "        if plot_save_dir:\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            maha_map_for_plot = matching_maha_maps[-1]\n",
    "            if maha_map_for_plot.max() > 1e-8: # Evitar división por cero para mapas planos\n",
    "                plot_normalized_maha = (maha_map_for_plot - maha_map_for_plot.min()) / (maha_map_for_plot.max() - maha_map_for_plot.min() + 1e-8)\n",
    "            else:\n",
    "                plot_normalized_maha = torch.zeros_like(maha_map_for_plot)\n",
    "            plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "            plt.title(f\"Matching Score Map (Normalized for Plot) - Obj {query_idx}\") # Cambia el título\n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\") # Cambia la etiqueta de la barra de color\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"matching_score_raw_obj_{query_idx}.png\")\n",
    "            plt.savefig(save_path) # Descomentar para guardar plots\n",
    "            plt.close()\n",
    "\n",
    "    # Calcular el min y max global de TODOS los valores brutos recolectados\n",
    "    global_min_maha = 0.0\n",
    "    global_max_maha = 1.0 # Valores por defecto si no hay ningún matched válido\n",
    "\n",
    "    if all_raw_maha_values:\n",
    "        combined_raw_values = torch.cat(all_raw_maha_values)\n",
    "        global_min_maha = combined_raw_values.min().item()\n",
    "        global_max_maha = combined_raw_values.max().item()\n",
    "        # Asegurar que el rango no sea cero para evitar división por cero más tarde\n",
    "        if global_max_maha <= global_min_maha:\n",
    "            global_max_maha = global_min_maha + 1e-8 \n",
    "\n",
    "    print(f\"Rango global de Mahalanobis RAW para 'Matched': Min={global_min_maha:.4f}, Max={global_max_maha:.4f}\")\n",
    "\n",
    "    return matching_maha_maps, (global_min_maha, global_max_maha) # Devolvemos la tupla con min/max\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_unmatched_score_map(\n",
    "    fobj_q,\n",
    "    all_closest_unmatched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list,\n",
    "    regularization=1e-5,\n",
    "    plot_save_dir=None,\n",
    "    all_matched_ref_indices_by_query_obj=None,\n",
    "    # --- RECIBE LA TUPLA CON MIN/MAX (YA NO SE USA PARA NORMALIZAR INTERNAMENTE) ---\n",
    "    matched_maha_range_global=(0.0, 1.0) ):\n",
    "    \"\"\"\n",
    "    Calcula los mapas de distancia de Mahalanobis para objetos de consulta\n",
    "    que NO tienen referencias emparejadas. Devuelve los valores RAW de Mahalanobis.\n",
    "    \"\"\"\n",
    "    print(f\"matched_maha_range_global recibidos: {matched_maha_range_global}\") # Se sigue recibiendo, pero no se usa para normalizar\n",
    "\n",
    "    unmatched_maha_maps = []\n",
    "    print(\"\\n--- Calculando Unmatched Score Maps (Valores RAW de Mahalanobis) ---\")\n",
    "\n",
    "    # min_matched_maha_global, max_matched_maha_global = matched_maha_range_global # Ya no se necesitan para normalizar aquí.\n",
    "\n",
    "    for query_idx in range(len(fobj_q)):\n",
    "        query_fmap = fobj_q[query_idx] \n",
    "\n",
    "        matched_refs = all_matched_ref_indices_by_query_obj.get(query_idx, []) if all_matched_ref_indices_by_query_obj else []\n",
    "        \n",
    "        if len(matched_refs) >= 2: \n",
    "            unmatched_maha_maps.append(torch.zeros_like(query_fmap[0]).cpu())\n",
    "            print(f\"✅ Objeto de consulta {query_idx} ya emparejado. Unmatched map puesto a cero y saltado.\")\n",
    "            continue \n",
    "\n",
    "        closest_ref_fmaps = []\n",
    "        for neighbor_idx, ref_idx in all_closest_unmatched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "            ref_fmap_closest = all_fobj_r_list[neighbor_idx][ref_idx] \n",
    "            closest_ref_fmaps.append(ref_fmap_closest)\n",
    "\n",
    "        if len(closest_ref_fmaps) >= 2:\n",
    "            maha_map_raw = compute_mahalanobis_map_single( # Obtén el mapa de Mahalanobis bruto\n",
    "                query_fmap=query_fmap,\n",
    "                ref_fmaps=closest_ref_fmaps,\n",
    "                regularization=regularization\n",
    "            )\n",
    "            \n",
    "            # --- Lógica Clave: ¡NO NORMALIZAR AQUÍ! DEVOLVER RAW ---\n",
    "            # Si el objetivo es Mahalanobis RAW para UNMATCHED, se devuelve directamente\n",
    "            maha_map_to_return = maha_map_raw\n",
    "\n",
    "            print(f\"🟡 Objeto de consulta {query_idx} NO emparejado, Mahalanobis RAW con {len(closest_ref_fmaps)} 'casi-pares'. Max RAW={maha_map_to_return.max().item():.4f}, Min RAW={maha_map_to_return.min().item():.4f}\")\n",
    "        else:\n",
    "            maha_map_to_return = torch.zeros_like(query_fmap[0])\n",
    "            print(f\"⚠️ Objeto de consulta {query_idx} no emparejado y sin suficientes 'casi-pares', se pone mapa vacío.\")\n",
    "        \n",
    "        unmatched_maha_maps.append(maha_map_to_return.cpu()) \n",
    "\n",
    "        # Visualización (opcional) - Normalizar solo para la visualización si hay valores\n",
    "        if plot_save_dir:\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            maha_map_for_plot = unmatched_maha_maps[-1]\n",
    "            if maha_map_for_plot.max() > 1e-8:\n",
    "                plot_normalized_maha = (maha_map_for_plot - maha_map_for_plot.min()) / (maha_map_for_plot.max() - maha_map_for_plot.min() + 1e-8)\n",
    "            else:\n",
    "                plot_normalized_maha = torch.zeros_like(maha_map_for_plot)\n",
    "            plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "            plt.title(f\"Unmatched Anomaly Map (Normalized for Plot) - Obj {query_idx}\") # Cambia el título\n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"unmatched_anomaly_raw_obj_{query_idx}.png\")\n",
    "            plt.savefig(save_path) # Descomentar para guardar plots\n",
    "            plt.close()\n",
    "\n",
    "    return unmatched_maha_maps\n",
    "\n",
    "@torch.no_grad()\n",
    "def build_aggregated_score_map(individual_score_maps_list, final_size=(1024, 1024), title_prefix=\"Global Score Map\", plot_save_dir=None, filename_prefix=\"global_score_map\"):\n",
    "    \"\"\"\n",
    "    Construye un mapa de puntuación agregado (global) a partir de una lista de mapas individuales.\n",
    "    Args:\n",
    "        individual_score_maps_list (List[Tensor]): Lista de tensores (H', W') de mapas de puntuación individuales.                         Estos ya deberían estar en CPU.\n",
    "        final_size (tuple): Tamaño final deseado para el mapa agregado (H, W).\n",
    "        title_prefix (str): Prefijo para el título del gráfico.\n",
    "        plot_save_dir (str, optional): Directorio para guardar las visualizaciones.\n",
    "        filename_prefix (str): Prefijo para el nombre del archivo guardado.\n",
    "    Returns:\n",
    "        Tensor: Tensor (H, W) con el mapa de calor total de puntuación.\n",
    "    \"\"\"\n",
    "    H_out, W_out = final_size\n",
    "    aggregated_score_map = torch.zeros((H_out, W_out), device='cpu')\n",
    "\n",
    "    print(f\"\\n--- Construyendo el {title_prefix} ---\")\n",
    "    if not individual_score_maps_list:\n",
    "        print(f\"No hay mapas individuales para {title_prefix}. Retornando un mapa vacío.\")\n",
    "        return aggregated_score_map\n",
    "\n",
    "    for i, score_map in enumerate(individual_score_maps_list):\n",
    "        if score_map.dim() == 2:\n",
    "            score_map_tensor = score_map.unsqueeze(0).unsqueeze(0) # (1,1,H',W')\n",
    "        else:\n",
    "            print(f\"Advertencia: El mapa de puntuación {i} tiene dimensiones inesperadas: {score_map.shape}. Saltando.\")\n",
    "            continue\n",
    "\n",
    "        score_resized = F.interpolate(\n",
    "            score_map_tensor,\n",
    "            size=(H_out, W_out),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        ).squeeze()\n",
    "\n",
    "        aggregated_score_map += score_resized\n",
    "\n",
    "    print(f\"Dimensiones del {title_prefix} final: {aggregated_score_map.shape}\")\n",
    "\n",
    "    if plot_save_dir:\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        # Para el mapa agregado, también se normaliza solo para la visualización\n",
    "        map_for_plot = aggregated_score_map\n",
    "        if map_for_plot.max() > 1e-8:\n",
    "            plot_normalized_map = (map_for_plot - map_for_plot.min()) / (map_for_plot.max() - map_for_plot.min() + 1e-8)\n",
    "        else:\n",
    "            plot_normalized_map = torch.zeros_like(map_for_plot)\n",
    "\n",
    "        plt.imshow(plot_normalized_map.numpy(), cmap=\"hot\")\n",
    "        plt.title(title_prefix + \" (Normalized for Plot)\") # Ajusta el título para reflejar la normalización de visualización\n",
    "        plt.axis(\"off\")\n",
    "        plt.colorbar(label=\"Score Acumulado (Normalized for display)\")\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(plot_save_dir, f\"{filename_prefix}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"✅ Visualización del {title_prefix} guardada en: {save_path}\")\n",
    "\n",
    "    return aggregated_score_map\n",
    "\n",
    "def overlay_anomaly_map_on_image(image_rgb_path, anomaly_map, alpha=0.7, cmap='magma', plot_save_dir=None, filename_suffix=\"overlay\"):\n",
    "    \"\"\"\n",
    "    Superpone el mapa de anomalía sobre la imagen original RGB como un heatmap.\n",
    "    Args:\n",
    "        image_rgb_path (str): Ruta a la imagen original RGB.\n",
    "        anomaly_map (Tensor o ndarray): mapa de anomalía (H, W) — debe estar reescalado a 1024×1024.\n",
    "        alpha (float): transparencia del mapa (0=solo imagen, 1=solo heatmap)\n",
    "        cmap (str): mapa de color matplotlib a usar (\"hot\", \"jet\", etc.)\n",
    "        plot_save_dir (str, optional): Directorio para guardar la visualización.\n",
    "        filename_suffix (str): Sufijo para el nombre del archivo guardado.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Superponiendo el mapa de anomalía final sobre la imagen original ---\")\n",
    "    try:\n",
    "        image_original_loaded = Image.open(image_rgb_path).convert(\"RGB\")\n",
    "        image_np = np.array(image_original_loaded)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró la imagen en {image_rgb_path}. No se puede superponer.\")\n",
    "        return\n",
    "\n",
    "    if isinstance(anomaly_map, torch.Tensor):\n",
    "        anomaly_np = anomaly_map.cpu().numpy()\n",
    "    else:\n",
    "        anomaly_np = anomaly_map\n",
    "\n",
    "    # Normalizamos el mapa a [0, 1] PARA LA VISUALIZACIÓN\n",
    "    # Añadimos un pequeño epsilon para evitar división por cero si max == min\n",
    "    anomaly_min = anomaly_np.min()\n",
    "    anomaly_max = anomaly_np.max()\n",
    "    if (anomaly_max - anomaly_min) < 1e-8: # Si todos los valores son iguales\n",
    "        anomaly_norm = np.zeros_like(anomaly_np)\n",
    "    else:\n",
    "        anomaly_norm = (anomaly_np - anomaly_min) / (anomaly_max - anomaly_min)\n",
    "\n",
    "    # Redimensionamos si las resoluciones no coinciden con la imagen original\n",
    "    if anomaly_norm.shape[:2] != image_np.shape[:2]:\n",
    "        anomaly_norm = np.array(Image.fromarray(anomaly_norm).resize(\n",
    "            (image_np.shape[1], image_np.shape[0]), resample=Image.BILINEAR\n",
    "        ))\n",
    "\n",
    "    # Visualización\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image_np)\n",
    "    plt.imshow(anomaly_norm, cmap=cmap, alpha=alpha)\n",
    "    plt.title(\"Anomaly Heatmap Overlay (Normalized for Display)\") # Ajusta el título\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if plot_save_dir:\n",
    "        save_path = os.path.join(plot_save_dir, f\"{filename_suffix}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Visualización superpuesta guardada en: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# --- 1. Calcular Matching Score Maps y obtener el rango global ---\n",
    "all_matching_score_maps, matched_maha_range_global = compute_matching_score_map(\n",
    "    fobj_q=fobj_q,\n",
    "    all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list=all_fobj_r_list,\n",
    "    regularization=1e-2,\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR)\n",
    "# matched_maha_range_global ahora es una tupla (min_value, max_value)\n",
    "# --- 2. Calcular Unmatched Score Maps (ya no normaliza con el rango global, devuelve RAW) ---\n",
    "all_unmatched_score_maps = compute_unmatched_score_map(\n",
    "    fobj_q=fobj_q,\n",
    "    all_closest_unmatched_ref_indices_by_query_obj=all_closest_unmatched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list=all_fobj_r_list,\n",
    "    regularization=1e-2,\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "    matched_maha_range_global=matched_maha_range_global # Se sigue pasando, pero no se usa para normalización interna en compute_unmatched_score_map\n",
    ")\n",
    "\n",
    "# 3. Construir el Global Matched Score Map\n",
    "# Obtener las dimensiones de la imagen original\n",
    "image_original = Image.open(query_image_path)\n",
    "H, W = image_original.size\n",
    "\n",
    "# Construir el Global Matched Score Map\n",
    "global_matched_score_map = build_aggregated_score_map(\n",
    "    individual_score_maps_list=all_matching_score_maps,\n",
    "    final_size=(H, W),\n",
    "    title_prefix=\"Global Matched Anomaly Map (RAW Mahalanobis)\", # Ajusta el título\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_prefix=\"global_matched_anomaly_raw\")\n",
    "\n",
    "# 4. Construir el Global Unmatched Score Map\n",
    "global_unmatched_score_map = build_aggregated_score_map(\n",
    "    individual_score_maps_list=all_unmatched_score_maps,\n",
    "    final_size=(H, W),\n",
    "    title_prefix=\"Global Unmatched Anomaly Map (RAW Mahalanobis)\", # Ajusta el título\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_prefix=\"global_unmatched_anomaly_raw\")\n",
    "\n",
    "# 5. Combinar ambos tipos de mapas individuales para el Mapa Global Final (Total)\n",
    "combined_individual_score_maps = []\n",
    "num_queries = len(fobj_q)\n",
    "for i in range(num_queries):\n",
    "    matched_map_for_query = all_matching_score_maps[i] if i < len(all_matching_score_maps) else torch.zeros((H, W), device='cpu')\n",
    "    unmatched_map_for_query = all_unmatched_score_maps[i] if i < len(all_unmatched_score_maps) else torch.zeros((H, W), device='cpu')\n",
    "    \n",
    "    combined_map_for_query_i = matched_map_for_query + unmatched_map_for_query\n",
    "    combined_individual_score_maps.append(combined_map_for_query_i)\n",
    "print(\"\\n--- Proceso de combinación de mapas RAW completado. ---\")\n",
    "\n",
    "# 6. Construir el Global Total Anomaly Score Map (el que combina ambos)\n",
    "# Este será el 'score_map' que usaremos para la evaluación\n",
    "global_total_anomaly_score_map = build_aggregated_score_map(\n",
    "    individual_score_maps_list=combined_individual_score_maps,\n",
    "    final_size=(H, W), # Usar las dimensiones originales de la imagen para la evaluación\n",
    "    title_prefix=\"Global Total Anomaly Map (Sum of RAW Mahalanobis)\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_prefix=\"global_total_anomaly_raw\")\n",
    "\n",
    "# 7. Superponer los mapas globales en la imagen original\n",
    "# NOTA: La función overlay_anomaly_map_on_image SIEMPRE normalizará para la visualización.\n",
    "overlay_anomaly_map_on_image(\n",
    "    image_rgb_path=query_image_path,\n",
    "    anomaly_map=global_matched_score_map,\n",
    "    alpha=0.7,\n",
    "    cmap=\"magma\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_suffix=\"global_matched_overlay_raw\")\n",
    "\n",
    "overlay_anomaly_map_on_image(\n",
    "    image_rgb_path=query_image_path,\n",
    "    anomaly_map=global_unmatched_score_map,\n",
    "    alpha=0.7,\n",
    "    cmap=\"magma\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_suffix=\"global_unmatched_overlay_raw\")\n",
    "\n",
    "overlay_anomaly_map_on_image(\n",
    "    image_rgb_path=query_image_path,\n",
    "    anomaly_map=global_total_anomaly_score_map,\n",
    "    alpha=0.7,\n",
    "    cmap=\"magma\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_suffix=\"global_total_anomaly_overlay_raw\")\n",
    "\n",
    "print(\"\\n--- Proceso de generación y visualización de todos los mapas globales completado. ---\")\n",
    "print(f\"Revisa la carpeta '{PLOT_SAVE_ROOT_DIR}' para las visualizaciones.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Máscara Ground Truth cargada desde: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/cut/006_mask.png con dimensiones (1024, 1024)\n",
      "Shape de la imagen de consulta: (1024, 1024)\n",
      "Valor máximo: 196.89837646484375\n",
      "Valor mínimo: 0.0\n",
      "1 percentil arriba: 126\n",
      "10 percentil abajo: 0.0\n",
      "\n",
      "Aplicando umbral de 126 al mapa de puntuación de anomalías RAW...\n",
      "Filtrando componentes conectados menores de 2000 píxeles...\n",
      "Máscara de anomalías predicha después del umbral y filtrado: (1024, 1024)\n",
      "Máscara de anomalías predicha guardada en: /home/imercatoma/FeatUp/plots_final_eval/cut/cut_006/detected_anomaly_regions/predicted_anomaly_mask_006.png\n",
      "\n",
      "Calculando métricas de evaluación a nivel de píxel...\n",
      "TP (True Positives): 6699\n",
      "FP (False Positives): 13890\n",
      "TN (True Negatives): 1023954\n",
      "FN (False Negatives): 4033\n",
      "Precision: 0.3254\n",
      "Accuracy: 0.9829\n",
      "Sensitivity (Recall): 0.6242\n",
      "Specificity: 0.9866\n",
      "F1-Score: 0.4278\n",
      "\n",
      "Realizando clasificación a nivel de imagen...\n",
      "Imagen GT Anómala: True\n",
      "Imagen Predicha Anómala: True\n",
      "Image-level TP: 1, FP: 0, TN: 0, FN: 0\n",
      "La imagen 006.png se clasifica como: ANÓMALA\n"
     ]
    }
   ],
   "source": [
    "### **Evaluación de Detección de Anomalías (Pixel-level y Image-level)**\n",
    "\n",
    "##Ahora que tienes tu `global_total_anomaly_score_map` (que es tu `score_map` principal para la anomalía), podemos aplicar los pasos de evaluación que mencionaste.\n",
    "\n",
    "# --- 1. Load Ground Truth Mask ---\n",
    "def load_ground_truth_mask(mask_path, target_size):\n",
    "    try:\n",
    "        gt_mask_pil = Image.open(mask_path).convert('L') # Convert to grayscale\n",
    "        gt_mask_resized = gt_mask_pil.resize(target_size, Image.NEAREST) # Resize using nearest neighbor to preserve binary\n",
    "        gt_mask_np = np.array(gt_mask_resized)\n",
    "        # MVTec masks are typically 0 (background) and 255 (anomaly)\n",
    "        gt_binary_mask = (gt_mask_np > 0).astype(np.uint8)\n",
    "        print(f\"Máscara Ground Truth cargada desde: {mask_path} con dimensiones {gt_binary_mask.shape}\")\n",
    "        return gt_binary_mask\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Máscara Ground Truth no encontrada en {mask_path}.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar la máscara Ground Truth: {e}\")\n",
    "        return None\n",
    "\n",
    "# Definir el tamaño objetivo para las máscaras de evaluación (el mismo que el mapa de anomalías)\n",
    "# H, W son las dimensiones originales de la imagen de consulta cargadas anteriormente.\n",
    "# Asegúrate de que `global_total_anomaly_score_map` también esté en estas dimensiones si no lo está ya.\n",
    "# (Tu build_aggregated_score_map ya lo hace para H, W de la imagen original)\n",
    "TARGET_EVAL_SIZE = (W, H) # (width, height) para resize de PIL\n",
    "\n",
    "ground_truth_mask = load_ground_truth_mask(gt_mask_path, TARGET_EVAL_SIZE) \n",
    "\n",
    "\n",
    "if ground_truth_mask is None:\n",
    "    print(\"No se pudo cargar la máscara Ground Truth. La evaluación a nivel de píxel y de imagen no se realizará.\")\n",
    "else:\n",
    "    # --- 2. Apply Threshold and Filter Connected Components ---\n",
    "    \n",
    "    # Define a threshold for anomaly score map (this is a critical hyperparameter)\n",
    "    # You might need to tune this based on your dataset and desired trade-off.\n",
    "    # Los valores de Mahalanobis pueden ser diferentes a las distancias de coseno,\n",
    "    # por lo que este umbral DEBE ser ajustado experimentalmente para tu dataset.\n",
    "    ANOMALY_SCORE_THRESHOLD = 100 # <--- ¡AJUSTAR ESTE UMBRAL! Valor de ejemplo.\n",
    "\n",
    "    # Define minimum pixel area for connected components\n",
    "    MIN_PIXEL_AREA_THRESHOLD = 1000 # Example: components smaller than 500 pixels will be removed\n",
    "                                   # Ajustar según el tamaño esperado de anomalías.\n",
    "\n",
    "    print(f\"Shape de la imagen de consulta: {query_img_pil.size}\")\n",
    "    # Binarize the anomaly score map (convertir a NumPy si es un tensor de PyTorch)\n",
    "    anomaly_map_np = global_total_anomaly_score_map.cpu().numpy()\n",
    "    max_value = anomaly_map_np.max()\n",
    "    min_value = anomaly_map_np.min()\n",
    "    ANOMALY_SCORE_THRESHOLD = int(np.percentile(anomaly_map_np, 98))\n",
    "    percentile_10_below = np.percentile(anomaly_map_np, 20)\n",
    "    print(f\"Valor máximo: {max_value}\")\n",
    "    print(f\"Valor mínimo: {min_value}\")\n",
    "    print(f\"1 percentil arriba: {ANOMALY_SCORE_THRESHOLD}\")\n",
    "    print(f\"10 percentil abajo: {percentile_10_below}\")\n",
    "    print(f\"\\nAplicando umbral de {ANOMALY_SCORE_THRESHOLD} al mapa de puntuación de anomalías RAW...\")\n",
    "    predicted_anomaly_mask_thresholded = (anomaly_map_np >= 125).astype(np.uint8)\n",
    "\n",
    "    print(f\"Filtrando componentes conectados menores de {MIN_PIXEL_AREA_THRESHOLD} píxeles...\")\n",
    "    # Find connected components\n",
    "    labels = measure.label(predicted_anomaly_mask_thresholded)\n",
    "    properties = measure.regionprops(labels)\n",
    "\n",
    "    filtered_predicted_mask = np.zeros_like(predicted_anomaly_mask_thresholded, dtype=np.uint8)\n",
    "    for prop in properties:\n",
    "        if prop.area >= MIN_PIXEL_AREA_THRESHOLD:\n",
    "            # Reconstruct the mask with only large enough components\n",
    "            filtered_predicted_mask[labels == prop.label] = 1\n",
    "\n",
    "    print(f\"Máscara de anomalías predicha después del umbral y filtrado: {filtered_predicted_mask.shape}\")\n",
    "\n",
    "    # --- Visualización de la Máscara de Anomalías Predicha ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(query_img_pil) # Original image background\n",
    "    # Overlay the predicted anomaly regions\n",
    "    # Use alpha to make it semi-transparent, and a distinct color like red\n",
    "    plt.imshow(filtered_predicted_mask, cmap='Blues', alpha=0.8 * filtered_predicted_mask, vmin=0, vmax=1)\n",
    "    plt.title(f'Regiones de Anomalía Predichas\\nUmbral: {ANOMALY_SCORE_THRESHOLD}, Área Mín: {MIN_PIXEL_AREA_THRESHOLD}')\n",
    "    plt.axis('off')\n",
    "    predicted_mask_output_path = os.path.join(ANOMALY_REGIONS_SAVE_DIR, f'predicted_anomaly_mask_{base_image_name}')\n",
    "    plt.savefig(predicted_mask_output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Máscara de anomalías predicha guardada en: {predicted_mask_output_path}\")\n",
    "\n",
    "    # --- 3. Pixel-Level TP, FP, TN, FN Calculation ---\n",
    "    print(\"\\nCalculando métricas de evaluación a nivel de píxel...\")\n",
    "\n",
    "    # Ensure masks are the same shape\n",
    "    if ground_truth_mask.shape != filtered_predicted_mask.shape:\n",
    "        print(f\"Error de dimensiones: GT Mask {ground_truth_mask.shape} vs Predicted Mask {filtered_predicted_mask.shape}\")\n",
    "        # Esto no debería pasar si TARGET_EVAL_SIZE se usa consistentemente.\n",
    "        print(\"Shapes mismatch. Evaluation might be inaccurate or skipped.\")\n",
    "    \n",
    "    # Flatten the masks for element-wise comparison\n",
    "    gt_flat = ground_truth_mask.flatten()\n",
    "    pred_flat = filtered_predicted_mask.flatten()\n",
    "\n",
    "    TP = np.sum((gt_flat == 1) & (pred_flat == 1))\n",
    "    FP = np.sum((gt_flat == 0) & (pred_flat == 1))\n",
    "    TN = np.sum((gt_flat == 0) & (pred_flat == 0))\n",
    "    FN = np.sum((gt_flat == 1) & (pred_flat == 0))\n",
    "\n",
    "    print(f\"TP (True Positives): {TP}\")\n",
    "    print(f\"FP (False Positives): {FP}\")\n",
    "    print(f\"TN (True Negatives): {TN}\")\n",
    "    print(f\"FN (False Negatives): {FN}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0 # Also known as Recall\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    f1_score = 2 * (sensitivity * (TP / (TP + FP))) / (sensitivity + (TP / (TP + FP))) if (sensitivity + (TP / (TP + FP))) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "    # --- (Optional) 4. Image-Level Classification and Evaluation ---\n",
    "    print(\"\\nRealizando clasificación a nivel de imagen...\")\n",
    "\n",
    "    # Image-level classification: If any anomaly pixels are detected, classify as anomalous.\n",
    "    is_image_anomalous_gt = np.sum(ground_truth_mask) > 0\n",
    "    is_image_anomalous_pred = np.sum(filtered_predicted_mask) > 0\n",
    "\n",
    "    image_level_TP = 0\n",
    "    image_level_FP = 0\n",
    "    image_level_TN = 0\n",
    "    image_level_FN = 0\n",
    "\n",
    "    if is_image_anomalous_gt and is_image_anomalous_pred:\n",
    "        image_level_TP = 1\n",
    "    elif not is_image_anomalous_gt and is_image_anomalous_pred:\n",
    "        image_level_FP = 1\n",
    "    elif not is_image_anomalous_gt and not is_image_anomalous_pred:\n",
    "        image_level_TN = 1\n",
    "    elif is_image_anomalous_gt and not is_image_anomalous_pred:\n",
    "        image_level_FN = 1\n",
    "    \n",
    "    print(f\"Imagen GT Anómala: {is_image_anomalous_gt}\")\n",
    "    print(f\"Imagen Predicha Anómala: {is_image_anomalous_pred}\")\n",
    "    print(f\"Image-level TP: {image_level_TP}, FP: {image_level_FP}, TN: {image_level_TN}, FN: {image_level_FN}\")\n",
    "\n",
    "    if is_image_anomalous_pred:\n",
    "        (print(f\"La imagen {base_image_name} se clasifica como: ANÓMALA\"))\n",
    "    else:\n",
    "        (print(f\"La imagen {base_image_name} se clasifica como: NORMAL\"))\n",
    "\n",
    "#else:\n",
    "#    print(\"La evaluación a nivel de píxel y de imagen se omitió debido a la falta de máscara Ground Truth.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_featup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
