{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta para guardar score maps: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/mahalanobis_score_maps\n",
      "Cargando datos del coreset...\n",
      "Coreset cargado. Dimensión: torch.Size([6323, 384])\n",
      "NearestNeighbors finder inicializado.\n",
      "Cargando modelo DINOv2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo DINOv2 cargado.\n",
      "Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\n",
      "Modelo SAM2 cargado.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/000.png ---\n",
      "Ground Truth Mask Path para 000: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/000_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2149 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/000/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 236.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9936301112174988\n",
      "Stability Score de la máscara: 0.9977436065673828\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/000/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 065.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9930665493011475\n",
      "Stability Score de la máscara: 0.9989156723022461\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/000/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 226.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9828659892082214\n",
      "Stability Score de la máscara: 0.9966545104980469\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/000/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 6.5854 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.997243404388428\n",
      "Mínimo de fobj_q_pooled: -1.612534523010254\n",
      "Máximo de d_M_q: 0.21730302274227142\n",
      "Mínimo de d_M_q: -0.05842828005552292\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8614, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[5510.6934, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8733, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[6205.3418, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8824, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[6792.8027, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.4520]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.4520, 0.5480],\n",
      "        [0.5480, 0.4520]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4520, 0.5480, 1.0000],\n",
      "        [0.5480, 0.4520, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4520 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5480\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.4667]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.4667, 0.5333],\n",
      "        [0.5333, 0.4667]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4667, 0.5333, 1.0000],\n",
      "        [0.5333, 0.4667, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4667 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5333\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.4780]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.4780, 0.5220],\n",
      "        [0.5220, 0.4780]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4780, 0.5220, 1.0000],\n",
      "        [0.5220, 0.4780, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4780 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5220\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 7789.8677\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 7789.8677\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [7789.86767578125]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 24.38 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/001.png ---\n",
      "Ground Truth Mask Path para 001: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/001_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2259 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/001/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 158.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.997078537940979\n",
      "Stability Score de la máscara: 0.9980888366699219\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/001/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 121.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9959703683853149\n",
      "Stability Score de la máscara: 0.997075080871582\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/001/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 161.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9969758987426758\n",
      "Stability Score de la máscara: 0.998560905456543\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/001/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 6.2897 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 6.298155307769775\n",
      "Mínimo de fobj_q_pooled: -1.7397104501724243\n",
      "Máximo de d_M_q: 0.23344089090824127\n",
      "Mínimo de d_M_q: -0.06448230147361755\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8956, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[7755.6045, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9120, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[9133.0908, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9113, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[9076.8496, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.4945]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.4945, 0.5055],\n",
      "        [0.5055, 0.4945]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4945, 0.5055, 1.0000],\n",
      "        [0.5055, 0.4945, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4945 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5055\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5150]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5150, 0.4850],\n",
      "        [0.4850, 0.5150]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5150, 0.4850, 1.0000],\n",
      "        [0.4850, 0.5150, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5150 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4850\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5142]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5142, 0.4858],\n",
      "        [0.4858, 0.5142]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5142, 0.4858, 1.0000],\n",
      "        [0.4858, 0.5142, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5142 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4858\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: [(0, 0)]\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 7338.3237\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 7070.2422\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 14407.8965\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [14407.896484375]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 28.51 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/002.png ---\n",
      "Ground Truth Mask Path para 002: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/002_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2082 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/002/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 158.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.997078537940979\n",
      "Stability Score de la máscara: 0.9980888366699219\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/002/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 210.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9952326416969299\n",
      "Stability Score de la máscara: 0.9984169006347656\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/002/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 157.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9968181848526001\n",
      "Stability Score de la máscara: 0.9978361129760742\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/002/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 6.5060 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 6.867792129516602\n",
      "Mínimo de fobj_q_pooled: -2.3180108070373535\n",
      "Máximo de d_M_q: 0.23191630840301514\n",
      "Mínimo de d_M_q: -0.07827617228031158\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8921, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[7484.0571, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8763, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[6394.3208, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8963, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[7807.8203, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.4901]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.4901, 0.5099],\n",
      "        [0.5099, 0.4901]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4901, 0.5099, 1.0000],\n",
      "        [0.5099, 0.4901, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4901 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5099\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.4704]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.4704, 0.5296],\n",
      "        [0.5296, 0.4704]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4704, 0.5296, 1.0000],\n",
      "        [0.5296, 0.4704, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4704 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5296\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.4954]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.4954, 0.5046],\n",
      "        [0.5046, 0.4954]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4954, 0.5046, 1.0000],\n",
      "        [0.5046, 0.4954, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4954 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5046\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 7332.6538\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 7332.6538\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [7332.65380859375]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 23.37 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/003.png ---\n",
      "Ground Truth Mask Path para 003: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/003_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2986 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/003/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 240.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9928275942802429\n",
      "Stability Score de la máscara: 0.9966316223144531\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/003/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 122.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9964908957481384\n",
      "Stability Score de la máscara: 0.9983291625976562\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/003/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 134.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9970133304595947\n",
      "Stability Score de la máscara: 0.9977245330810547\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/003/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 6.5057 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.9762468338012695\n",
      "Mínimo de fobj_q_pooled: -1.858911395072937\n",
      "Máximo de d_M_q: 0.21693125367164612\n",
      "Mínimo de d_M_q: -0.06747645884752274\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9225, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[10148.1250,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9011, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[8192.2852, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9075, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[8733.7754, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5281]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5281, 0.4719],\n",
      "        [0.4719, 0.5281]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5281, 0.4719, 1.0000],\n",
      "        [0.4719, 0.5281, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5281 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4719\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5014]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5014, 0.4986],\n",
      "        [0.4986, 0.5014]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5014, 0.4986, 1.0000],\n",
      "        [0.4986, 0.5014, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5014 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4986\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5094]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5094, 0.4906],\n",
      "        [0.4906, 0.5094]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5094, 0.4906, 1.0000],\n",
      "        [0.4906, 0.5094, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5094 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4906\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 6473.2261\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 6473.2261\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [6473.22607421875]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 22.92 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/004.png ---\n",
      "Ground Truth Mask Path para 004: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/004_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3039 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/004/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 236.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9936301112174988\n",
      "Stability Score de la máscara: 0.9977436065673828\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/004/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 234.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9954445362091064\n",
      "Stability Score de la máscara: 0.9984512329101562\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/004/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 013.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9966411590576172\n",
      "Stability Score de la máscara: 0.9990968704223633\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/004/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 6.0338 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 6.399409294128418\n",
      "Mínimo de fobj_q_pooled: -2.4009408950805664\n",
      "Máximo de d_M_q: 0.22239595651626587\n",
      "Mínimo de d_M_q: -0.08343888074159622\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8880, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[7186.8667, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8839, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[6900.5239, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8794, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[6591.5439, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.4850]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.4850, 0.5150],\n",
      "        [0.5150, 0.4850]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4850, 0.5150, 1.0000],\n",
      "        [0.5150, 0.4850, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4850 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5150\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.4799]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.4799, 0.5201],\n",
      "        [0.5201, 0.4799]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4799, 0.5201, 1.0000],\n",
      "        [0.5201, 0.4799, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4799 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5201\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.4742]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.4742, 0.5258],\n",
      "        [0.5258, 0.4742]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4742, 0.5258, 1.0000],\n",
      "        [0.5258, 0.4742, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4742 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5258\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 6994.0947\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 6994.0947\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [6994.0947265625]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 23.63 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/005.png ---\n",
      "Ground Truth Mask Path para 005: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/005_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2751 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/005/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 234.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9954445362091064\n",
      "Stability Score de la máscara: 0.9984512329101562\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/005/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 043.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9948327541351318\n",
      "Stability Score de la máscara: 0.9957942962646484\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/005/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 236.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9936301112174988\n",
      "Stability Score de la máscara: 0.9977436065673828\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/005/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 6.6288 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.720937728881836\n",
      "Mínimo de fobj_q_pooled: -2.0834808349609375\n",
      "Máximo de d_M_q: 0.2099420577287674\n",
      "Mínimo de d_M_q: -0.07645779103040695\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9272, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[10632.2031,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9386, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[11916.6133,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9236, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[10259.6533,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5339]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5339, 0.4661],\n",
      "        [0.4661, 0.5339]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5339, 0.4661, 1.0000],\n",
      "        [0.4661, 0.5339, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5339 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4661\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5481]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5481, 0.4519],\n",
      "        [0.4519, 0.5481]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5481, 0.4519, 1.0000],\n",
      "        [0.4519, 0.5481, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5481 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4519\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5295]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5295, 0.4705],\n",
      "        [0.4705, 0.5295]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5295, 0.4705, 1.0000],\n",
      "        [0.4705, 0.5295, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5295 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4705\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 5100.7695\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 5100.7695\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [5100.76953125]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 23.75 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/006.png ---\n",
      "Ground Truth Mask Path para 006: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/006_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3004 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/006/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 233.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9938873648643494\n",
      "Stability Score de la máscara: 0.9986305236816406\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/006/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 236.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9936301112174988\n",
      "Stability Score de la máscara: 0.9977436065673828\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/006/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 234.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9954445362091064\n",
      "Stability Score de la máscara: 0.9984512329101562\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/006/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 7.5329 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.963206768035889\n",
      "Mínimo de fobj_q_pooled: -2.64412260055542\n",
      "Máximo de d_M_q: 0.22025202214717865\n",
      "Mínimo de d_M_q: -0.0976611003279686\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9462, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[12861.3223,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9536, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[13845.7979,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9573, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[14374.2607,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5575]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5575, 0.4425],\n",
      "        [0.4425, 0.5575]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5575, 0.4425, 1.0000],\n",
      "        [0.4425, 0.5575, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5575 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4425\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5666]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5666, 0.4334],\n",
      "        [0.4334, 0.5666]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5666, 0.4334, 1.0000],\n",
      "        [0.4334, 0.5666, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5666 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4334\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5712]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5712, 0.4288],\n",
      "        [0.4288, 0.5712]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5712, 0.4288, 1.0000],\n",
      "        [0.4288, 0.5712, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5712 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4288\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 3589.3735\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 3589.3735\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [3589.37353515625]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 23.90 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/007.png ---\n",
      "Ground Truth Mask Path para 007: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/007_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.5243 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/007/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 240.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9928275942802429\n",
      "Stability Score de la máscara: 0.9966316223144531\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/007/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 237.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9961380362510681\n",
      "Stability Score de la máscara: 0.9973115921020508\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/007/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 243.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9958662986755371\n",
      "Stability Score de la máscara: 0.9972257614135742\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/007/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 5.9233 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 6.5148797035217285\n",
      "Mínimo de fobj_q_pooled: -2.1628530025482178\n",
      "Máximo de d_M_q: 0.22768394649028778\n",
      "Mínimo de d_M_q: -0.07558802515268326\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9244, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[10346.2168,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9252, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[10422.1230,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9037, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[8410.8369, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5305]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5305, 0.4695],\n",
      "        [0.4695, 0.5305]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5305, 0.4695, 1.0000],\n",
      "        [0.4695, 0.5305, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5305 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4695\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5314]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5314, 0.4686],\n",
      "        [0.4686, 0.5314]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5314, 0.4686, 1.0000],\n",
      "        [0.4686, 0.5314, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5314 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4686\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5047]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5047, 0.4953],\n",
      "        [0.4953, 0.5047]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5047, 0.4953, 1.0000],\n",
      "        [0.4953, 0.5047, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5047 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4953\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 6906.5327\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 6906.5327\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [6906.53271484375]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 23.51 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/008.png ---\n",
      "Ground Truth Mask Path para 008: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/008_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.1881 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/008/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 240.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9928275942802429\n",
      "Stability Score de la máscara: 0.9966316223144531\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/008/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 153.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9971202611923218\n",
      "Stability Score de la máscara: 0.9983854293823242\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/008/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 242.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9963576197624207\n",
      "Stability Score de la máscara: 0.9979267120361328\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/008/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 2.3241 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.962265968322754\n",
      "Mínimo de fobj_q_pooled: -2.219223976135254\n",
      "Máximo de d_M_q: 0.22411039471626282\n",
      "Mínimo de d_M_q: -0.08341646939516068\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9466, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[12911.8828,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9289, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[10817.7051,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9386, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[11917.7266,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5580]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5580, 0.4420],\n",
      "        [0.4420, 0.5580]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5580, 0.4420, 1.0000],\n",
      "        [0.4420, 0.5580, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5580 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4420\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5361]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5361, 0.4639],\n",
      "        [0.4639, 0.5361]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5361, 0.4639, 1.0000],\n",
      "        [0.4639, 0.5361, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5361 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4639\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5481]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5481, 0.4519],\n",
      "        [0.4519, 0.5481]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5481, 0.4519, 1.0000],\n",
      "        [0.4519, 0.5481, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5481 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4519\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 5386.8423\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 0.0000\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 5386.8423\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [5386.84228515625]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 18.64 segundos\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/hole/009.png ---\n",
      "Ground Truth Mask Path para 009: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/ground_truth/hole/009_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (247, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([247, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3198 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 8x8 puntos...\n",
      "Número de máscaras generadas (SIn de filtrar): 1\n",
      "Máscara 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/009/processed_masks/query_mask_1.png\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 066.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.995355486869812\n",
      "Stability Score de la máscara: 0.9970169067382812\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/009/processed_masks/similar_1_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 065.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9930665493011475\n",
      "Stability Score de la máscara: 0.9989156723022461\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/009/processed_masks/similar_2_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 236.png ---\n",
      "Mayor área de máscara actualizada: 1048576\n",
      "Bounding box de la máscara: [0.0, 0.0, 1023.0, 1023.0]\n",
      "Predicted IoU de la máscara: 0.9936301112174988\n",
      "Stability Score de la máscara: 0.9977436065673828\n",
      "Procesando jerárquicamente 1 máscaras...\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_wood/hole/009/processed_masks/similar_3_processed_mask_1.png\n",
      "Procesamiento jerárquico de máscaras completado.\n",
      "Área de la máscara: 1048576\n",
      "Máscaras generadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 6.2851 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 6.28516149520874\n",
      "Mínimo de fobj_q_pooled: -1.7297154664993286\n",
      "Máximo de d_M_q: 0.22365646064281464\n",
      "Mínimo de d_M_q: -0.061551645398139954\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8897, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[7311.3452, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9008, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[8169.0835, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8750, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[6309.4424, 8103.0840],\n",
      "        [8103.0840, 8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.4872]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.4872, 0.5128],\n",
      "        [0.5128, 0.4872]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4872, 0.5128, 1.0000],\n",
      "        [0.5128, 0.4872, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4872 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5128\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5010]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5010, 0.4990],\n",
      "        [0.4990, 0.5010]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5010, 0.4990, 1.0000],\n",
      "        [0.4990, 0.5010, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5010 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4990\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.4688]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.4688, 0.5312],\n",
      "        [0.5312, 0.4688]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.4688, 0.5312, 1.0000],\n",
      "        [0.5312, 0.4688, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.4688 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.5312\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(1, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (2, 0)]\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "pre1\n",
      "preparando\n",
      "pre2\n",
      "Query 0:\n",
      "  Shape of matched_map_for_query: torch.Size([128, 128]), Max: 7765.8477\n",
      "  Shape of unmatched_map_for_query: torch.Size([128, 128]), Max: 7735.3623\n",
      "  Shape of combined_map_for_query_i: torch.Size([128, 128]), Max: 15501.2100\n",
      "Number of maps in combined_individual_score_maps: 1\n",
      "Max values across all combined_individual_score_maps: [15501.2099609375]\n",
      "finalizado iteracion\n",
      "Tiempo total de ejecución iteracion: 24.65 segundos\n",
      "finalizado\n",
      "Tiempo total de ejecución iteracion: 237.27 segundos\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# FeatUp utilities\n",
    "from featup.util import norm, unnorm\n",
    "from featup.plotting import plot_feats\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Anomaly region detection and visualization\n",
    "from skimage import measure\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# SAM2 imports\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import cv2\n",
    "\n",
    "# PCA for manual visualization\n",
    "from sklearn.decomposition import PCA\n",
    "# --- Enable loading of truncated images ---\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # Add this at the very top for global effect\n",
    "\n",
    "# --- Configuración ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224  # DINOv2 input size\n",
    "BACKBONE_PATCH_SIZE = 14  # DINOv2 ViT-S/14 patch size\n",
    "use_norm = True\n",
    "\n",
    "H_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "W_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "\n",
    "# Directorios\n",
    "TRAIN_GOOD_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/train/good'\n",
    "directorio_coreset = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/train/good/archivos_coreset'\n",
    "#PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/plots_final_eval/cut'\n",
    "# --- Imagen de Consulta ---\n",
    "BASE_PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion_wood/good'\n",
    "\n",
    "# Directory containing the test images \n",
    "TEST_IMAGES_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/wood/test/good'\n",
    "\n",
    "# Create parent plot directory if it doesn't exist\n",
    "os.makedirs(BASE_PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "# --- NUEVA CARPETA PARA LOS MAPAS DE ANOMALÍAS ---\n",
    "MAHALANOBIS_SCORE_MAPS_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'mahalanobis_score_maps')\n",
    "os.makedirs(MAHALANOBIS_SCORE_MAPS_DIR, exist_ok=True)\n",
    "print(f\"Carpeta para guardar score maps: {MAHALANOBIS_SCORE_MAPS_DIR}\")\n",
    "\n",
    "# Coreset file paths\n",
    "core_bank_filenames_file = os.path.join(directorio_coreset, 'core_bank_filenames.pt')\n",
    "coreset_relevant_flat_features_bank_file = os.path.join(directorio_coreset, 'coreset_relevant_flat_features_bank.pt')\n",
    "template_features_bank_coreset_file = os.path.join(directorio_coreset, 'template_features_bank_coreset.pt')\n",
    "\n",
    "# --- Cargar Datos del Coreset ---\n",
    "print(\"Cargando datos del coreset...\")\n",
    "try:\n",
    "    coreset_relevant_filenames = torch.load(core_bank_filenames_file)\n",
    "    coreset_relevant_flat_features_bank = torch.load(coreset_relevant_flat_features_bank_file).to(device)\n",
    "    coreset_features = torch.load(template_features_bank_coreset_file).to(device)\n",
    "    print(f\"Coreset cargado. Dimensión: {coreset_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar archivos del coreset: {e}. Asegúrate de que la Etapa 1 se ejecutó.\")\n",
    "    exit()\n",
    "\n",
    "# Mover coreset a CPU para sklearn's NearestNeighbors\n",
    "coreset_features_cpu = coreset_features.cpu().numpy()\n",
    "# se calcula la distancia coseno == 1 - similitud coseno [0,1] 0 identico, 1 completamente diferente\n",
    "nn_finder = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='cosine').fit(coreset_features_cpu)\n",
    "print(\"NearestNeighbors finder inicializado.\")\n",
    "\n",
    "# --- Cargar Modelo DINOv2 ---\n",
    "print(\"Cargando modelo DINOv2...\")\n",
    "featup_local_path = \"/home/imercatoma/FeatUp\"\n",
    "upsampler = torch.hub.load(featup_local_path, 'dinov2', use_norm=use_norm, source='local').to(device)\n",
    "\n",
    "dinov2_model = upsampler.model\n",
    "dinov2_model.eval()\n",
    "print(\"Modelo DINOv2 cargado.\")\n",
    "\n",
    "# --- Transformación de Imagen ---\n",
    "transform = T.Compose([\n",
    "    T.Resize(input_size),\n",
    "    T.CenterCrop((input_size, input_size)),\n",
    "    T.ToTensor(),\n",
    "    norm\n",
    "])\n",
    "\n",
    "# --- Carga del Modelo SAM2 ---\n",
    "print(f\"Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\")\n",
    "checkpoint = \"/home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt\"\n",
    "model_cfg_name = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_model = build_sam2(model_cfg_name, checkpoint, device=device, apply_postprocessing=True)\n",
    "sam2_model.eval()\n",
    "print(\"Modelo SAM2 cargado.\")\n",
    "\n",
    "#### fin de carga de modelos\n",
    "\n",
    "# --- CONFIGURACIÓN PARA EL GUARDADO DE EXCEL ---\n",
    "EXCEL_OUTPUT_PATH = 'resultados_evaluacion_anomalias.xlsx'\n",
    "all_evaluation_results = [] # This list will accumulate results from all processed images\n",
    "\n",
    "# Opción 2: Procesar solo las primeras 10 imágenes (descomentar si prefieres esta opción)\n",
    "image_paths = glob.glob(os.path.join(TEST_IMAGES_DIR, '*.png'))\n",
    "image_paths.sort()\n",
    "\n",
    "######\n",
    "start_time_global = time.time()\n",
    "# --- Bucle para procesar cada imagen ---\n",
    "for query_image_path in image_paths:\n",
    "    start_time_total = time.time()\n",
    "    print(f\"\\n--- Procesando imagen: {query_image_path} ---\")\n",
    "\n",
    "    # Extraer el nombre base de la imagen (ej: '006.png')\n",
    "    base_image_name_with_ext = os.path.basename(query_image_path)\n",
    "    base_image_name = os.path.splitext(base_image_name_with_ext)[0] # '006'\n",
    "\n",
    "    # Construir la ruta de la máscara Ground Truth para la imagen actual\n",
    "    gt_mask_path = query_image_path.replace('test', 'ground_truth').replace('.png', '_mask.png')\n",
    "    print(f\"Ground Truth Mask Path para {base_image_name}: {gt_mask_path}\")\n",
    "\n",
    "    # --- Directorios de guardado específicos para esta imagen ---\n",
    "    PLOT_SAVE_ROOT_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, base_image_name)\n",
    "    os.makedirs(PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "    HEATMAPS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'individual_heatmaps')\n",
    "    os.makedirs(HEATMAPS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    ANOMALY_REGIONS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'detected_anomaly_regions')\n",
    "    os.makedirs(ANOMALY_REGIONS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    FEATUP_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'featup_feature_plots')\n",
    "    os.makedirs(FEATUP_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "    # --- Cargar la imagen de consulta CON ERROR HANDLING ---\n",
    "    query_img_pil = None # Initialize to None\n",
    "    try:\n",
    "        query_img_pil = Image.open(query_image_path).convert(\"RGB\")\n",
    "        W, H = query_img_pil.size # Get dimensions for consistent resizing\n",
    "    except OSError as e:\n",
    "        print(f\"ERROR: No se pudo cargar o procesar la imagen de consulta '{query_image_path}'. Error: {e}\")\n",
    "        print(\"Saltando a la siguiente imagen...\")\n",
    "        continue # Skip to the next image in the loop\n",
    "\n",
    "    # If query_img_pil is still None, it means an error occurred, so skip\n",
    "    if query_img_pil is None:\n",
    "        continue\n",
    "\n",
    "    # Definir el tamaño objetivo para las máscaras de evaluación (el mismo que el mapa de anomalías)\n",
    "    TARGET_EVAL_SIZE = (W, H)\n",
    "\n",
    "    #############----------- PROCESO   -----###############\n",
    "    \n",
    "    input_tensor = transform(query_img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_lr = dinov2_model(input_tensor)\n",
    "\n",
    "    query_lr_features = features_lr\n",
    "\n",
    "    # --- Función para buscar imágenes similares usando KNN ---\n",
    "    def buscar_imagenes_similares_knn(query_feature_map, pre_flattened_features_bank, k=3, nombres_archivos=None):\n",
    "        query_feat_flatten = query_feature_map.flatten().cpu().numpy()#dimension mapa desde banco torch.Size([1, 384, 16, 16])\n",
    "        print(f\"dimension mapa query\", query_feature_map.shape)\n",
    "        print(f\"dimension query flatten\", query_feat_flatten.shape)#dimension query flatten (98304,)\n",
    "        features_bank_for_knn = pre_flattened_features_bank.cpu().numpy() if isinstance(pre_flattened_features_bank, torch.Tensor) else pre_flattened_features_bank\n",
    "        print(f\"dimension query flatten\", features_bank_for_knn.shape)#dimension query flatten (213, 98304)\n",
    "        print(f\"dimensiones desde BANCO STAGE 1 stage\", pre_flattened_features_bank.shape)#dimensiones desde BANCO STAGE 1 stage torch.Size([213, 98304])\n",
    "        \n",
    "        \n",
    "        start_time_knn_dist = time.time()\n",
    "        distances = euclidean_distances([query_feat_flatten], features_bank_for_knn)\n",
    "        nearest_indices = np.argsort(distances[0])[:k]\n",
    "        end_time_knn_dist = time.time()\n",
    "        print(f\"Tiempo para calcular distancias KNN: {end_time_knn_dist - start_time_knn_dist:.4f} segundos\")\n",
    "\n",
    "        imagenes_similares = []\n",
    "        rutas_imagenes_similares = []\n",
    "        if nombres_archivos:\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(nombres_archivos[idx])\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, nombres_archivos[idx]))\n",
    "        else: # Fallback if no filenames provided (less common for this use case)\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(f\"Imagen_Banco_{idx:03d}.png\")\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, f\"Imagen_Banco_{idx:03d}.png\"))\n",
    "        return imagenes_similares, rutas_imagenes_similares, end_time_knn_dist\n",
    "\n",
    "    # --- Búsqueda KNN ---\n",
    "    print(\"\\nBuscando imágenes similares usando el banco pre-aplanado del Coreset...\")\n",
    "    imagenes_similares, rutas_imagenes_similares, time_knn_dist = buscar_imagenes_similares_knn(\n",
    "        query_lr_features, coreset_relevant_flat_features_bank, nombres_archivos=coreset_relevant_filenames\n",
    "    )\n",
    "\n",
    "    # --- Aplicar FeatUp para obtener características de alta resolución ---\n",
    "    def apply_featup_hr(image_path, featup_upsampler, image_transform, device):\n",
    "        image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = image_transform(image_pil).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            lr_feats = featup_upsampler.model(image_tensor)\n",
    "            hr_feats = featup_upsampler(image_tensor)\n",
    "        return lr_feats.cpu(), hr_feats.cpu()\n",
    "\n",
    "    # Características de la imagen de consulta\n",
    "    input_query_tensor_original = transform(Image.open(query_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    query_lr_feats_featup, query_hr_feats = apply_featup_hr(query_image_path, upsampler, transform, device)\n",
    "\n",
    "    # Características de las imágenes similares\n",
    "    similar_hr_feats_list = []\n",
    "    for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "        input_similar_tensor_original = transform(Image.open(similar_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "        similar_lr_feats, similar_hr_feats = apply_featup_hr(similar_image_path, upsampler, transform, device)\n",
    "        similar_hr_feats_list.append(similar_hr_feats)\n",
    "\n",
    "    ################################\n",
    "    ### Aplicando Máscaras SAM query y similares\n",
    "\n",
    "    def show_mask(mask, ax, random_color=False, borders=True):\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image_alpha = np.zeros((h, w, 4), dtype=np.float32)\n",
    "        mask_image_alpha[mask > 0] = color\n",
    "        if borders:\n",
    "            mask_uint8 = mask.astype(np.uint8) * 255\n",
    "            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contour_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=2)\n",
    "            contour_mask = (contour_image.astype(np.float32) / 255.0).sum(axis=-1) > 0\n",
    "            mask_image_alpha[contour_mask > 0, :3] = 1.0\n",
    "            mask_image_alpha[contour_mask > 0, 3] = 0.5\n",
    "        ax.imshow(mask_image_alpha)\n",
    "\n",
    "    def process_masks_with_hierarchy(image, masks, output_dir, filename_prefix, overlap_threshold=0.8):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        final_processed_masks_data = [] \n",
    "        original_mask_segments_for_comparison = [mask_data[\"segmentation\"] for mask_data in masks]\n",
    "\n",
    "        print(f\"Procesando jerárquicamente {len(masks)} máscaras...\")\n",
    "\n",
    "        for i, mask_data_a_original in enumerate(masks): \n",
    "            mask_data_a_processed = mask_data_a_original.copy() \n",
    "            mask_a_current_processing = np.copy(mask_data_a_original[\"segmentation\"]) \n",
    "\n",
    "            is_completely_internal_to_another = False \n",
    "            potential_holes_for_mask_a = [] \n",
    "\n",
    "            for j, mask_data_b_comparison in enumerate(masks): \n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                mask_b = original_mask_segments_for_comparison[j] \n",
    "\n",
    "                if np.sum(mask_a_current_processing) > 0 and np.all(np.logical_and(mask_a_current_processing, mask_b) == mask_a_current_processing):\n",
    "                    is_completely_internal_to_another = True\n",
    "                    break \n",
    "\n",
    "                intersection_ab = np.logical_and(mask_b, mask_a_current_processing)\n",
    "                area_b = np.sum(mask_b)\n",
    "                area_intersection_ab = np.sum(intersection_ab)\n",
    "\n",
    "                if area_b > 0 and (np.all(intersection_ab == mask_b) or \\\n",
    "                                (area_intersection_ab / area_b > overlap_threshold and area_intersection_ab > 0)):\n",
    "                    if np.sum(mask_b) < np.sum(mask_a_current_processing) * 0.9: \n",
    "                        potential_holes_for_mask_a.append(mask_b)\n",
    "\n",
    "            if is_completely_internal_to_another:\n",
    "                display_title = f'Máscara {i + 1} (Interna - Sin cambios significativos)'\n",
    "            else:\n",
    "                hollowed = False\n",
    "                for hole_mask in potential_holes_for_mask_a:\n",
    "                    mask_a_current_processing = np.logical_and(mask_a_current_processing, np.logical_not(hole_mask))\n",
    "                    hollowed = True\n",
    "                \n",
    "                mask_data_a_processed[\"segmentation\"] = mask_a_current_processing \n",
    "                if hollowed:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Hueca)'\n",
    "                else:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Sin huecos significativos)'\n",
    "\n",
    "            final_processed_masks_data.append(mask_data_a_processed) \n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(image) \n",
    "            show_mask(mask_data_a_processed[\"segmentation\"], plt.gca(), random_color=True) \n",
    "            plt.axis('off')\n",
    "            plt.title(display_title)\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{filename_prefix}_processed_mask_{i + 1}.png\")\n",
    "            plt.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Máscara procesada {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "        print(\"Procesamiento jerárquico de máscaras completado.\")\n",
    "        return final_processed_masks_data \n",
    "\n",
    "    def apply_morphological_closing(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            return masks_list\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando cierre morfológico con kernel {kernel_size}x{kernel_size}...\")\n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_smoothed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_CLOSE, kernel)\n",
    "            mask_data['segmentation'] = (mask_smoothed_np > 0).astype(bool)\n",
    "        print(\"Suavizado de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    def apply_morphological_opening(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            print(\"La lista de máscaras está vacía, no se aplica la apertura morfológica.\")\n",
    "            return masks_list\n",
    "        \n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando apertura morfológica con kernel {kernel_size}x{kernel_size}...\")\n",
    "        \n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            if mask_boolean.dtype != bool:\n",
    "                mask_boolean = mask_boolean.astype(bool)\n",
    "\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_processed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_OPEN, kernel)\n",
    "            mask_data['segmentation'] = (mask_processed_np > 0).astype(bool)\n",
    "            \n",
    "        print(\"Suavizado (apertura) de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    try:\n",
    "        image_for_sam_np = np.array(Image.open(query_image_path).convert(\"RGB\"))\n",
    "        print(f\"Dimensiones imagen SAM: {image_for_sam_np.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando imagen para SAM: {e}. Saltando SAM.\")\n",
    "        sam2_model = None\n",
    "        \n",
    "    PROCESSED_MASKS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"processed_masks\")\n",
    "\n",
    "    if sam2_model is not None:\n",
    "        points_grid_density = 8\n",
    "        min_mask_area_pixels = 3000\n",
    "\n",
    "        mask_generator_query = SAM2AutomaticMaskGenerator(\n",
    "            model=sam2_model,\n",
    "            points_per_side=points_grid_density,\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.7,\n",
    "            stability_score_thresh=0.6,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=min_mask_area_pixels,\n",
    "        )\n",
    "        max_mask_area_pixels = 1024*1024\n",
    "        print(f\"Generando máscaras para consulta con grid de {points_grid_density}x{points_grid_density} puntos...\")\n",
    "        \n",
    "        \n",
    "        masks_data_query_image = mask_generator_query.generate(image_for_sam_np)\n",
    "        \n",
    "        # Reemplazar masks_data_query_image con toda la imagen sin excepción\n",
    "        # Crear una máscara que cubra toda la imagen\n",
    "        full_image_mask = np.ones(image_for_sam_np.shape[:2], dtype=bool)  # Máscara binaria que cubre toda la imagen\n",
    "\n",
    "        # Crear un diccionario con la estructura esperada por el mask generator\n",
    "        masks_data_query_image = [{\n",
    "            'segmentation': full_image_mask,\n",
    "            'area': full_image_mask.sum(),\n",
    "            'bbox': [0, 0, image_for_sam_np.shape[1], image_for_sam_np.shape[0]],  # Bounding box que cubre toda la imagen\n",
    "            'predicted_iou': 1.0,  # IoU máximo ya que cubre toda la imagen\n",
    "            'point_coords': None,  # Sin puntos específicos\n",
    "            'stability_score': 1.0,  # Máxima estabilidad\n",
    "            'crop_box': [0, 0, image_for_sam_np.shape[1], image_for_sam_np.shape[0]]  # Caja de recorte que cubre toda la imagen\n",
    "        }]\n",
    "        print(f\"Número de máscaras generadas (SIn de filtrar): {len(masks_data_query_image)}\")\n",
    "        # # Quedarse solo con el área más grande\n",
    "        # if filtered_masks_data:\n",
    "        #     masks_data_query_image = [max(filtered_masks_data, key=lambda mask: mask['area'])]\n",
    "        # else:\n",
    "        #     masks_data_query_image = []\n",
    "        \n",
    "         #processed_masks_query = process_masks_with_hierarchy(image_for_sam_np, masks_data_query_image, PROCESSED_MASKS_DIR, \"query\")\n",
    "        for i, mask_data in enumerate(masks_data_query_image):\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            mask_np = mask_data[\"segmentation\"]\n",
    "            plt.imshow(mask_np, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Máscara {i + 1} - Área: {mask_data['area']}, IoU: {mask_data['predicted_iou']:.4f}\")\n",
    "            \n",
    "            if not os.path.exists(PROCESSED_MASKS_DIR):\n",
    "                os.makedirs(PROCESSED_MASKS_DIR)\n",
    "            output_path = os.path.join(PROCESSED_MASKS_DIR, f\"query_mask_{i + 1}.png\")\n",
    "            plt.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Máscara {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "        \n",
    "        #print(f\"Número de máscaras generadas DESPUÉS de filtrar (área >= {min_area_threshold}): {len(masks_data_query_image)}\")   \n",
    "        \n",
    "        mask_generator_similar = SAM2AutomaticMaskGenerator( \n",
    "            model=sam2_model,\n",
    "            points_per_side=8,#25\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.7,\n",
    "            stability_score_thresh=0.6,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=3000,\n",
    "        )\n",
    "\n",
    "        print(\"\\nGenerando máscaras SAM para imágenes similares...\")\n",
    "        similar_masks_raw_list = []\n",
    "        mask_big = []\n",
    "       \n",
    "        # Initialize start_time_sam here, outside the loop\n",
    "        start_time_sam = time.time()\n",
    "        for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "            \n",
    "            try:\n",
    "                image_np_similar_for_sam = np.array(Image.open(similar_image_path).convert('RGB'))\n",
    "                print(f\"--- Procesando vecino {j+1}: {os.path.basename(similar_image_path)} ---\")\n",
    "                filtered_masks_data =[]\n",
    "                current_similar_masks_data = []\n",
    "                mask_big = []\n",
    "                current_similar_masks_data = mask_generator_similar.generate(image_np_similar_for_sam)\n",
    "                # Filtrar por área mínima\n",
    "                current_similar_masks_data = [\n",
    "                    m for m in current_similar_masks_data \n",
    "                    if m['area'] >= 900*900 and m['area'] <= max_mask_area_pixels\n",
    "                ]\n",
    "\n",
    "                # # Filtrar máscaras que toquen algún borde de la imagen\n",
    "                # filtered_masks_data = []\n",
    "                # image_width, image_height = image_np_similar_for_sam.shape[1], image_np_similar_for_sam.shape[0]\n",
    "\n",
    "                # for mask_data in current_similar_masks_data:\n",
    "                #     bbox = mask_data['bbox']\n",
    "                #     x_min, y_min, x_max, y_max = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "\n",
    "                #     # Verificar si la máscara toca algún borde de la imagen\n",
    "                #     touches_left = x_min <= 0\n",
    "                #     touches_top = y_min <= 0\n",
    "                #     touches_right = x_max >= image_width\n",
    "                #     touches_bottom = y_max >= image_height\n",
    "\n",
    "                #     # Calcular porcentaje de contacto con los bordes\n",
    "                #     contact_percentage = 0\n",
    "                #     if touches_left:\n",
    "                #         contact_percentage += (y_max - y_min) / image_height\n",
    "                #     if touches_top:\n",
    "                #         contact_percentage += (x_max - x_min) / image_width\n",
    "                #     if touches_right:\n",
    "                #         contact_percentage += (y_max - y_min) / image_height\n",
    "                #     if touches_bottom:\n",
    "                #         contact_percentage += (x_max - x_min) / image_width\n",
    "\n",
    "                #     # Filtrar máscaras que tengan al menos 1% de contacto con algún borde\n",
    "                #     if contact_percentage < 0.01:\n",
    "                #         filtered_masks_data.append(mask_data)\n",
    "                #     else:\n",
    "                #         print(f\"Máscara descartada por tocar borde: Área={mask_data['area']}, IoU={mask_data['predicted_iou']:.4f}, Estabilidad={mask_data['stability_score']:.4f}\")\n",
    "                # print(f\"Cantidad de máscaras filtradas por área mínima y contacto con bordes: {len(filtered_masks_data)}\")\n",
    "                \n",
    "                # current_similar_masks_data = filtered_masks_data\n",
    "                \n",
    "                # # Filtrar por la máscara binaria que tiende más al centro\n",
    "                # center_x, center_y = image_np_similar_for_sam.shape[1] // 2, image_np_similar_for_sam.shape[0] // 2\n",
    "\n",
    "                # def binary_mask_distance_to_center(mask):\n",
    "                #     mask_indices = np.argwhere(mask['segmentation'])\n",
    "                #     if mask_indices.size == 0:\n",
    "                #         return float('inf')  # Si la máscara está vacía, asignar una distancia infinita\n",
    "                #     mask_center_x = mask_indices[:, 1].mean()\n",
    "                #     mask_center_y = mask_indices[:, 0].mean()\n",
    "                #     return np.sqrt((mask_center_x - center_x)**2 + (mask_center_y - center_y)**2)\n",
    "\n",
    "                # if current_similar_masks_data:\n",
    "                #     closest_to_center_mask = min(current_similar_masks_data, key=binary_mask_distance_to_center)\n",
    "                #     # Asegurarse de que la máscara esté suficientemente centrada verificando su distancia al centro de la imagen\n",
    "                #     max_distance_threshold = min(image_np_similar_for_sam.shape[1], image_np_similar_for_sam.shape[0]) * 0.25\n",
    "                #     if binary_mask_distance_to_center(closest_to_center_mask) <= max_distance_threshold:\n",
    "                #         current_similar_masks_data = [closest_to_center_mask]\n",
    "\n",
    "                # Filtrar por el de mayor área\n",
    "                if current_similar_masks_data:\n",
    "                    max_area_mask = max(current_similar_masks_data, key=lambda m: m['area'])\n",
    "                    mask_big = [max_area_mask]\n",
    "                    print(f\"Mayor área de máscara actualizada: {max_area_mask['area']}\")\n",
    "                    bbox = max_area_mask['bbox']\n",
    "                    print(f\"Bounding box de la máscara: {bbox}\")\n",
    "                    print(f\"Predicted IoU de la máscara: {max_area_mask['predicted_iou']}\")\n",
    "                    print(f\"Stability Score de la máscara: {max_area_mask['stability_score']}\")\n",
    "                    \n",
    "                    # # Dibujar el bounding box en la imagen\n",
    "                    # plt.figure(figsize=(8, 8))\n",
    "                    # plt.imshow(image_np_similar_for_sam)\n",
    "                    # rect = patches.Rectangle(\n",
    "                    #     (bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1],\n",
    "                    #     linewidth=2, edgecolor='red', facecolor='none'\n",
    "                    # )\n",
    "                    # plt.gca().add_patch(rect)\n",
    "                    # plt.title(f\"Bounding Box de la Máscara Mayor Área - Vecino {j+1}\")\n",
    "                    # plt.axis('off')\n",
    "                    \n",
    "                    # # Guardar la imagen con el bounding box\n",
    "                    # bbox_save_path = os.path.join(PROCESSED_MASKS_DIR, f\"bbox_similar_{j+1}.png\")\n",
    "                    # plt.savefig(bbox_save_path, bbox_inches='tight')\n",
    "                    # plt.close()\n",
    "                    # print(f\"Bounding box dibujado y guardado en: {bbox_save_path}\")\n",
    "                        \n",
    "                processed_masks_similar = process_masks_with_hierarchy(image_np_similar_for_sam, current_similar_masks_data, PROCESSED_MASKS_DIR, f\"similar_{j+1}\")\n",
    "                for mask in processed_masks_similar:\n",
    "                    print(f\"Área de la máscara: {mask['area']}\")\n",
    "                similar_masks_raw_list.append(processed_masks_similar)\n",
    "                \n",
    "                print(f\"Máscaras generadas para vecino {j+1}: {len(processed_masks_similar)}.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando imagen similar {os.path.basename(similar_image_path)} para SAM: {e}\")\n",
    "\n",
    "        end_time_sam = time.time()\n",
    "        print(f\"Tiempo total de ejecución de SAM: {end_time_sam - start_time_sam:.4f} segundos.\")\n",
    "\n",
    "    print(\"\\nAnálisis de detección de anomalías para una sola imagen completado.\")\n",
    "    \n",
    "    # Llamar a la función para procesar las máscaras de la query\n",
    "    # processed_masks_query = process_masks_with_hierarchy(image_for_sam_np, masks_data_query_image, PROCESSED_MASKS_DIR, \"query\")\n",
    "    # masks_data_query_image = processed_masks_query\n",
    "    # print(\"Shape de masks_data_query_image:\", len(masks_data_query_image))\n",
    "\n",
    "    #####################\n",
    "\n",
    "    # --- Implementación del punto 3.4.3. Object Feature Map ---\n",
    "    def process_masks_to_object_feature_maps(raw_masks, hr_feature_map, target_h, target_w, sam_processed_image_shape):\n",
    "        if not raw_masks:\n",
    "            print(\"Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\")\n",
    "            C_dim = hr_feature_map.shape[0] if hr_feature_map.ndim >= 3 else 0\n",
    "            return torch.empty(0, C_dim, target_h, target_w, device=hr_feature_map.device), \\\n",
    "                torch.empty(0, 1, target_h, target_w, device=hr_feature_map.device)\n",
    "\n",
    "        object_feature_maps_list = []\n",
    "        scaled_mask_append = []\n",
    "        C_dim = hr_feature_map.shape[0] \n",
    "\n",
    "        for mask_info in raw_masks:\n",
    "            mask_np = mask_info['segmentation'].astype(np.float32)\n",
    "            mask_tensor_original_res = torch.from_numpy(mask_np).unsqueeze(0).unsqueeze(0) #(1,1,H,W)\n",
    "            mask_tensor_original_res = mask_tensor_original_res.to(hr_feature_map.device)\n",
    "\n",
    "            scaled_mask = F.interpolate(mask_tensor_original_res,\n",
    "                                        size=(target_h, target_w),\n",
    "                                        mode='bilinear',\n",
    "                                        align_corners=False)\n",
    "            scaled_mask = (scaled_mask > 0.5).float()\n",
    "            scaled_mask_append.append(scaled_mask)\n",
    "            \n",
    "            if hr_feature_map.ndim == 3:\n",
    "                hr_feature_map_with_batch = hr_feature_map.unsqueeze(0) #(1,C,W,H)\n",
    "            else: \n",
    "                hr_feature_map_with_batch = hr_feature_map\n",
    "\n",
    "            object_feature_map_i = scaled_mask * hr_feature_map_with_batch\n",
    "            object_feature_maps_list.append(object_feature_map_i)\n",
    "\n",
    "        final_object_feature_maps = torch.cat(object_feature_maps_list, dim=0) \n",
    "        final_scaled_masks = torch.cat(scaled_mask_append, dim=0)\n",
    "        \n",
    "        return final_object_feature_maps, final_scaled_masks\n",
    "\n",
    "    # --- Visualización de Mapas de Características de Objeto ---\n",
    "    def visualize_object_feature_map(original_image_path, sam_mask_info, hr_feature_map_tensor,\n",
    "                                    object_feature_map_tensor, target_h, target_w,\n",
    "                                    plot_save_dir, plot_filename_prefix, mask_idx,\n",
    "                                    sam_processed_image_shape):\n",
    "        try:\n",
    "            original_img = Image.open(original_image_path).convert(\"RGB\")\n",
    "            sam_mask_np = sam_mask_info['segmentation']\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "            axes[0].imshow(original_img)\n",
    "            axes[0].set_title(f'Imagen Original\\n{os.path.basename(original_image_path)}')\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            mask_display = sam_mask_np \n",
    "            axes[1].imshow(original_img) \n",
    "            show_mask(mask_display, axes[1], random_color=False, borders=True) \n",
    "            axes[1].set_title(f'Máscara SAM {mask_idx}')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            if object_feature_map_tensor.numel() == 0:\n",
    "                axes[2].text(0.5, 0.5, \"No hay características de objeto\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                axes[2].set_title('Mapa de Características de Objeto (Vacío)')\n",
    "                axes[2].axis('off')\n",
    "            else:\n",
    "                ofm_cpu = object_feature_map_tensor.squeeze().cpu().numpy() \n",
    "                if ofm_cpu.ndim == 3: \n",
    "                    C, H, W = ofm_cpu.shape\n",
    "                    ofm_reshaped = ofm_cpu.transpose(1, 2, 0).reshape(-1, C) \n",
    "\n",
    "                    if C > 3: \n",
    "                        pca = PCA(n_components=3)\n",
    "                        ofm_pca = pca.fit_transform(ofm_reshaped)\n",
    "                        ofm_pca_normalized = (ofm_pca - ofm_pca.min()) / (ofm_pca.max() - ofm_pca.min() + 1e-8)\n",
    "                        ofm_display = ofm_pca_normalized.reshape(H, W, 3)\n",
    "                        axes[2].imshow(ofm_display)\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto (PCA)\\nMáscara {mask_idx}')\n",
    "                    else: \n",
    "                        if C == 1:\n",
    "                            ofm_display = ofm_cpu.squeeze()\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        elif C == 3:\n",
    "                            ofm_display = ofm_cpu.transpose(1, 2, 0) \n",
    "                            ofm_display_norm = (ofm_display - ofm_display.min()) / (ofm_display.max() - ofm_display.min() + 1e-8)\n",
    "                            axes[2].imshow(ofm_display_norm)\n",
    "                        else: \n",
    "                            ofm_display = ofm_cpu[0]\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto\\nMáscara {mask_idx}')\n",
    "                else: \n",
    "                    axes[2].text(0.5, 0.5, \"Formato de características de objeto inesperado\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                    axes[2].set_title('Mapa de Características de Objeto (Error)')\n",
    "\n",
    "                axes[2].axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{plot_filename_prefix}_mask_{mask_idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al visualizar el mapa de características de objeto para máscara {mask_idx} de {os.path.basename(original_image_path)}: {e}\")\n",
    "\n",
    "    # --- Aplicar el proceso a la imagen de consulta y a las imágenes de referencia ---\n",
    "\n",
    "    print(\"\\n--- Generando Mapas de Características de Objeto ---\")\n",
    "\n",
    "    TARGET_MASK_H = 8 * H_prime \n",
    "    TARGET_MASK_W = 8 * W_prime \n",
    "    print(f\"TARGET_MASK_H: {TARGET_MASK_H}\")\n",
    "    print(f\"TARGET_MASK_W: {TARGET_MASK_W}\")\n",
    "\n",
    "    fobj_q, scaled_masks_query = process_masks_to_object_feature_maps(\n",
    "        masks_data_query_image,\n",
    "        query_hr_feats.squeeze(0), \n",
    "        TARGET_MASK_H,\n",
    "        TARGET_MASK_W,\n",
    "        image_for_sam_np.shape \n",
    "    )\n",
    "\n",
    "    fobj_q = fobj_q.to(device)\n",
    "\n",
    "    print(f\"Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): {fobj_q.shape}\") \n",
    "\n",
    "    all_fobj_r_list = [] \n",
    "    for i, similar_hr_feats in enumerate(similar_hr_feats_list):\n",
    "        current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "        img_similar_pil = Image.open(rutas_imagenes_similares[i]).convert('RGB') \n",
    "        image_np_similar_for_sam_shape = np.array(img_similar_pil).shape\n",
    "\n",
    "        fobj_r_current, scaled_masks_similar = process_masks_to_object_feature_maps(\n",
    "            current_similar_masks_raw,\n",
    "            similar_hr_feats.squeeze(0), \n",
    "            TARGET_MASK_H,\n",
    "            TARGET_MASK_W,\n",
    "            image_np_similar_for_sam_shape \n",
    "        )\n",
    "        fobj_r_current = fobj_r_current.to(device)\n",
    "        \n",
    "        all_fobj_r_list.append(fobj_r_current)\n",
    "        print(f\"Dimensiones de fobj_r para vecino {i+1}: {fobj_r_current.shape}\") \n",
    "        print(\"\\nTipos de los elementos en all_fobj_r_list:\")\n",
    "        for idx, fobj_r in enumerate(all_fobj_r_list):\n",
    "            print(f\"Vecino {idx + 1}: Tipo de fobj_r:\", type(fobj_r))\n",
    "    print(\"\\nProceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\")\n",
    "\n",
    "\n",
    "    # -----------3.5.2 Object matching module-----------------\n",
    "    ## Matching\n",
    "    # --- Definición de la función show_anomalies_on_image ---\n",
    "    def show_anomalies_on_image(image_np, masks, anomalous_info, alpha=0.5, save_path=None):\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image_np)\n",
    "\n",
    "        for obj_id, similarity in anomalous_info: # Iterate through (id, similarity) tuples\n",
    "            # Extraer la máscara binaria real\n",
    "            mask = masks[obj_id]['segmentation']\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "\n",
    "            # Crear máscara en rojo\n",
    "            colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "            colored_mask[mask > 0] = [255, 0, 0]\n",
    "            plt.imshow(colored_mask, alpha=alpha)\n",
    "\n",
    "            # Calcular centroide para colocar el texto\n",
    "            ys, xs = np.where(mask > 0)\n",
    "            if len(xs) > 0 and len(ys) > 0:\n",
    "                cx = int(xs.mean())\n",
    "                cy = int(ys.mean())\n",
    "                \n",
    "                # Create text with index and percentage\n",
    "                text_label = f\"{obj_id} ({similarity*100:.2f}%)\"\n",
    "                plt.text(cx, cy, text_label, color='white', fontsize=10, fontweight='bold', ha='center', va='center',\n",
    "                        bbox=dict(facecolor='red', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "        plt.title(\"Objetos Anómalos en Rojo con Índice y Similitud\") # Updated title for clarity\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de anomalías guardado en: {save_path}\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    # --- Fin de la definición de la función show_anomalies_on_image ---\n",
    "    # --- Nuevas funciones de ploteo para la matriz P y P_augmented_full ---\n",
    "    def plot_assignment_matrix(P_matrix, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación P\"):\n",
    "\n",
    "        if isinstance(P_matrix, torch.Tensor):\n",
    "            #P_matrix = P_matrix.cpu().numpy()\n",
    "            P_matrix = P_matrix.detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(P_matrix.shape[1] * 0.8 + 2, P_matrix.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_matrix, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(reference_labels)), reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(query_labels)), query_labels)\n",
    "        plt.xlabel('Objetos de Referencia')\n",
    "        plt.ylabel('Objetos de Consulta')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_augmented_assignment_matrix(P_augmented_full, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación Aumentada (con Trash Bin)\"):\n",
    "\n",
    "        if isinstance(P_augmented_full, torch.Tensor):\n",
    "            #P_augmented_full = P_augmented_full.cpu().numpy()\n",
    "            P_augmented_full = P_augmented_full.detach().cpu().numpy()\n",
    "\n",
    "        # Añadir etiquetas para los trash bins\n",
    "        full_query_labels = [f\"Q_{i}\" for i in query_labels] + [\"Trash Bin (Q)\"]\n",
    "        full_reference_labels = [f\"R_{i}\" for i in reference_labels] + [\"Trash Bin (R)\"]\n",
    "\n",
    "        plt.figure(figsize=(P_augmented_full.shape[1] * 0.8 + 2, P_augmented_full.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_augmented_full, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(full_reference_labels)), full_reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(full_query_labels)), full_query_labels)\n",
    "        plt.xlabel('Objetos de Referencia y Trash Bin')\n",
    "        plt.ylabel('Objetos de Consulta y Trash Bin')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación aumentada guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# --- Fin de las nuevas funciones de ploteo ---\n",
    "\n",
    "    ## Matching-continue---\n",
    "    ## Matching\n",
    "    start_time_sam_matching = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    def apply_global_max_pool(feat_map):\n",
    "        return F.adaptive_max_pool2d(feat_map, output_size=1).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    class SimpleObjectMatchingModule(nn.Module):\n",
    "        def __init__(self, sinkhorn_iterations=100, sinkhorn_epsilon=0.1, bin_score_value=0.5):\n",
    "            super(SimpleObjectMatchingModule, self).__init__()\n",
    "            self.sinkhorn_iterations = sinkhorn_iterations\n",
    "            self.sinkhorn_epsilon = sinkhorn_epsilon\n",
    "            self.z = nn.Parameter(torch.tensor(bin_score_value, dtype=torch.float32))\n",
    "\n",
    "        def forward(self, d_M_q, d_N_r):\n",
    "            M = d_M_q.shape[0]\n",
    "            N = d_N_r.shape[0]\n",
    "\n",
    "            if M == 0 or N == 0:\n",
    "                return torch.empty(M, N, device=d_M_q.device), \\\n",
    "                    torch.empty(M+1, N+1, device=d_M_q.device)\n",
    "\n",
    "            score_matrix = torch.mm(d_M_q, d_N_r.T)\n",
    "            #print(\"score_matrix (antes de Sinkhorn):\\n\", score_matrix)\n",
    "\n",
    "            S_augmented = torch.zeros((M + 1, N + 1), device=d_M_q.device, dtype=d_M_q.dtype)\n",
    "            S_augmented[:M, :N] = score_matrix\n",
    "            S_augmented[:M, N] = self.z\n",
    "            S_augmented[M, :N] = self.z\n",
    "            S_augmented[M, N] = self.z\n",
    "            print(\"S_augmented antes de Sinkhorn:\\n\", S_augmented)\n",
    "\n",
    "            K = torch.exp(S_augmented / self.sinkhorn_epsilon)\n",
    "            print(\"K (antes de Sinkhorn):\\n\", K)\n",
    "            \n",
    "\n",
    "            for i in range(self.sinkhorn_iterations):\n",
    "                K = K / K.sum(dim=1, keepdim=True)\n",
    "                K = K / K.sum(dim=0, keepdim=True)\n",
    "                #print(f\"Iteración {i+1}: K.shape = {K}\")\n",
    "\n",
    "            P_augmented_full = K\n",
    "            P = P_augmented_full[:M, :N]\n",
    "\n",
    "            return P, P_augmented_full\n",
    "\n",
    "    if fobj_q.shape[0] == 0:\n",
    "        print(\"Advertencia: fobj_q tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "        continue\n",
    "\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        if fobj_r_current.shape[0] == 0:\n",
    "            print(\"Advertencia: fobj_r_current tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "            continue\n",
    "    \n",
    "    fobj_q_pooled = apply_global_max_pool(fobj_q)\n",
    "    print(\"Shape de fobj_q_pooled:\", fobj_q_pooled.shape)\n",
    "    print(\"Máximo de fobj_q_pooled:\", torch.max(fobj_q_pooled).item())\n",
    "    print(\"Mínimo de fobj_q_pooled:\", torch.min(fobj_q_pooled).item())\n",
    "\n",
    "    all_fobj_r_pooled_list = []\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        pooled_r = apply_global_max_pool(fobj_r_current)\n",
    "        all_fobj_r_pooled_list.append(pooled_r)\n",
    "        \n",
    "    d_M_q = F.normalize(fobj_q_pooled, p=2, dim=1) #shape (M, C)\n",
    "    d_N_r_list = [F.normalize(fobj_r_pooled, p=2, dim=1) \n",
    "                                for fobj_r_pooled in all_fobj_r_pooled_list]\n",
    "    print(\"Máximo de d_M_q:\", torch.max(d_M_q).item())\n",
    "    print(\"Mínimo de d_M_q:\", torch.min(d_M_q).item())\n",
    "\n",
    "    object_matching_module = SimpleObjectMatchingModule(\n",
    "        sinkhorn_iterations=100,\n",
    "        sinkhorn_epsilon=0.1,\n",
    "        bin_score_value=0.9 #2.36\n",
    "    ).to(device)\n",
    "\n",
    "    P_matrices = []\n",
    "    P_augmented_full_matrices = []\n",
    "\n",
    "    for i, d_N_r_current_image in enumerate(d_N_r_list):\n",
    "        d_M_q_cuda = d_M_q.to(device)\n",
    "        d_N_r_current_image_cuda = d_N_r_current_image.to(device)\n",
    "\n",
    "        P_current, P_augmented_current = object_matching_module(d_M_q_cuda, d_N_r_current_image_cuda)\n",
    "        P_matrices.append(P_current)\n",
    "        P_augmented_full_matrices.append(P_augmented_current)\n",
    "\n",
    "\n",
    "    print(\"\\n--- Matrices P y P_augmented_full generadas ---\")\n",
    "    # --- NUEVOS DICCIONARIOS CONSOLIDADOS ---\n",
    "    # Almacenarán para cada query_idx, las referencias que le corresponden de TODOS los vecinos.\n",
    "    M = d_M_q.shape[0]\n",
    "    all_matched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)} # M es el número de objetos de consulta (Iq)\n",
    "    all_closest_unmatched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)}\n",
    "    # Imprimir shapes de los diccionarios consolidados\n",
    "    #//////\n",
    "    print(\"\\n--- Resultados Consolidados ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {closest_unmatches}\")\n",
    "    #/////////////////\n",
    "    # Procesar matrices P y P_augmented_full para obtener índices\n",
    "    for i, (P, P_augmented_full) in enumerate(zip(P_matrices, P_augmented_full_matrices)):\n",
    "        current_neighbor_key = f\"Vecino_{i+1}\"\n",
    "        N_current = P.shape[1] \n",
    "\n",
    "        print(f\"\\n--- Vecino {current_neighbor_key} ---\")\n",
    "        print(f\"Matriz P (MxN) para el vecino {current_neighbor_key}:\")\n",
    "        print(P)\n",
    "        print(f\"Matriz P_augmented_full (M+1 x N+1) para el vecino {current_neighbor_key}:\")\n",
    "        print(P_augmented_full)\n",
    "\n",
    "        # Imprimir sumas de filas y columnas de P_augmented_full\n",
    "        augmented_with_totals = torch.cat([\n",
    "            torch.cat([P_augmented_full, P_augmented_full.sum(dim=0, keepdim=True)], dim=0),\n",
    "            torch.cat([P_augmented_full.sum(dim=1, keepdim=True), P_augmented_full.sum().unsqueeze(0).unsqueeze(0)], dim=0)\n",
    "        ], dim=1)\n",
    "        print(f\"Matriz P_augmented_full con totales (M+2 x N+2):\\n{augmented_with_totals}\")\n",
    "\n",
    "        print(f\"\\n--- Decisiones de Emparejamiento para el Vecino {current_neighbor_key} ---\")\n",
    "        for obj_idx in range(P.shape[0]):\n",
    "            \n",
    "            # Obtener la probabilidad más alta dentro de P y su índice\n",
    "            if N_current > 0:\n",
    "                max_prob_P = P[obj_idx].max().item()\n",
    "                max_idx_P = P[obj_idx].argmax().item()\n",
    "            else:\n",
    "                max_prob_P = -float('inf')\n",
    "                max_idx_P = -1\n",
    "\n",
    "            trash_bin_prob = P_augmented_full[obj_idx, -1].item() \n",
    "\n",
    "            print(f\"   Objeto de Consulta {obj_idx}:\")\n",
    "            print(f\"     Probabilidad máxima en P: {max_prob_P:.4f} en el índice {max_idx_P}\")\n",
    "            print(f\"     Probabilidad en el 'Trash Bin': {trash_bin_prob:.4f}\")\n",
    "\n",
    "\n",
    "        # Decisión y almacenamiento en los diccionarios consolidados\n",
    "            if trash_bin_prob > max_prob_P:\n",
    "                # Desemparejado: ahora añadimos el 'primer máximo' a la lista de ese objeto de consulta\n",
    "                if max_idx_P != -1: # Solo añadir si hay un 'primer máximo' válido\n",
    "                    all_closest_unmatched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto {max_idx_P}\")\n",
    "            else:\n",
    "                # Emparejado: añadir el emparejamiento real a la lista de ese objeto de consulta\n",
    "                all_matched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: EMPAREJADO con objeto de imagen {max_idx_P}\")\n",
    "\n",
    "\n",
    "    # --- Resultados Finales Consolidados ---\n",
    "    print(\"\\n--- Resultados Finales Consolidados (Índices) ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {closest_unmatches}\")\n",
    "\n",
    "\n",
    "    # --- AHORA SE NECESITAN ESTOS DICTIONARIOS PARA TU IMPLEMENTACIÓN DE MAHALANOBIS ---\n",
    "\n",
    "    print(\"--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\")\n",
    "    # ***************************************************************************************************\n",
    "    ## AUROC\n",
    "    # --- Acumuladores para AUROC Global (Nivel de Imagen) ---\n",
    "    # Estas listas acumularán las etiquetas verdaderas y las puntuaciones de anomalía\n",
    "    # de todas las imágenes para calcular el AUROC global a nivel de imagen al final.\n",
    "    global_image_true_labels = []\n",
    "    global_image_anomaly_scores = []\n",
    "\n",
    "    # Function to compute Mahalanobis distance map for a single query feature map\n",
    "    @torch.no_grad()\n",
    "    def compute_mahalanobis_map_single(query_fmap, ref_fmaps, regularization=1e-5, pixel_batch_size=4096):\n",
    "        device = query_fmap.device\n",
    "        k = len(ref_fmaps)\n",
    "        C, H, W = query_fmap.shape\n",
    "\n",
    "        if k < 2:  # Need at least 2 references for covariance calculation\n",
    "            return torch.zeros(H, W, device=device, dtype=torch.float32)\n",
    "\n",
    "        # Cast to float32 for stable matrix inversion\n",
    "        query_fmap_float32 = query_fmap.to(torch.float32)\n",
    "        ref_fmaps_float32 = [fmap.to(torch.float32) for fmap in ref_fmaps]\n",
    "\n",
    "        ref_stack = torch.stack(ref_fmaps_float32, dim=0).permute(0, 2, 3, 1)\n",
    "        query_fmap_permuted = query_fmap_float32.permute(1, 2, 0)\n",
    "\n",
    "        N_pixels = H * W\n",
    "        ref_vectors_flat = ref_stack.reshape(k, N_pixels, C)\n",
    "        query_vectors_flat = query_fmap_permuted.reshape(N_pixels, C)\n",
    "\n",
    "        mu = ref_vectors_flat.mean(dim=0)\n",
    "        \n",
    "        maha_map_flat = torch.zeros(N_pixels, device=device, dtype=torch.float32)\n",
    "\n",
    "        # Process pixels in batches to manage memory\n",
    "        for i in range(0, N_pixels, pixel_batch_size):\n",
    "            end_idx = min(i + pixel_batch_size, N_pixels)\n",
    "            current_pixel_batch_size = end_idx - i\n",
    "\n",
    "            mu_batch = mu[i:end_idx]\n",
    "            query_vectors_flat_batch = query_vectors_flat[i:end_idx]\n",
    "            \n",
    "            delta_batch = ref_vectors_flat[:, i:end_idx, :] - mu_batch.unsqueeze(0)\n",
    "\n",
    "            delta_reshaped_batch = delta_batch.permute(1, 0, 2)\n",
    "\n",
    "            cov_batch = (delta_reshaped_batch.transpose(-1, -2) @ delta_reshaped_batch) / (k - 1)\n",
    "            \n",
    "            cov_batch += regularization * torch.eye(C, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            try:\n",
    "                cov_inv_batch = torch.linalg.inv(cov_batch)\n",
    "            except RuntimeError as e:\n",
    "                # If inversion fails for a batch, fill with zeros\n",
    "                maha_map_flat[i:end_idx] = 0.0\n",
    "                continue\n",
    "\n",
    "            diff_batch = query_vectors_flat_batch - mu_batch\n",
    "\n",
    "            maha_val_squared_batch = (diff_batch.unsqueeze(1) @ cov_inv_batch @ diff_batch.unsqueeze(2)).squeeze()\n",
    "            \n",
    "            maha_map_flat[i:end_idx] = torch.sqrt(torch.relu(maha_val_squared_batch))\n",
    "\n",
    "            # Clear memory\n",
    "            del mu_batch, query_vectors_flat_batch, delta_batch, delta_reshaped_batch, cov_batch, cov_inv_batch, diff_batch, maha_val_squared_batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        maha_map = maha_map_flat.reshape(H, W)\n",
    "\n",
    "        return maha_map\n",
    "    \n",
    "    # Function to compute Mahalanobis score maps for matched query objects\n",
    "    @torch.no_grad()\n",
    "    def compute_matching_score_map(\n",
    "        fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        matching_maha_maps = []\n",
    "        all_raw_maha_values = [] \n",
    "        \n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx]\n",
    "            device = query_fmap.device\n",
    "\n",
    "            matched_ref_fmaps_list = []\n",
    "            for neighbor_idx, ref_idx in all_matched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                matched_ref_fmaps_list.append(ref_fmap)\n",
    "                \n",
    "             # Manejo de los casos de referencias\n",
    "            if len(matched_ref_fmaps_list) == 0:\n",
    "                # Caso: Cero referencias. Asigna un valor muy alto para indicar \"no coincidencia\".\n",
    "                # Asegúrate que la forma del tensor sea (H, W) si eso es lo que esperas.\n",
    "                map_H, map_W = query_fmap.shape[1], query_fmap.shape[2] # Asumiendo query_fmap es (C, H, W)\n",
    "                #max_val = float('inf') \n",
    "                #maha_map_raw = torch.full((map_H, map_W), max_val, device=device)\n",
    "                       \n",
    "                # If there are no closest unmatched references, consider the anomaly score to be 0\n",
    "                maha_map_raw = torch.zeros((map_H, map_W), device=device)\n",
    "                \n",
    "            elif len(matched_ref_fmaps_list) == 1:\n",
    "                # Caso: Una sola referencia. Duplicar para permitir el cálculo de covarianza.\n",
    "                single_ref_fmap = matched_ref_fmaps_list[0]\n",
    "                # Creamos una lista con la referencia duplicada\n",
    "                effective_ref_fmaps = [single_ref_fmap, single_ref_fmap] \n",
    "                \n",
    "                maha_map_raw = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=effective_ref_fmaps, # Usamos la lista duplicada\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "                \n",
    "            else: # len(matched_ref_fmaps_list) >= 2\n",
    "                # Caso: Múltiples referencias (dos o más). Calcula Mahalanobis normalmente.\n",
    "                maha_map_raw = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=matched_ref_fmaps_list, # Usamos la lista original\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            \n",
    "            all_raw_maha_values.append(maha_map_raw.flatten().cpu()) \n",
    "            matching_maha_maps.append(maha_map_raw.cpu())\n",
    "\n",
    "            # Save plot for individual maps\n",
    "            if plot_save_dir:\n",
    "                plt.figure(figsize=(6, 5))\n",
    "                maha_map_for_plot = matching_maha_maps[-1]\n",
    "                if maha_map_for_plot.max() > 1e-8:\n",
    "                    plot_normalized_maha = (maha_map_for_plot - maha_map_for_plot.min()) / (maha_map_for_plot.max() - maha_map_for_plot.min() + 1e-8)\n",
    "                else:\n",
    "                    plot_normalized_maha = torch.zeros_like(maha_map_for_plot)\n",
    "                plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                plt.title(f\"Matching Score Map (Normalized for Plot) - Obj {query_idx}\")\n",
    "                plt.axis(\"off\")\n",
    "                plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                plt.tight_layout()\n",
    "                save_path = os.path.join(plot_save_dir, f\"matching_score_raw_obj_{query_idx}.png\")\n",
    "                plt.savefig(save_path)\n",
    "                plt.close()\n",
    "\n",
    "        # Calculate global min/max for raw Mahalanobis values\n",
    "        global_min_maha = 0.0\n",
    "        global_max_maha = 1.0\n",
    "\n",
    "        if all_raw_maha_values:\n",
    "            combined_raw_values = torch.cat(all_raw_maha_values)\n",
    "            global_min_maha = combined_raw_values.min().item()\n",
    "            global_max_maha = combined_raw_values.max().item()\n",
    "            if global_max_maha <= global_min_maha:\n",
    "                global_max_maha = global_min_maha + 1e-8 \n",
    "\n",
    "        return matching_maha_maps, (global_min_maha, global_max_maha)\n",
    "\n",
    "    # Function to compute Mahalanobis score maps for unmatched query objects\n",
    "    @torch.no_grad()\n",
    "    def compute_unmatched_score_map(\n",
    "        fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        all_matched_ref_indices_by_query_obj=None,\n",
    "        matched_maha_range_global=(0.0, 1.0),\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        \n",
    "        unmatched_maha_maps = []\n",
    "\n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx] \n",
    "            device = query_fmap.device\n",
    "            map_H, map_W = query_fmap.shape[1], query_fmap.shape[2] \n",
    "\n",
    "            # matched_refs = all_matched_ref_indices_by_query_obj.get(query_idx, []) if all_matched_ref_indices_by_query_obj else []\n",
    "            \n",
    "            # if len(matched_refs) >= 2: \n",
    "            #     unmatched_maha_maps.append(torch.zeros((map_H, map_W), device=device).cpu())\n",
    "            #     continue \n",
    "\n",
    "            closest_ref_fmaps = []\n",
    "            for neighbor_idx, ref_idx in all_closest_unmatched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap_closest = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                closest_ref_fmaps.append(ref_fmap_closest)\n",
    "\n",
    "            if len(closest_ref_fmaps) == 0:\n",
    "                # If there are no closest unmatched references, consider the anomaly score to be 0\n",
    "                maha_map_to_return = torch.zeros((map_H, map_W), device=device)\n",
    "                \n",
    "            elif len(closest_ref_fmaps) == 1:\n",
    "                single_ref_fmap = closest_ref_fmaps[0]\n",
    "                effective_ref_fmaps = [single_ref_fmap, single_ref_fmap] \n",
    "                \n",
    "                maha_map_to_return = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=effective_ref_fmaps, \n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                maha_map_to_return = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=closest_ref_fmaps,\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            \n",
    "            unmatched_maha_maps.append(maha_map_to_return.cpu())\n",
    "\n",
    "            # Save plot for individual maps\n",
    "            if plot_save_dir:\n",
    "                plt.figure(figsize=(6, 5))\n",
    "                maha_map_for_plot = unmatched_maha_maps[-1]\n",
    "                if maha_map_for_plot.max() > 1e-8:\n",
    "                    plot_normalized_maha = (maha_map_for_plot - maha_map_for_plot.min()) / (maha_map_for_plot.max() - maha_map_for_plot.min() + 1e-8)\n",
    "                else:\n",
    "                    plot_normalized_maha = torch.zeros_like(maha_map_for_plot)\n",
    "                plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                plt.title(f\"Unmatched Anomaly Map (Normalized for Plot) - Obj {query_idx}\")\n",
    "                plt.axis(\"off\")\n",
    "                plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                plt.tight_layout()\n",
    "                save_path = os.path.join(plot_save_dir, f\"unmatched_anomaly_raw_obj_{query_idx}.png\")\n",
    "                plt.savefig(save_path)\n",
    "                plt.close()\n",
    "\n",
    "        return unmatched_maha_maps\n",
    "\n",
    "    # Function to build an aggregated (global) score map\n",
    "    @torch.no_grad()\n",
    "    def build_aggregated_score_map(individual_score_maps_list, final_size=(1024, 1024), title_prefix=\"Global Score Map\", plot_save_dir=None, filename_prefix=\"global_score_map\"):\n",
    "\n",
    "        H_out, W_out = final_size\n",
    "        aggregated_score_map = torch.zeros((H_out, W_out), device='cpu') \n",
    "\n",
    "        if not individual_score_maps_list:\n",
    "            return aggregated_score_map\n",
    "        \n",
    "        for i, score_map in enumerate(individual_score_maps_list):\n",
    "            if score_map.dim() == 2:\n",
    "                score_map_tensor = score_map.unsqueeze(0).unsqueeze(0)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Resize on GPU for efficiency, then move back to CPU for summation\n",
    "            score_resized = F.interpolate(\n",
    "                score_map_tensor.to('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "                size=(H_out, W_out),\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            ).squeeze().cpu()\n",
    "            #aggregated_score_map += score_resized\n",
    "            \n",
    "            # CAMBIO CLAVE AQUÍ: Usar torch.max en lugar de +=\n",
    "            aggregated_score_map = torch.max(aggregated_score_map, score_resized)\n",
    "\n",
    "        # Después del bucle, si inicializaste con -inf, asegúrate de que los ceros se mantengan para áreas sin anomalía\n",
    "        aggregated_score_map[aggregated_score_map == -torch.inf] = 0.0\n",
    "\n",
    "        # Save plot for the aggregated map\n",
    "        if plot_save_dir:\n",
    "            plt.figure(figsize=(8, 7))\n",
    "            map_for_plot = aggregated_score_map\n",
    "            if map_for_plot.max() > 1e-8:\n",
    "                plot_normalized_map = (map_for_plot - map_for_plot.min()) / (map_for_plot.max() - map_for_plot.min() + 1e-8)\n",
    "            else:\n",
    "                plot_normalized_map = torch.zeros_like(map_for_plot)\n",
    "\n",
    "            plt.imshow(plot_normalized_map.numpy(), cmap=\"hot\")\n",
    "            plt.title(title_prefix + \" (Normalized for Plot)\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Score Acumulado (Normalized for display)\")\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_prefix}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "\n",
    "        return aggregated_score_map\n",
    "\n",
    "    # Function to overlay the anomaly map on the original image\n",
    "    def overlay_anomaly_map_on_image(image_rgb_path, anomaly_map, alpha=0.7, cmap='magma', plot_save_dir=None, filename_suffix=\"overlay\"):\n",
    "        try:\n",
    "            image_original_loaded = Image.open(image_rgb_path).convert(\"RGB\")\n",
    "            image_np = np.array(image_original_loaded)\n",
    "        except FileNotFoundError:\n",
    "            return\n",
    "\n",
    "        if isinstance(anomaly_map, torch.Tensor):\n",
    "            anomaly_np = anomaly_map.cpu().numpy()\n",
    "        else:\n",
    "            anomaly_np = anomaly_map\n",
    "\n",
    "        # Normalize map for visualization purposes\n",
    "        anomaly_min = anomaly_np.min()\n",
    "        anomaly_max = anomaly_np.max()\n",
    "        if (anomaly_max - anomaly_min) < 1e-8:\n",
    "            anomaly_norm = np.zeros_like(anomaly_np)\n",
    "        else:\n",
    "            anomaly_norm = (anomaly_np - anomaly_min) / (anomaly_max - anomaly_min)\n",
    "\n",
    "        # Resize map to match original image dimensions\n",
    "        if anomaly_norm.shape[:2] != image_np.shape[:2]:\n",
    "            anomaly_norm = np.array(Image.fromarray(anomaly_norm).resize(\n",
    "                (image_np.shape[1], image_np.shape[0]), resample=Image.BILINEAR\n",
    "            ))\n",
    "\n",
    "        # Plot overlay\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(image_np)\n",
    "        plt.imshow(anomaly_norm, cmap=cmap, alpha=alpha)\n",
    "        plt.title(\"Anomaly Heatmap Overlay (Normalized for Display)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if plot_save_dir:\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_suffix}.png\")\n",
    "            plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    # --- Main script execution ---\n",
    "    print(\"pre1\")\n",
    "    # Move feature objects to CUDA\n",
    "    if isinstance(fobj_q, list):\n",
    "        fobj_q = [fmap.to('cuda') for fmap in fobj_q]\n",
    "    else:\n",
    "        fobj_q = fobj_q.to('cuda')\n",
    "\n",
    "    all_fobj_r_list_gpu = []\n",
    "    for inner_list in all_fobj_r_list:\n",
    "        all_fobj_r_list_gpu.append([fmap.to('cuda') for fmap in inner_list])\n",
    "\n",
    "    all_fobj_r_list = all_fobj_r_list_gpu\n",
    "    print(\"preparando\")\n",
    "    # Clear CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"pre2\")\n",
    "    # --- Step 1: Compute Matching Score Maps ---\n",
    "    all_matching_score_maps, matched_maha_range_global = compute_matching_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        pixel_batch_size=4096\n",
    "        )\n",
    "\n",
    "    # --- Step 2: Compute Unmatched Score Maps ---\n",
    "    all_unmatched_score_maps = compute_unmatched_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj=all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "        matched_maha_range_global=matched_maha_range_global,\n",
    "        pixel_batch_size=4096\n",
    "    )\n",
    "\n",
    "    # Get original image dimensions for global maps\n",
    "    image_original = Image.open(query_image_path)\n",
    "    H, W = image_original.size\n",
    "\n",
    "    # --- Step 3: Build Global Matched Score Map ---\n",
    "    global_matched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_matching_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Matched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_matched_anomaly_raw\")\n",
    "\n",
    "    # --- Step 4: Build Global Unmatched Score Map ---\n",
    "    global_unmatched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_unmatched_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Unmatched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_unmatched_anomaly_raw\")\n",
    "\n",
    "    # --- Step 5: Combine individual matched and unmatched maps for a total map ---\n",
    "    combined_individual_score_maps = []\n",
    "    num_queries = len(fobj_q)\n",
    "    for i in range(num_queries):\n",
    "        matched_map_for_query = all_matching_score_maps[i] if i < len(all_matching_score_maps) else torch.zeros((H, W), device='cpu')\n",
    "        unmatched_map_for_query = all_unmatched_score_maps[i] if i < len(all_unmatched_score_maps) else torch.zeros((H, W), device='cpu')\n",
    "        \n",
    "        combined_map_for_query_i = matched_map_for_query + unmatched_map_for_query\n",
    "        combined_individual_score_maps.append(combined_map_for_query_i)\n",
    "                # --- ADD THESE DEBUG PRINTS ---\n",
    "        print(f\"Query {i}:\")\n",
    "        print(f\"  Shape of matched_map_for_query: {matched_map_for_query.shape}, Max: {matched_map_for_query.max().item():.4f}\")\n",
    "        print(f\"  Shape of unmatched_map_for_query: {unmatched_map_for_query.shape}, Max: {unmatched_map_for_query.max().item():.4f}\")\n",
    "        print(f\"  Shape of combined_map_for_query_i: {combined_map_for_query_i.shape}, Max: {combined_map_for_query_i.max().item():.4f}\")\n",
    "        # --- END DEBUG PRINTS ---\n",
    "\n",
    "    # --- Step 6: Build Global Total Anomaly Score Map ---\n",
    "        # --- ADD THIS DEBUG PRINT ---\n",
    "    print(f\"Number of maps in combined_individual_score_maps: {len(combined_individual_score_maps)}\")\n",
    "    if combined_individual_score_maps:\n",
    "        all_max_values = [m.max().item() for m in combined_individual_score_maps]\n",
    "        print(f\"Max values across all combined_individual_score_maps: {all_max_values}\")\n",
    "    # --- END DEBUG PRINT ---\n",
    "    global_total_anomaly_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=combined_individual_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Total Anomaly Map (Sum of RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_total_anomaly_raw\")\n",
    "\n",
    "    # --- Step 7: Overlay global maps on the original image ---\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_matched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_matched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_unmatched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_unmatched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_total_anomaly_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_total_anomaly_overlay_raw\")\n",
    "\n",
    "    # --- Step 8: Save the final total score map as a .npy file ---\n",
    "    score_map_filename = f\"maha_{base_image_name}.npy\"\n",
    "    score_map_save_path = os.path.join(MAHALANOBIS_SCORE_MAPS_DIR, score_map_filename)\n",
    "\n",
    "    score_map_to_save = global_total_anomaly_score_map.cpu().numpy()\n",
    "\n",
    "    np.save(score_map_save_path, score_map_to_save)\n",
    "    print(\"finalizado iteracion\")\n",
    "    end_time_total = time.time()\n",
    "    total_time = end_time_total - start_time_total\n",
    "    print(f\"Tiempo total de ejecución iteracion: {total_time:.2f} segundos\")\n",
    "print(\"finalizado\")\n",
    "end_time_global = time.time()\n",
    "total_global_time = end_time_global - start_time_global\n",
    "print(f\"Tiempo total de ejecución iteracion: {total_global_time:.2f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_featup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
