{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Detectando clases y cargando mapas de Mahalanobis ---\n",
      "  Clases detectadas: ['crack', 'cut', 'evaluacion_roc', 'good', 'hole', 'print']\n",
      "  Total de mapas cargados para 'crack': 10\n",
      "  Total de mapas cargados para 'cut': 10\n",
      "Advertencia: No se encontraron archivos .npy para la clase 'evaluacion_roc' en /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc\n",
      "  Total de mapas cargados para 'good': 10\n",
      "  Total de mapas cargados para 'hole': 10\n",
      "  Total de mapas cargados para 'print': 10\n",
      "--- Mapas cargados exitosamente ---\n",
      "\n",
      "  Clases finales para procesamiento: ['crack', 'cut', 'good', 'hole', 'print']\n",
      "--- 2. Calculando mínimos y máximos globales ---\n",
      "  Mínimo global (min_final): 0.0\n",
      "  Máximo global (max_final): 316.0980224609375\n",
      "--- Cálculo de min/max globales finalizado ---\n",
      "\n",
      "--- 3. Normalizando mapas de Mahalanobis ---\n",
      "--- Normalización de mapas finalizada ---\n",
      "\n",
      "\n",
      "Proceso completado para las clases: ['crack', 'cut', 'good', 'hole', 'print']\n",
      "\n",
      "--- 4. Evaluando a nivel de imagen para la curva ROC y preparando datos para métricas ---\n",
      "  Recolectando puntuaciones de anomalía (considerando filtrado por región) y etiquetas verdaderas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Procesando mapas de crack: 100%|██████████| 10/10 [00:00<00:00, 897.37it/s]\n",
      "    Procesando mapas de cut: 100%|██████████| 10/10 [00:00<00:00, 949.88it/s]\n",
      "    Procesando mapas de good: 100%|██████████| 10/10 [00:00<00:00, 220.52it/s]\n",
      "    Procesando mapas de hole: 100%|██████████| 10/10 [00:00<00:00, 1131.33it/s]\n",
      "    Procesando mapas de print: 100%|██████████| 10/10 [00:00<00:00, 1011.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cálculo de ROC y AUC finalizado ---\n",
      "Área Bajo la Curva (AUC): 0.9550\n",
      "\n",
      "--- 5 Umbrales 'Óptimos' detectados (basados en distancia a (0,1) en curva ROC o Youden's J) ---\n",
      "  Umbral 1: 0.4705 (TPR: 0.9500, FPR: 0.2000)\n",
      "  Umbral 2: 0.5304 (TPR: 0.8750, FPR: 0.2000)\n",
      "  Umbral 3: 0.5392 (TPR: 0.8750, FPR: 0.1000)\n",
      "  Umbral 4: 0.5565 (TPR: 0.8000, FPR: 0.1000)\n",
      "  Umbral 5: 0.5846 (TPR: 0.8000, FPR: 0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Curva ROC guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/roc_curve_image_level.png\n",
      "\n",
      "  Umbral seleccionado para visualización y métricas (mediana de umbrales óptimos): 0.4600\n",
      "\n",
      "  Recalculando predicciones binarias para métricas con umbral 0.4600...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Applying threshold for crack: 100%|██████████| 10/10 [00:00<00:00, 24.27it/s]\n",
      "    Applying threshold for cut: 100%|██████████| 10/10 [00:00<00:00, 44.15it/s]\n",
      "    Applying threshold for good: 100%|██████████| 10/10 [00:00<00:00, 102.16it/s]\n",
      "    Applying threshold for hole: 100%|██████████| 10/10 [00:00<00:00, 34.27it/s]\n",
      "    Applying threshold for print: 100%|██████████| 10/10 [00:00<00:00, 33.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Generando Matriz de Confusión Global ---\n",
      "✅ Matriz de Confusión guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/confusion_matrix_thresh_0.4600.png\n",
      "\n",
      "--- 6. Calculando, mostrando y guardando Tabla de Métricas de Rendimiento ---\n",
      "\n",
      "--- Métricas de Rendimiento a Nivel de Imagen (Umbral: 0.4600, MCC Area: 500) ---\n",
      "  Accuracy:    0.9200\n",
      "  Precision:   0.9500\n",
      "  Recall (Sensibilidad): 0.9500\n",
      "  Especificidad: 0.8000\n",
      "  F1-Score:    0.9500\n",
      "--------------------------------------------------------------------\n",
      "✅ Métricas añadidas al archivo Excel existente: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/image_level_metrics.xlsx\n",
      "\n",
      "--- 7. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\n",
      "    (Las imágenes se guardarán en: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/overlays_all_images)\n",
      "  Procesando visualizaciones para la clase: 'crack' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para crack: 100%|██████████| 10/10 [00:16<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'cut' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para cut: 100%|██████████| 10/10 [00:16<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'good' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para good: 100%|██████████| 10/10 [00:14<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'hole' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para hole: 100%|██████████| 10/10 [00:17<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'print' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para print: 100%|██████████| 10/10 [00:16<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡Se generaron 50 visualizaciones de máscaras de anomalía!\n",
      "\n",
      "¡Proceso de evaluación completado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import pandas as pd # Import pandas\n",
    "\n",
    "# --- CONFIGURACIÓN DE RUTAS ---\n",
    "BASE_MAHALANOBIS_MAPS_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion'\n",
    "BASE_IMAGE_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test' \n",
    "BASE_PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc' \n",
    "\n",
    "# Crear el directorio raíz para guardar los plots si no existe\n",
    "os.makedirs(BASE_PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- FUNCIONES DE PASOS ANTERIORES (sin cambios) ---\n",
    "def load_mahalanobis_maps(base_dir):\n",
    "    all_mahalanobis_maps = {}\n",
    "    classes = []\n",
    "    \n",
    "    print(\"--- 1. Detectando clases y cargando mapas de Mahalanobis ---\")\n",
    "    \n",
    "    for item in os.listdir(base_dir):\n",
    "        class_path = os.path.join(base_dir, item)\n",
    "        if os.path.isdir(class_path):\n",
    "            classes.append(item)\n",
    "    \n",
    "    classes.sort()\n",
    "    print(f\"  Clases detectadas: {classes}\")\n",
    "\n",
    "    map_filepaths = {} \n",
    "\n",
    "    for cls in classes:\n",
    "        class_specific_dir = os.path.join(base_dir, cls)\n",
    "        map_files = glob.glob(os.path.join(class_specific_dir, '**', '*.npy'), recursive=True)\n",
    "        \n",
    "        if not map_files:\n",
    "            print(f\"Advertencia: No se encontraron archivos .npy para la clase '{cls}' en {class_specific_dir}\")\n",
    "            all_mahalanobis_maps[cls] = []\n",
    "            map_filepaths[cls] = []\n",
    "            continue\n",
    "\n",
    "        class_maps = []\n",
    "        class_file_names = [] \n",
    "        for f_path in map_files:\n",
    "            try:\n",
    "                map_data = np.load(f_path)\n",
    "                class_maps.append(map_data)\n",
    "                \n",
    "                base_name = os.path.basename(f_path)\n",
    "                image_id = None\n",
    "                if 'maha_' in base_name: \n",
    "                    image_id = base_name.replace('maha_', '').split('.')[0]\n",
    "                elif base_name == 'global_matched_anomaly_raw.png.npy':\n",
    "                    parent_folder = os.path.basename(os.path.dirname(f_path))\n",
    "                    if parent_folder.isdigit():\n",
    "                        image_id = parent_folder\n",
    "                \n",
    "                if image_id:\n",
    "                    class_file_names.append(image_id)\n",
    "                else:\n",
    "                    class_maps.pop() \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error al cargar {f_path}: {e}\")\n",
    "        all_mahalanobis_maps[cls] = class_maps\n",
    "        map_filepaths[cls] = class_file_names \n",
    "        print(f\"  Total de mapas cargados para '{cls}': {len(class_maps)}\")\n",
    "    print(\"--- Mapas cargados exitosamente ---\\n\")\n",
    "    return all_mahalanobis_maps, classes, map_filepaths \n",
    "\n",
    "def find_global_min_max(mahalanobis_maps_dict):\n",
    "    all_min_values = []\n",
    "    all_max_values = []\n",
    "\n",
    "    print(\"--- 2. Calculando mínimos y máximos globales ---\")\n",
    "    for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "        if not maps_list:\n",
    "            continue\n",
    "        for map_array in maps_list:\n",
    "            all_min_values.append(np.min(map_array))\n",
    "            all_max_values.append(np.max(map_array))\n",
    "    \n",
    "    if not all_min_values or not all_max_values:\n",
    "        print(\"Error: No se encontraron mapas para calcular min/max globales. Asegúrate de que los archivos .npy existan y las rutas sean correctas.\")\n",
    "        return None, None\n",
    "\n",
    "    min_final = np.min(all_min_values)\n",
    "    max_final = np.max(all_max_values)\n",
    "    \n",
    "    print(f\"  Mínimo global (min_final): {min_final}\")\n",
    "    print(f\"  Máximo global (max_final): {max_final}\")\n",
    "    print(\"--- Cálculo de min/max globales finalizado ---\\n\")\n",
    "    return min_final, max_final\n",
    "\n",
    "def normalize_maps(mahalanobis_maps_dict, min_val, max_val):\n",
    "    normalized_mahalanobis_maps = {}\n",
    "    print(\"--- 3. Normalizando mapas de Mahalanobis ---\")\n",
    "    \n",
    "    if max_val == min_val:\n",
    "        print(\"Advertencia: min_final es igual a max_final. La normalización resultará en 0 o 1.\")\n",
    "        for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "            normalized_class_maps = []\n",
    "            for map_array in maps_list:\n",
    "                normalized_map = np.full_like(map_array, 0.0, dtype=np.float32) \n",
    "                if map_array.size > 0 and map_array.max() == max_val: \n",
    "                     normalized_map = np.full_like(map_array, 1.0, dtype=np.float32)\n",
    "\n",
    "                normalized_class_maps.append(normalized_map)\n",
    "            normalized_mahalanobis_maps[cls] = normalized_class_maps\n",
    "        print(\"--- Normalización finalizada (caso especial) ---\\n\")\n",
    "        return normalized_mahalanobis_maps\n",
    "\n",
    "    for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "        normalized_class_maps = []\n",
    "        for i, map_array in enumerate(maps_list):\n",
    "            normalized_map = (map_array - min_val) / (max_val - min_val)\n",
    "            normalized_map = np.clip(normalized_map, 0, 1)\n",
    "            \n",
    "            normalized_class_maps.append(normalized_map)\n",
    "        normalized_mahalanobis_maps[cls] = normalized_class_maps\n",
    "    print(\"--- Normalización de mapas finalizada ---\\n\")\n",
    "    return normalized_mahalanobis_maps\n",
    "\n",
    "def apply_threshold_and_filter(score_map, threshold, min_area_pixels=500):\n",
    "    \"\"\"\n",
    "    Aplica un umbral al mapa de puntuación y filtra componentes conectados pequeños.\n",
    "    score_map: Mapa de puntuación normalizado (0-1).\n",
    "    threshold: Umbral (0-1).\n",
    "    min_area_pixels: Área mínima en píxeles para mantener un componente conectado.\n",
    "    Retorna la máscara binaria predicha.\n",
    "    \"\"\"\n",
    "    binary_mask = (score_map > threshold).astype(np.uint8) * 255\n",
    "\n",
    "    if np.sum(binary_mask) == 0: \n",
    "        return np.zeros_like(binary_mask)\n",
    "\n",
    "    labeled_mask = label(binary_mask) \n",
    "    filtered_mask = np.zeros_like(binary_mask)\n",
    "\n",
    "    for region in regionprops(labeled_mask):\n",
    "        if region.area >= min_area_pixels:\n",
    "            coords = region.coords\n",
    "            filtered_mask[coords[:, 0], coords[:, 1]] = 255\n",
    "    \n",
    "    return filtered_mask\n",
    "\n",
    "def classify_image_anomaly(predicted_mask):\n",
    "    \"\"\"\n",
    "    Clasifica la imagen como anómala si la máscara predicha contiene alguna región anómala (píxeles > 0).\n",
    "    \"\"\"\n",
    "    return np.sum(predicted_mask) > 0 \n",
    "\n",
    "def get_image_gt_label(class_name):\n",
    "    \"\"\"\n",
    "    Retorna la etiqueta de Ground Truth a nivel de imagen basándose en el nombre de la clase.\n",
    "    True (1) para anómalo, False (0) para normal.\n",
    "    \"\"\"\n",
    "    return 1 if class_name != 'good' else 0\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, optimal_thresholds_for_plotting, save_path, thresholds_roc_values):\n",
    "    \"\"\"\n",
    "    Grafica la curva ROC y guarda la imagen.\n",
    "    optimal_thresholds_for_plotting: Umbrales seleccionados para marcar en el gráfico (en la escala de los scores).\n",
    "    thresholds_roc_values: Los umbrales reales de roc_curve de sklearn para poder mapear puntos.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title('Curva ROC de Detección de Anomalías a Nivel de Imagen')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    if optimal_thresholds_for_plotting is not None and len(optimal_thresholds_for_plotting) > 0:\n",
    "        for opt_thresh_plot in optimal_thresholds_for_plotting:\n",
    "            # Encuentra el índice más cercano en los umbrales de la curva ROC\n",
    "            idx = np.argmin(np.abs(thresholds_roc_values - opt_thresh_plot)) \n",
    "            plt.plot(fpr[idx], tpr[idx], 'o', color='red', markersize=8) \n",
    "            plt.annotate(f'{opt_thresh_plot:.2f}', (fpr[idx], tpr[idx]), textcoords=\"offset points\", xytext=(5,-10), ha='center', color='red')\n",
    "            \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Curva ROC guardada en: {save_path}\")\n",
    "\n",
    "def visualize_overlay(image_path, score_map, threshold, min_area_pixels, save_path):\n",
    "    \"\"\"\n",
    "    Carga la imagen original, aplica el umbral y filtro al mapa de puntuación,\n",
    "    y superpone la máscara resultante sobre la imagen original.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_image = cv2.imread(image_path)\n",
    "        if original_image is None:\n",
    "            print(f\"Error: No se pudo cargar la imagen original desde {image_path}\")\n",
    "            return\n",
    "\n",
    "        original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        filtered_mask = apply_threshold_and_filter(score_map, threshold, min_area_pixels)\n",
    "\n",
    "        overlay_color = np.array([255, 0, 0], dtype=np.uint8) # Rojo\n",
    "        overlay = np.zeros_like(original_image_rgb, dtype=np.uint8)\n",
    "        overlay[filtered_mask > 0] = overlay_color\n",
    "\n",
    "        alpha = 0.4 \n",
    "        overlaid_image = cv2.addWeighted(original_image_rgb, 1 - alpha, overlay, alpha, 0)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(overlaid_image)\n",
    "        plt.title(f'Anomalía Detectada (Umbral: {threshold:.4f})\\n{os.path.basename(image_path)}') # Añadimos el nombre del archivo\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        # print(f\"✅ Imagen con superposición guardada en: {save_path}\") # Descomenta si quieres ver cada guardado\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al visualizar la superposición para {image_path}: {e}\")\n",
    "\n",
    "# --- NUEVAS FUNCIONES PARA PASOS 5 y 6 ---\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path, threshold):\n",
    "    \"\"\"\n",
    "    Calcula y grafica la matriz de confusión.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Normal (0)', 'Anómalo (1)'],\n",
    "                yticklabels=['Normal (0)', 'Anómalo (1)'])\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.title(f'Matriz de Confusión (Umbral: {threshold:.4f})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Matriz de Confusión guardada en: {save_path}\")\n",
    "\n",
    "def calculate_and_print_metrics(y_true, y_pred, threshold, min_connected_component_area): # Added min_connected_component_area\n",
    "    \"\"\"\n",
    "    Calcula y imprime las métricas de rendimiento, incluyendo Sensibilidad (Recall) y Especificidad.\n",
    "    Retorna un diccionario con las métricas.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0) \n",
    "    recall = recall_score(y_true, y_pred, zero_division=0) # Sensibilidad (Sensitivity)\n",
    "\n",
    "    # Calcular especificidad\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if cm.shape == (2,2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    else: \n",
    "        if 0 not in np.unique(y_true): \n",
    "            specificity = 0.0\n",
    "        elif 1 not in np.unique(y_true): \n",
    "            specificity = 1.0 \n",
    "        else: \n",
    "            specificity = float('nan') \n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n--- Métricas de Rendimiento a Nivel de Imagen (Umbral: {threshold:.4f}, MCC Area: {min_connected_component_area}) ---\")\n",
    "    print(f\"  Accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"  Precision:   {precision:.4f}\")\n",
    "    print(f\"  Recall (Sensibilidad): {recall:.4f}\")\n",
    "    print(f\"  Especificidad: {specificity:.4f}\")\n",
    "    print(f\"  F1-Score:    {f1:.4f}\")\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    \n",
    "    return {\n",
    "        \"Umbral\": f\"{threshold:.4f}\",\n",
    "        \"Min_Connected_Component_Area\": min_connected_component_area, # Added to dictionary\n",
    "        \"Accuracy\": f\"{accuracy:.4f}\",\n",
    "        \"Precision\": f\"{precision:.4f}\",\n",
    "        \"Recall (Sensibilidad)\": f\"{recall:.4f}\",\n",
    "        \"Especificidad\": f\"{specificity:.4f}\",\n",
    "        \"F1-Score\": f\"{f1:.4f}\"\n",
    "    }\n",
    "\n",
    "# --- EJECUCIÓN DE LOS PASOS ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar los mapas y obtener las clases detectadas y nombres de archivo\n",
    "    mahalanobis_maps, MAP_CLASSES, MAP_FILE_IDS = load_mahalanobis_maps(BASE_MAHALANOBIS_MAPS_DIR)\n",
    "\n",
    "    # Filtrar 'evaluacion_roc' de las clases detectadas si se ha colado\n",
    "    CLASSES = [cls for cls in MAP_CLASSES if cls not in ['evaluacion_roc', '']]\n",
    "    print(f\"  Clases finales para procesamiento: {CLASSES}\")\n",
    "\n",
    "\n",
    "    # Encontrar el min y max global\n",
    "    min_final_val, max_final_val = find_global_min_max(mahalanobis_maps)\n",
    "\n",
    "    if min_final_val is None or max_final_val is None:\n",
    "        print(\"No se pudo proceder con la normalización y evaluación debido a un error en el cálculo de min/max.\")\n",
    "        exit()\n",
    "\n",
    "    # Normalizar los mapas\n",
    "    normalized_mahalanobis_maps = normalize_maps(mahalanobis_maps, min_final_val, max_final_val)\n",
    "    \n",
    "    print(f\"\\nProceso completado para las clases: {CLASSES}\")\n",
    "\n",
    "    # --- PASO 4: Evaluación a Nivel de Imagen para la curva ROC y preparando datos para métricas ---\n",
    "    print(\"\\n--- 4. Evaluando a nivel de imagen para la curva ROC y preparando datos para métricas ---\")\n",
    "    \n",
    "    # We will use a consistent set of thresholds for internal scoring\n",
    "    test_thresholds_for_scoring = np.linspace(0.0, 1.0, 500) \n",
    "    MIN_CONNECTED_COMPONENT_AREA = 500\n",
    "\n",
    "    all_true_labels = [] \n",
    "    # This will be the anomaly score for ROC: higher value means higher anomaly likelihood\n",
    "    all_anomaly_scores_for_roc = [] \n",
    "    \n",
    "    print(\"  Recolectando puntuaciones de anomalía (considerando filtrado por región) y etiquetas verdaderas...\")\n",
    "    for cls in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls, [])\n",
    "        file_ids = MAP_FILE_IDS.get(cls, [])\n",
    "\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        gt_label_for_class = get_image_gt_label(cls) \n",
    "\n",
    "        for i, score_map in enumerate(tqdm(maps_list, desc=f\"    Procesando mapas de {cls}\")):\n",
    "            \n",
    "            # Here, we need a single score for each image that represents its \"anomalousness\".\n",
    "            # The simplest way is to take the MAXIMUM score from the score map, after filtering.\n",
    "            # If no anomaly region is found above any threshold, the score will be 0.\n",
    "            \n",
    "            image_max_anomaly_score = 0.0 # Default to 0 (not anomalous)\n",
    "            \n",
    "            if score_map.size > 0:\n",
    "                # Find the maximum score in the map that belongs to a connected component\n",
    "                # above a minimal size (if any part of the map would trigger a detection)\n",
    "                \n",
    "                # To get a single image-level anomaly score for ROC:\n",
    "                # Option 1: Max value of the entire map (simplest, but ignores connected components)\n",
    "                # image_max_anomaly_score = np.max(score_map)\n",
    "                \n",
    "                # Option 2: Max value of the *filtered* mask. This is more aligned with your current logic.\n",
    "                # Iterate thresholds to find the highest score that creates a significant anomaly region\n",
    "                \n",
    "                max_score_in_anom_region = 0.0\n",
    "                \n",
    "                # Iterate from high thresholds to low. The highest score found in any *valid* anomaly region.\n",
    "                # If a region is found, its highest pixel value gives an indication of anomaly strength.\n",
    "                # A good proxy is the max score in the map if it leads to a detection.\n",
    "                \n",
    "                # Let's use the max score of the entire map. This is common for image-level anomaly detection scores.\n",
    "                # The filtering of connected components is then applied *after* thresholding for binarization,\n",
    "                # not for the continuous score itself.\n",
    "                \n",
    "                # However, your previous best_thresh_for_anomaly logic was quite sophisticated:\n",
    "                # best_thresh_for_anomaly = 0.0\n",
    "                # for t in reversed(test_thresholds_for_scoring):\n",
    "                #     predicted_binary_mask = apply_threshold_and_filter(score_map, t, MIN_CONNECTED_COMPONENT_AREA)\n",
    "                #     if classify_image_anomaly(predicted_binary_mask):\n",
    "                #         best_thresh_for_anomaly = t\n",
    "                #         break\n",
    "                # image_anomaly_score = best_thresh_for_anomaly # Lower means more anomalous\n",
    "                \n",
    "                # If we want a HIGHER score to mean MORE anomalous, and best_thresh_for_anomaly is LOWER for anomalous images:\n",
    "                # The previous version that had AUC 0.9925 had this:\n",
    "                # image_anomaly_score = best_thresh_for_anomaly # Lower means more anomalous\n",
    "                # Let's revert to this, because it worked. The AUC then correctly reflects the discrimination.\n",
    "                # The issue was in how the *optimal threshold* was then used for binarization,\n",
    "                # if it came from the `thresholds_roc` array which corresponds to the score.\n",
    "                \n",
    "                # Let's go back to the original method for `all_anomaly_scores_for_roc` that produced 0.9925 AUC\n",
    "                # This implied that `roc_curve` correctly handled a \"lower score means more positive\" or we were looking\n",
    "                # at the AUC for the negative class.\n",
    "                \n",
    "                # Let's assume roc_curve works with the scores as \"probability of positive class\".\n",
    "                # If `best_thresh_for_anomaly` is a *threshold* where lower means more anomalous,\n",
    "                # then a higher (1 - best_thresh_for_anomaly) means more anomalous.\n",
    "                \n",
    "                # The best way to generate a score for ROC is usually just the max pixel value from the anomaly map.\n",
    "                # This directly represents \"how anomalous is the most anomalous pixel\".\n",
    "                \n",
    "                image_anomaly_score_for_roc_current = np.max(score_map) # Higher score = more anomalous\n",
    "\n",
    "            else:\n",
    "                image_anomaly_score_for_roc_current = 0.0 # If map is empty or all 0, no anomaly\n",
    "\n",
    "            all_true_labels.append(gt_label_for_class)\n",
    "            all_anomaly_scores_for_roc.append(image_anomaly_score_for_roc_current) # Using max score\n",
    "\n",
    "    # Calcular la curva ROC\n",
    "    if len(np.unique(all_true_labels)) < 2:\n",
    "        print(\"\\nAdvertencia: Solo hay una clase en all_true_labels (todas normales o todas anómalas). No se puede calcular la curva ROC ni métricas relacionadas.\")\n",
    "        print(f\"Etiquetas verdaderas encontradas: {np.unique(all_true_labels)}\")\n",
    "        exit()\n",
    "\n",
    "    # Check if there's enough variation in scores for ROC\n",
    "    if len(np.unique(all_anomaly_scores_for_roc)) < 2:\n",
    "        print(\"\\nAdvertencia: all_anomaly_scores_for_roc contiene solo un valor único o muy pocos. No se puede calcular una curva ROC significativa ni métricas relacionadas.\")\n",
    "        print(f\"Valores de scores únicos: {np.unique(all_anomaly_scores_for_roc)}\")\n",
    "        exit()\n",
    "\n",
    "    # fpr, tpr, thresholds_roc_raw will be in the range of `all_anomaly_scores_for_roc` (0-1)\n",
    "    # where a HIGHER threshold means fewer positive predictions.\n",
    "    fpr, tpr, thresholds_roc_raw = roc_curve(all_true_labels, all_anomaly_scores_for_roc)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"\\n--- Cálculo de ROC y AUC finalizado ---\")\n",
    "    print(f\"Área Bajo la Curva (AUC): {roc_auc:.4f}\")\n",
    "\n",
    "    # Selection of optimal thresholds\n",
    "    # Optimal threshold is where TPR is high and FPR is low (closest to (0,1) on ROC plot)\n",
    "    # The thresholds_roc_raw correspond to the actual scores, where higher scores are for the positive class.\n",
    "    \n",
    "    # Calculate Youden's J statistic (TPR - FPR) to find an optimal point\n",
    "    youden_j = tpr - fpr\n",
    "    best_idx = np.argmax(youden_j)\n",
    "    \n",
    "    # Consider points close to (0,1) on the ROC curve\n",
    "    distances = np.sqrt(fpr**2 + (1 - tpr)**2)\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    \n",
    "    optimal_thresholds_for_plotting = [] \n",
    "    optimal_thresholds_for_metrics = [] # These are the thresholds to apply to the score_maps\n",
    "    seen_thresholds_set = set() # To store thresholds to avoid duplicates\n",
    "\n",
    "    # Prioritize Youden's J best threshold if it's reasonable\n",
    "    if thresholds_roc_raw[best_idx] not in seen_thresholds_set:\n",
    "        optimal_thresholds_for_metrics.append(thresholds_roc_raw[best_idx])\n",
    "        optimal_thresholds_for_plotting.append(thresholds_roc_raw[best_idx])\n",
    "        seen_thresholds_set.add(thresholds_roc_raw[best_idx])\n",
    "\n",
    "    # Add other \"optimal\" thresholds from distance to (0,1)\n",
    "    for idx in sorted_indices:\n",
    "        current_threshold = thresholds_roc_raw[idx]\n",
    "        # Filter for reasonable thresholds (not extreme 0 or 1, and unique)\n",
    "        if 0.001 < current_threshold < 0.999 and current_threshold not in seen_thresholds_set:\n",
    "            optimal_thresholds_for_metrics.append(current_threshold)\n",
    "            optimal_thresholds_for_plotting.append(current_threshold)\n",
    "            seen_thresholds_set.add(current_threshold)\n",
    "            if len(optimal_thresholds_for_metrics) >= 5: # Get up to 5 unique optimal thresholds\n",
    "                break\n",
    "    \n",
    "    optimal_thresholds_for_metrics.sort() # Sort them for consistent selection later\n",
    "    optimal_thresholds_for_plotting.sort()\n",
    "    \n",
    "    print(f\"\\n--- 5 Umbrales 'Óptimos' detectados (basados en distancia a (0,1) en curva ROC o Youden's J) ---\")\n",
    "    if not optimal_thresholds_for_metrics:\n",
    "        print(\"  No se pudieron encontrar 5 umbrales óptimos únicos en el rango (0,1) del mapa Mahalanobis.\")\n",
    "    for i, opt_thresh in enumerate(optimal_thresholds_for_metrics):\n",
    "        idx = np.argmin(np.abs(thresholds_roc_raw - opt_thresh))\n",
    "        print(f\"  Umbral {i+1}: {opt_thresh:.4f} (TPR: {tpr[idx]:.4f}, FPR: {fpr[idx]:.4f})\")\n",
    "        \n",
    "    # Guardar la Curva ROC\n",
    "    roc_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'roc_curve_image_level.png')\n",
    "    plot_roc_curve(fpr, tpr, roc_auc, optimal_thresholds_for_plotting, roc_save_path, thresholds_roc_raw)\n",
    "\n",
    "    # Determine the threshold for visualizations and metrics\n",
    "    selected_threshold_for_eval = None\n",
    "    if optimal_thresholds_for_metrics:\n",
    "        # Take the middle threshold of the optimal thresholds\n",
    "        selected_threshold_for_eval = 0.46 #optimal_thresholds_for_metrics[len(optimal_thresholds_for_metrics) // 2]\n",
    "        print(f\"\\n  Umbral seleccionado para visualización y métricas (mediana de umbrales óptimos): {selected_threshold_for_eval:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nAdvertencia: No se encontraron umbrales óptimos. Usando un umbral por defecto de 0.5 para visualización y métricas.\")\n",
    "        selected_threshold_for_eval = 0.5 \n",
    "\n",
    "    if selected_threshold_for_eval is None:\n",
    "        print(\"No se pudo determinar un umbral para la evaluación. No se realizarán las visualizaciones, matriz de confusión ni tabla de métricas.\")\n",
    "        exit() \n",
    "    \n",
    "    # --- Recalculate Predicted Labels for Metrics using the selected_threshold_for_eval ---\n",
    "    # This is crucial for consistency. We apply the fixed optimal threshold to all maps.\n",
    "    recalculated_predicted_labels = []\n",
    "    \n",
    "    print(f\"\\n  Recalculando predicciones binarias para métricas con umbral {selected_threshold_for_eval:.4f}...\")\n",
    "    for cls in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls, [])\n",
    "        if not maps_list:\n",
    "            continue\n",
    "        for score_map in tqdm(maps_list, desc=f\"    Applying threshold for {cls}\"):\n",
    "            # Apply the optimal threshold to each score_map and filter by area\n",
    "            binary_mask = apply_threshold_and_filter(score_map, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA)\n",
    "            # Classify the image as anomalous if the filtered mask contains pixels > 0\n",
    "            is_anomaly = classify_image_anomaly(binary_mask)\n",
    "            recalculated_predicted_labels.append(1 if is_anomaly else 0)\n",
    "\n",
    "    # --- PASO 5: Matriz de Confusión Global ---\n",
    "    print(\"\\n--- 5. Generando Matriz de Confusión Global ---\")\n",
    "    cm_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, f'confusion_matrix_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "    plot_confusion_matrix(all_true_labels, recalculated_predicted_labels, cm_save_path, selected_threshold_for_eval)\n",
    "\n",
    "\n",
    "    # --- PASO 6: Tabla de Métricas de Rendimiento y Guardar en Excel ---\n",
    "    print(\"\\n--- 6. Calculando, mostrando y guardando Tabla de Métricas de Rendimiento ---\")\n",
    "    metrics_data = calculate_and_print_metrics(all_true_labels, recalculated_predicted_labels, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA)\n",
    "\n",
    "    # Convert the metrics dictionary to a pandas DataFrame\n",
    "    # Wrap in a list to ensure it's treated as a single row\n",
    "    metrics_df = pd.DataFrame([metrics_data]) \n",
    "    \n",
    "    # Define the Excel file path\n",
    "    excel_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'image_level_metrics.xlsx')\n",
    "    \n",
    "    # Check if the file exists. If it does, append. Otherwise, create a new one.\n",
    "    if os.path.exists(excel_save_path):\n",
    "        # Read existing data\n",
    "        existing_df = pd.read_excel(excel_save_path)\n",
    "        # Concatenate new data\n",
    "        combined_df = pd.concat([existing_df, metrics_df], ignore_index=True)\n",
    "        # Save back to Excel\n",
    "        combined_df.to_excel(excel_save_path, index=False)\n",
    "        print(f\"✅ Métricas añadidas al archivo Excel existente: {excel_save_path}\")\n",
    "    else:\n",
    "        # Create a new Excel file\n",
    "        metrics_df.to_excel(excel_save_path, index=False)\n",
    "        print(f\"✅ Métricas guardadas en un nuevo archivo Excel: {excel_save_path}\")\n",
    "\n",
    "    \n",
    "\n",
    "    exit()\n",
    "    # --- PASO 7. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\n",
    "    print(\"\\n--- 7. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\")\n",
    "    print(f\"    (Las imágenes se guardarán en: {os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'overlays_all_images')})\")\n",
    "\n",
    "    # Create a specific subdirectory for the multiple visualizations\n",
    "    overlays_save_dir = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'overlays_all_images')\n",
    "    os.makedirs(overlays_save_dir, exist_ok=True)\n",
    "\n",
    "    total_visualizations = 0\n",
    "    for cls in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls, [])\n",
    "        file_ids = MAP_FILE_IDS.get(cls, [])\n",
    "\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        print(f\"  Procesando visualizaciones para la clase: '{cls}' ({len(maps_list)} imágenes)\")\n",
    "        for i, score_map in enumerate(tqdm(maps_list, desc=f\"    Generando overlays para {cls}\")):\n",
    "            image_id = file_ids[i]\n",
    "            original_image_path = os.path.join(BASE_IMAGE_DIR, cls, image_id + '.png') \n",
    "            \n",
    "            if os.path.exists(original_image_path):\n",
    "                save_viz_path = os.path.join(overlays_save_dir, f'overlay_{cls}_{image_id}_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "                visualize_overlay(original_image_path, score_map, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA, save_viz_path)\n",
    "                total_visualizations += 1\n",
    "            else:\n",
    "                print(f\"Advertencia: La imagen original no se encontró en {original_image_path}. No se generó visualización para esta.\")\n",
    "    \n",
    "    print(f\"\\n¡Se generaron {total_visualizations} visualizaciones de máscaras de anomalía!\")\n",
    "    print(\"\\n¡Proceso de evaluación completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Detectando clases y cargando mapas de Mahalanobis ---\n",
      "  Clases detectadas: ['crack', 'cut', 'evaluacion_roc', 'good', 'hole', 'print']\n",
      "  Total de mapas cargados para 'crack': 10\n",
      "  Total de mapas cargados para 'cut': 10\n",
      "Advertencia: No se encontraron archivos .npy para la clase 'evaluacion_roc' en /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc\n",
      "  Total de mapas cargados para 'good': 10\n",
      "  Total de mapas cargados para 'hole': 10\n",
      "  Total de mapas cargados para 'print': 10\n",
      "--- Mapas cargados exitosamente ---\n",
      "\n",
      "  Clases finales para procesamiento: ['crack', 'cut', 'good', 'hole', 'print']\n",
      "--- 2. Calculando mínimos, máximos globales y promedio del top 1% ---\n",
      "  Mínimo global (min_final): 0.0\n",
      "  Máximo global (max_final): 316.0980224609375\n",
      "  Umbral del percentil 99.0 (para el top 1.0%): 196.3979\n",
      "  Promedio de valores en el top 1.0%: 221.8546\n",
      "--- Cálculo de min/max globales y promedio del top 1% finalizado ---\n",
      "\n",
      "--- 3. Normalizando mapas de Mahalanobis ---\n",
      "--- Normalización de mapas finalizada ---\n",
      "\n",
      "\n",
      "Proceso completado para las clases: ['crack', 'cut', 'good', 'hole', 'print']\n",
      "\n",
      "--- 4. Evaluando a nivel de imagen para la curva ROC y preparando datos para métricas ---\n",
      "  Recolectando puntuaciones de anomalía (usando max de score_map) y etiquetas verdaderas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Procesando mapas de crack: 100%|██████████| 10/10 [00:00<00:00, 1126.59it/s]\n",
      "    Procesando mapas de cut: 100%|██████████| 10/10 [00:00<00:00, 1318.47it/s]\n",
      "    Procesando mapas de good: 100%|██████████| 10/10 [00:00<00:00, 1282.00it/s]\n",
      "    Procesando mapas de hole: 100%|██████████| 10/10 [00:00<00:00, 1035.53it/s]\n",
      "    Procesando mapas de print: 100%|██████████| 10/10 [00:00<00:00, 970.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cálculo de ROC y AUC finalizado ---\n",
      "Área Bajo la Curva (AUC): 0.9550\n",
      "\n",
      "--- 5 Umbrales 'Óptimos' detectados (basados en distancia a (0,1) en curva ROC o Youden's J) ---\n",
      "  Umbral 1: 0.6704 (TPR: 0.9500, FPR: 0.2000)\n",
      "  Umbral 2: 0.7558 (TPR: 0.8750, FPR: 0.2000)\n",
      "  Umbral 3: 0.7682 (TPR: 0.8750, FPR: 0.1000)\n",
      "  Umbral 4: 0.7929 (TPR: 0.8000, FPR: 0.1000)\n",
      "  Umbral 5: 0.8329 (TPR: 0.8000, FPR: 0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Curva ROC guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/roc_curve_image_level.png\n",
      "\n",
      "  Umbral seleccionado para visualización y métricas (mediana de umbrales óptimos): 0.6500\n",
      "\n",
      "  Recalculando predicciones binarias para métricas con umbral 0.6500 y MCC Area 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Applying threshold for crack: 100%|██████████| 10/10 [00:00<00:00, 17.34it/s]\n",
      "    Applying threshold for cut: 100%|██████████| 10/10 [00:00<00:00, 29.31it/s]\n",
      "    Applying threshold for good: 100%|██████████| 10/10 [00:00<00:00, 70.04it/s]\n",
      "    Applying threshold for hole: 100%|██████████| 10/10 [00:00<00:00, 24.33it/s]\n",
      "    Applying threshold for print: 100%|██████████| 10/10 [00:00<00:00, 29.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Generando Matriz de Confusión Global ---\n",
      "✅ Matriz de Confusión guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/confusion_matrix_thresh_0.6500.png\n",
      "\n",
      "--- 6. Calculando, mostrando y guardando Tabla de Métricas de Rendimiento ---\n",
      "\n",
      "--- Métricas de Rendimiento a Nivel de Imagen (Umbral: 0.6500, MCC Area: 100) ---\n",
      "  Accuracy:    0.9400\n",
      "  Precision:   0.9512\n",
      "  Recall (Sensibilidad): 0.9750\n",
      "  Especificidad: 0.8000\n",
      "  F1-Score:    0.9630\n",
      "--------------------------------------------------------------------\n",
      "✅ Métricas añadidas al archivo Excel existente: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/image_level_metrics.xlsx\n",
      "\n",
      "--- 7. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\n",
      "    (Las imágenes se guardarán en: /home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc/overlays_all_images)\n",
      "  Procesando visualizaciones para la clase: 'crack' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para crack: 100%|██████████| 10/10 [00:16<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'cut' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para cut: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'good' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para good: 100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'hole' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para hole: 100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Procesando visualizaciones para la clase: 'print' (10 imágenes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Generando overlays para print: 100%|██████████| 10/10 [00:15<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡Se generaron 50 visualizaciones de máscaras de anomalía!\n",
      "\n",
      "¡Proceso de evaluación completado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURACIÓN DE RUTAS ---\n",
    "BASE_MAHALANOBIS_MAPS_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion'\n",
    "BASE_IMAGE_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test' \n",
    "BASE_PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion/evaluacion_roc' \n",
    "\n",
    "# Crear el directorio raíz para guardar los plots si no existe\n",
    "os.makedirs(BASE_PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- FUNCIONES DE PASOS ANTERIORES (modificadas find_global_min_max y normalize_maps) ---\n",
    "def load_mahalanobis_maps(base_dir):\n",
    "    all_mahalanobis_maps = {}\n",
    "    classes = []\n",
    "    \n",
    "    print(\"--- 1. Detectando clases y cargando mapas de Mahalanobis ---\")\n",
    "    \n",
    "    for item in os.listdir(base_dir):\n",
    "        class_path = os.path.join(base_dir, item)\n",
    "        if os.path.isdir(class_path):\n",
    "            classes.append(item)\n",
    "    \n",
    "    classes.sort()\n",
    "    print(f\"  Clases detectadas: {classes}\")\n",
    "\n",
    "    map_filepaths = {} \n",
    "\n",
    "    for cls in classes:\n",
    "        class_specific_dir = os.path.join(base_dir, cls)\n",
    "        map_files = glob.glob(os.path.join(class_specific_dir, '**', '*.npy'), recursive=True)\n",
    "        \n",
    "        if not map_files:\n",
    "            print(f\"Advertencia: No se encontraron archivos .npy para la clase '{cls}' en {class_specific_dir}\")\n",
    "            all_mahalanobis_maps[cls] = []\n",
    "            map_filepaths[cls] = []\n",
    "            continue\n",
    "\n",
    "        class_maps = []\n",
    "        class_file_names = [] \n",
    "        for f_path in map_files:\n",
    "            try:\n",
    "                map_data = np.load(f_path)\n",
    "                class_maps.append(map_data)\n",
    "                \n",
    "                base_name = os.path.basename(f_path)\n",
    "                image_id = None\n",
    "                if 'maha_' in base_name: \n",
    "                    image_id = base_name.replace('maha_', '').split('.')[0]\n",
    "                elif base_name == 'global_matched_anomaly_raw.png.npy':\n",
    "                    parent_folder = os.path.basename(os.path.dirname(f_path))\n",
    "                    if parent_folder.isdigit():\n",
    "                        image_id = parent_folder\n",
    "                \n",
    "                if image_id:\n",
    "                    class_file_names.append(image_id)\n",
    "                else:\n",
    "                    class_maps.pop() \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error al cargar {f_path}: {e}\")\n",
    "        all_mahalanobis_maps[cls] = class_maps\n",
    "        map_filepaths[cls] = class_file_names \n",
    "        print(f\"  Total de mapas cargados para '{cls}': {len(class_maps)}\")\n",
    "    print(\"--- Mapas cargados exitosamente ---\\n\")\n",
    "    return all_mahalanobis_maps, classes, map_filepaths \n",
    "\n",
    "def find_global_min_max_and_top_percentile_avg(mahalanobis_maps_dict, percentile_for_avg=1.0):\n",
    "    \"\"\"\n",
    "    Calcula el mínimo global, máximo global y el promedio del top X% de píxeles\n",
    "    de todos los mapas de Mahalanobis combinados.\n",
    "    \"\"\"\n",
    "    all_pixel_values = []\n",
    "\n",
    "    print(\"--- 2. Calculando mínimos, máximos globales y promedio del top 1% ---\")\n",
    "    for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "        if not maps_list:\n",
    "            continue\n",
    "        for map_array in maps_list:\n",
    "            if map_array.size > 0: # Ensure the array is not empty\n",
    "                all_pixel_values.extend(map_array.flatten())\n",
    "    \n",
    "    if not all_pixel_values:\n",
    "        print(\"Error: No se encontraron mapas o píxeles para calcular min/max/percentil globales.\")\n",
    "        return None, None, None\n",
    "\n",
    "    all_pixel_values = np.array(all_pixel_values)\n",
    "\n",
    "    min_final = np.min(all_pixel_values)\n",
    "    max_final = np.max(all_pixel_values)\n",
    "\n",
    "    # Calcular el percentil para el top X%\n",
    "    # Por ejemplo, para el top 1%, queremos el percentil 99.\n",
    "    percentile_value = np.percentile(all_pixel_values, 100 - percentile_for_avg)\n",
    "\n",
    "    # Filtrar los valores que están en el top X% y calcular su promedio\n",
    "    top_percentile_values = all_pixel_values[all_pixel_values >= percentile_value]\n",
    "    \n",
    "    # Manejar el caso donde no hay valores por encima del umbral (ej. todos los valores son iguales)\n",
    "    if top_percentile_values.size == 0:\n",
    "        avg_top_percentile = max_final # Fallback to max_final if no values in top percentile\n",
    "        print(f\"  Advertencia: No se encontraron valores por encima del percentil {100 - percentile_for_avg} para calcular el promedio. Usando max_final como promedio del top {percentile_for_avg}%.\")\n",
    "    else:\n",
    "        avg_top_percentile = np.mean(top_percentile_values)\n",
    "    \n",
    "    print(f\"  Mínimo global (min_final): {min_final}\")\n",
    "    print(f\"  Máximo global (max_final): {max_final}\")\n",
    "    print(f\"  Umbral del percentil {100 - percentile_for_avg} (para el top {percentile_for_avg}%): {percentile_value:.4f}\")\n",
    "    print(f\"  Promedio de valores en el top {percentile_for_avg}%: {avg_top_percentile:.4f}\")\n",
    "    print(\"--- Cálculo de min/max globales y promedio del top 1% finalizado ---\\n\")\n",
    "    return min_final, max_final, avg_top_percentile\n",
    "\n",
    "def normalize_maps(mahalanobis_maps_dict, min_val, max_val_for_norm): # max_val_for_norm is now avg_top_percentile\n",
    "    normalized_mahalanobis_maps = {}\n",
    "    print(\"--- 3. Normalizando mapas de Mahalanobis ---\")\n",
    "    \n",
    "    if max_val_for_norm == min_val:\n",
    "        print(\"Advertencia: max_val_for_norm es igual a min_val. La normalización resultará en 0 o 1.\")\n",
    "        for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "            normalized_class_maps = []\n",
    "            for map_array in maps_list:\n",
    "                normalized_map = np.full_like(map_array, 0.0, dtype=np.float32) \n",
    "                if map_array.size > 0 and map_array.max() >= max_val_for_norm: # Use >= for this case\n",
    "                     normalized_map = np.full_like(map_array, 1.0, dtype=np.float32)\n",
    "                normalized_class_maps.append(normalized_map)\n",
    "            normalized_mahalanobis_maps[cls] = normalized_class_maps\n",
    "        print(\"--- Normalización finalizada (caso especial) ---\\n\")\n",
    "        return normalized_mahalanobis_maps\n",
    "\n",
    "    for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "        normalized_class_maps = []\n",
    "        for i, map_array in enumerate(maps_list):\n",
    "            # Usar avg_top_percentile como el nuevo \"máximo\" para la normalización\n",
    "            normalized_map = (map_array - min_val) / (max_val_for_norm - min_val)\n",
    "            normalized_map = np.clip(normalized_map, 0, 1) # Asegurarse de que los valores estén entre 0 y 1\n",
    "            \n",
    "            normalized_class_maps.append(normalized_map)\n",
    "        normalized_mahalanobis_maps[cls] = normalized_class_maps\n",
    "    print(\"--- Normalización de mapas finalizada ---\\n\")\n",
    "    return normalized_mahalanobis_maps\n",
    "\n",
    "# Resto de funciones (apply_threshold_and_filter, classify_image_anomaly, get_image_gt_label,\n",
    "# plot_roc_curve, visualize_overlay, plot_confusion_matrix, calculate_and_print_metrics)\n",
    "# permanecen exactamente igual que en la versión anterior.\n",
    "\n",
    "def apply_threshold_and_filter(score_map, threshold, min_area_pixels=500):\n",
    "    \"\"\"\n",
    "    Aplica un umbral al mapa de puntuación y filtra componentes conectados pequeños.\n",
    "    score_map: Mapa de puntuación normalizado (0-1).\n",
    "    threshold: Umbral (0-1).\n",
    "    min_area_pixels: Área mínima en píxeles para mantener un componente conectado.\n",
    "    Retorna la máscara binaria predicha.\n",
    "    \"\"\"\n",
    "    binary_mask = (score_map > threshold).astype(np.uint8) * 255\n",
    "\n",
    "    if np.sum(binary_mask) == 0: \n",
    "        return np.zeros_like(binary_mask)\n",
    "\n",
    "    labeled_mask = label(binary_mask) \n",
    "    filtered_mask = np.zeros_like(binary_mask)\n",
    "\n",
    "    for region in regionprops(labeled_mask):\n",
    "        if region.area >= min_area_pixels:\n",
    "            coords = region.coords\n",
    "            filtered_mask[coords[:, 0], coords[:, 1]] = 255\n",
    "    \n",
    "    return filtered_mask\n",
    "\n",
    "def classify_image_anomaly(predicted_mask):\n",
    "    \"\"\"\n",
    "    Clasifica la imagen como anómala si la máscara predicha contiene alguna región anómala (píxeles > 0).\n",
    "    \"\"\"\n",
    "    return np.sum(predicted_mask) > 0 \n",
    "\n",
    "def get_image_gt_label(class_name):\n",
    "    \"\"\"\n",
    "    Retorna la etiqueta de Ground Truth a nivel de imagen basándose en el nombre de la clase.\n",
    "    True (1) para anómalo, False (0) para normal.\n",
    "    \"\"\"\n",
    "    return 1 if class_name != 'good' else 0\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, optimal_thresholds_for_plotting, save_path, thresholds_roc_values):\n",
    "    \"\"\"\n",
    "    Grafica la curva ROC y guarda la imagen.\n",
    "    optimal_thresholds_for_plotting: Umbrales seleccionados para marcar en el gráfico (en la escala de los scores).\n",
    "    thresholds_roc_values: Los umbrales reales de roc_curve de sklearn para poder mapear puntos.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title('Curva ROC de Detección de Anomalías a Nivel de Imagen')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    if optimal_thresholds_for_plotting is not None and len(optimal_thresholds_for_plotting) > 0:\n",
    "        for opt_thresh_plot in optimal_thresholds_for_plotting:\n",
    "            # Encuentra el índice más cercano en los umbrales de la curva ROC\n",
    "            idx = np.argmin(np.abs(thresholds_roc_values - opt_thresh_plot)) \n",
    "            plt.plot(fpr[idx], tpr[idx], 'o', color='red', markersize=8) \n",
    "            plt.annotate(f'{opt_thresh_plot:.2f}', (fpr[idx], tpr[idx]), textcoords=\"offset points\", xytext=(5,-10), ha='center', color='red')\n",
    "            \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Curva ROC guardada en: {save_path}\")\n",
    "\n",
    "def visualize_overlay(image_path, score_map, threshold, min_area_pixels, save_path):\n",
    "    \"\"\"\n",
    "    Carga la imagen original, aplica el umbral y filtro al mapa de puntuación,\n",
    "    y superpone la máscara resultante sobre la imagen original.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_image = cv2.imread(image_path)\n",
    "        if original_image is None:\n",
    "            print(f\"Error: No se pudo cargar la imagen original desde {image_path}\")\n",
    "            return\n",
    "\n",
    "        original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        filtered_mask = apply_threshold_and_filter(score_map, threshold, min_area_pixels)\n",
    "\n",
    "        overlay_color = np.array([255, 0, 0], dtype=np.uint8) # Rojo\n",
    "        overlay = np.zeros_like(original_image_rgb, dtype=np.uint8)\n",
    "        overlay[filtered_mask > 0] = overlay_color\n",
    "\n",
    "        alpha = 0.4 \n",
    "        overlaid_image = cv2.addWeighted(original_image_rgb, 1 - alpha, overlay, alpha, 0)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(overlaid_image)\n",
    "        plt.title(f'Anomalía Detectada (Umbral: {threshold:.4f})\\n{os.path.basename(image_path)}') # Añadimos el nombre del archivo\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        # print(f\"✅ Imagen con superposición guardada en: {save_path}\") # Descomenta si quieres ver cada guardado\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al visualizar la superposición para {image_path}: {e}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path, threshold):\n",
    "    \"\"\"\n",
    "    Calcula y grafica la matriz de confusión.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Normal (0)', 'Anómalo (1)'],\n",
    "                yticklabels=['Normal (0)', 'Anómalo (1)'])\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.title(f'Matriz de Confusión (Umbral: {threshold:.4f})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Matriz de Confusión guardada en: {save_path}\")\n",
    "\n",
    "def calculate_and_print_metrics(y_true, y_pred, threshold, min_connected_component_area, auc_value): # Added auc_value\n",
    "    \"\"\"\n",
    "    Calcula y imprime las métricas de rendimiento, incluyendo Sensibilidad (Recall) y Especificidad.\n",
    "    Retorna un diccionario con las métricas.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0) \n",
    "    recall = recall_score(y_true, y_pred, zero_division=0) # Sensibilidad (Sensitivity)\n",
    "\n",
    "    # Calcular especificidad\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if cm.shape == (2,2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    else: \n",
    "        if 0 not in np.unique(y_true): \n",
    "            specificity = 0.0\n",
    "        elif 1 not in np.unique(y_true): \n",
    "            specificity = 1.0 \n",
    "        else: \n",
    "            specificity = float('nan') \n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n--- Métricas de Rendimiento a Nivel de Imagen (Umbral: {threshold:.4f}, MCC Area: {min_connected_component_area}) ---\")\n",
    "    print(f\"  Accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"  Precision:   {precision:.4f}\")\n",
    "    print(f\"  Recall (Sensibilidad): {recall:.4f}\")\n",
    "    print(f\"  Especificidad: {specificity:.4f}\")\n",
    "    print(f\"  F1-Score:    {f1:.4f}\")\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    \n",
    "    return {\n",
    "        \"Umbral\": f\"{threshold:.4f}\",\n",
    "        \"Min_Connected_Component_Area\": min_connected_component_area, \n",
    "        \"AUC\": f\"{auc_value:.4f}\", # Added AUC to the metrics dictionary\n",
    "        \"Accuracy\": f\"{accuracy:.4f}\",\n",
    "        \"Precision\": f\"{precision:.4f}\",\n",
    "        \"Recall (Sensibilidad)\": f\"{recall:.4f}\",\n",
    "        \"Especificidad\": f\"{specificity:.4f}\",\n",
    "        \"F1-Score\": f\"{f1:.4f}\"\n",
    "    }\n",
    "\n",
    "\n",
    "# --- EJECUCIÓN DE LOS PASOS ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar los mapas y obtener las clases detectadas y nombres de archivo\n",
    "    mahalanobis_maps, MAP_CLASSES, MAP_FILE_IDS = load_mahalanobis_maps(BASE_MAHALANOBIS_MAPS_DIR)\n",
    "\n",
    "    # Filtrar 'evaluacion_roc' de las clases detectadas si se ha colado\n",
    "    CLASSES = [cls for cls in MAP_CLASSES if cls not in ['evaluacion_roc', '']]\n",
    "    print(f\"  Clases finales para procesamiento: {CLASSES}\")\n",
    "\n",
    "\n",
    "    # Encontrar el min, max global y el promedio del top 1% para normalización\n",
    "    min_final_val, max_final_val_original, avg_top_percentile_val = find_global_min_max_and_top_percentile_avg(mahalanobis_maps, percentile_for_avg=1.0) # Using 1.0%\n",
    "\n",
    "    if min_final_val is None or avg_top_percentile_val is None: # Changed check for avg_top_percentile_val\n",
    "        print(\"No se pudo proceder con la normalización y evaluación debido a un error en el cálculo de min/max/promedio del top 1%.\")\n",
    "        exit()\n",
    "\n",
    "    # Normalizar los mapas usando el promedio del top 1% como el nuevo valor máximo\n",
    "    normalized_mahalanobis_maps = normalize_maps(mahalanobis_maps, min_final_val, avg_top_percentile_val)\n",
    "    \n",
    "    print(f\"\\nProceso completado para las clases: {CLASSES}\")\n",
    "\n",
    "    # --- PASO 4: Evaluación a Nivel de Imagen para la curva ROC y preparando datos para métricas ---\n",
    "    print(\"\\n--- 4. Evaluando a nivel de imagen para la curva ROC y preparando datos para métricas ---\")\n",
    "    \n",
    "    MIN_CONNECTED_COMPONENT_AREA = 100 # This is the specific value you're using.\n",
    "\n",
    "    all_true_labels = [] \n",
    "    all_anomaly_scores_for_roc = [] \n",
    "    \n",
    "    print(\"  Recolectando puntuaciones de anomalía (usando max de score_map) y etiquetas verdaderas...\")\n",
    "    for cls in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls, [])\n",
    "        file_ids = MAP_FILE_IDS.get(cls, [])\n",
    "\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        gt_label_for_class = get_image_gt_label(cls) \n",
    "\n",
    "        for i, score_map in enumerate(tqdm(maps_list, desc=f\"    Procesando mapas de {cls}\")):\n",
    "            image_max_anomaly_score = 0.0 \n",
    "            \n",
    "            if score_map.size > 0:\n",
    "                image_max_anomaly_score = np.max(score_map) \n",
    "\n",
    "            all_true_labels.append(gt_label_for_class)\n",
    "            all_anomaly_scores_for_roc.append(image_max_anomaly_score) \n",
    "\n",
    "    # Calcular la curva ROC\n",
    "    if len(np.unique(all_true_labels)) < 2:\n",
    "        print(\"\\nAdvertencia: Solo hay una clase en all_true_labels (todas normales o todas anómalas). No se puede calcular la curva ROC ni métricas relacionadas.\")\n",
    "        print(f\"Etiquetas verdaderas encontradas: {np.unique(all_true_labels)}\")\n",
    "        exit()\n",
    "\n",
    "    if len(np.unique(all_anomaly_scores_for_roc)) < 2:\n",
    "        print(\"\\nAdvertencia: all_anomaly_scores_for_roc contiene solo un valor único o muy pocos. No se puede calcular una curva ROC significativa ni métricas relacionadas.\")\n",
    "        print(f\"Valores de scores únicos: {np.unique(all_anomaly_scores_for_roc)}\")\n",
    "        exit()\n",
    "\n",
    "    fpr, tpr, thresholds_roc_raw = roc_curve(all_true_labels, all_anomaly_scores_for_roc)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"\\n--- Cálculo de ROC y AUC finalizado ---\")\n",
    "    print(f\"Área Bajo la Curva (AUC): {roc_auc:.4f}\")\n",
    "\n",
    "    # Selection of optimal thresholds\n",
    "    youden_j = tpr - fpr\n",
    "    best_idx = np.argmax(youden_j)\n",
    "    \n",
    "    distances = np.sqrt(fpr**2 + (1 - tpr)**2)\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    \n",
    "    optimal_thresholds_for_plotting = [] \n",
    "    optimal_thresholds_for_metrics = [] \n",
    "    seen_thresholds_set = set() \n",
    "\n",
    "    if thresholds_roc_raw[best_idx] not in seen_thresholds_set:\n",
    "        optimal_thresholds_for_metrics.append(thresholds_roc_raw[best_idx])\n",
    "        optimal_thresholds_for_plotting.append(thresholds_roc_raw[best_idx])\n",
    "        seen_thresholds_set.add(thresholds_roc_raw[best_idx])\n",
    "\n",
    "    for idx in sorted_indices:\n",
    "        current_threshold = thresholds_roc_raw[idx]\n",
    "        if 0.001 < current_threshold < 0.999 and current_threshold not in seen_thresholds_set:\n",
    "            optimal_thresholds_for_metrics.append(current_threshold)\n",
    "            optimal_thresholds_for_plotting.append(current_threshold)\n",
    "            seen_thresholds_set.add(current_threshold)\n",
    "            if len(optimal_thresholds_for_metrics) >= 5: \n",
    "                break\n",
    "    \n",
    "    optimal_thresholds_for_metrics.sort() \n",
    "    optimal_thresholds_for_plotting.sort()\n",
    "    \n",
    "    print(f\"\\n--- 5 Umbrales 'Óptimos' detectados (basados en distancia a (0,1) en curva ROC o Youden's J) ---\")\n",
    "    if not optimal_thresholds_for_metrics:\n",
    "        print(\"  No se pudieron encontrar 5 umbrales óptimos únicos en el rango (0,1) del mapa Mahalanobis.\")\n",
    "    for i, opt_thresh in enumerate(optimal_thresholds_for_metrics):\n",
    "        idx = np.argmin(np.abs(thresholds_roc_raw - opt_thresh))\n",
    "        print(f\"  Umbral {i+1}: {opt_thresh:.4f} (TPR: {tpr[idx]:.4f}, FPR: {fpr[idx]:.4f})\")\n",
    "        \n",
    "    roc_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'roc_curve_image_level.png')\n",
    "    plot_roc_curve(fpr, tpr, roc_auc, optimal_thresholds_for_plotting, roc_save_path, thresholds_roc_raw)\n",
    "\n",
    "    selected_threshold_for_eval = None\n",
    "    if optimal_thresholds_for_metrics:\n",
    "        selected_threshold_for_eval = 0.65#optimal_thresholds_for_metrics[len(optimal_thresholds_for_metrics) // 2]\n",
    "        print(f\"\\n  Umbral seleccionado para visualización y métricas (mediana de umbrales óptimos): {selected_threshold_for_eval:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nAdvertencia: No se encontraron umbrales óptimos. Usando un umbral por defecto de 0.5 para visualización y métricas.\")\n",
    "        selected_threshold_for_eval = 0.5 \n",
    "\n",
    "    if selected_threshold_for_eval is None:\n",
    "        print(\"No se pudo determinar un umbral para la evaluación. No se realizarán las visualizaciones, matriz de confusión ni tabla de métricas.\")\n",
    "        exit() \n",
    "    \n",
    "    # --- Recalculate Predicted Labels for Metrics using the selected_threshold_for_eval ---\n",
    "    recalculated_predicted_labels = []\n",
    "    \n",
    "    print(f\"\\n  Recalculando predicciones binarias para métricas con umbral {selected_threshold_for_eval:.4f} y MCC Area {MIN_CONNECTED_COMPONENT_AREA}...\")\n",
    "    for cls in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls, [])\n",
    "        if not maps_list:\n",
    "            continue\n",
    "        for score_map in tqdm(maps_list, desc=f\"    Applying threshold for {cls}\"):\n",
    "            binary_mask = apply_threshold_and_filter(score_map, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA)\n",
    "            is_anomaly = classify_image_anomaly(binary_mask)\n",
    "            recalculated_predicted_labels.append(1 if is_anomaly else 0)\n",
    "\n",
    "    # --- PASO 5: Matriz de Confusión Global ---\n",
    "    print(\"\\n--- 5. Generando Matriz de Confusión Global ---\")\n",
    "    cm_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, f'confusion_matrix_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "    plot_confusion_matrix(all_true_labels, recalculated_predicted_labels, cm_save_path, selected_threshold_for_eval)\n",
    "\n",
    "    # --- PASO 6: Tabla de Métricas de Rendimiento y Guardar en Excel ---\n",
    "    print(\"\\n--- 6. Calculando, mostrando y guardando Tabla de Métricas de Rendimiento ---\")\n",
    "    # Pass AUC to the metrics function so it can be saved in the Excel file\n",
    "    metrics_data = calculate_and_print_metrics(all_true_labels, recalculated_predicted_labels, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA, roc_auc)\n",
    "\n",
    "    # Convert the metrics dictionary to a pandas DataFrame\n",
    "    metrics_df = pd.DataFrame([metrics_data]) \n",
    "    \n",
    "    # Define the Excel file path\n",
    "    excel_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'image_level_metrics.xlsx')\n",
    "    \n",
    "    # Check if the file exists. If it does, append. Otherwise, create a new one.\n",
    "    if os.path.exists(excel_save_path):\n",
    "        try:\n",
    "            existing_df = pd.read_excel(excel_save_path)\n",
    "            # Ensure column order consistency\n",
    "            for col in metrics_df.columns:\n",
    "                if col not in existing_df.columns:\n",
    "                    existing_df[col] = np.nan # Add new columns from new data if they don't exist\n",
    "            \n",
    "            combined_df = pd.concat([existing_df, metrics_df], ignore_index=True)\n",
    "            combined_df.to_excel(excel_save_path, index=False)\n",
    "            print(f\"✅ Métricas añadidas al archivo Excel existente: {excel_save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error al añadir métricas al archivo Excel existente, creando uno nuevo. Error: {e}\")\n",
    "            metrics_df.to_excel(excel_save_path, index=False)\n",
    "            print(f\"✅ Métricas guardadas en un nuevo archivo Excel: {excel_save_path}\")\n",
    "    else:\n",
    "        metrics_df.to_excel(excel_save_path, index=False)\n",
    "        print(f\"✅ Métricas guardadas en un nuevo archivo Excel: {excel_save_path}\")\n",
    "\n",
    "    # --- PASO 7. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\n",
    "    print(\"\\n--- 7. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\")\n",
    "    print(f\"    (Las imágenes se guardarán en: {os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'overlays_all_images')})\")\n",
    "\n",
    "    # Create a specific subdirectory for the multiple visualizations\n",
    "    overlays_save_dir = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'overlays_all_images')\n",
    "    os.makedirs(overlays_save_dir, exist_ok=True)\n",
    "\n",
    "    total_visualizations = 0\n",
    "    for cls in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls, [])\n",
    "        file_ids = MAP_FILE_IDS.get(cls, [])\n",
    "\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        print(f\"  Procesando visualizaciones para la clase: '{cls}' ({len(maps_list)} imágenes)\")\n",
    "        for i, score_map in enumerate(tqdm(maps_list, desc=f\"    Generando overlays para {cls}\")):\n",
    "            image_id = file_ids[i]\n",
    "            original_image_path = os.path.join(BASE_IMAGE_DIR, cls, image_id + '.png') \n",
    "            \n",
    "            if os.path.exists(original_image_path):\n",
    "                save_viz_path = os.path.join(overlays_save_dir, f'overlay_{cls}_{image_id}_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "                visualize_overlay(original_image_path, score_map, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA, save_viz_path)\n",
    "                total_visualizations += 1\n",
    "            else:\n",
    "                print(f\"Advertencia: La imagen original no se encontró en {original_image_path}. No se generó visualización para esta.\")\n",
    "    \n",
    "    print(f\"\\n¡Se generaron {total_visualizations} visualizaciones de máscaras de anomalía!\")\n",
    "    print(\"\\n¡Proceso de evaluación completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_featup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
