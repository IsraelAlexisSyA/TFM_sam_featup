{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (382481611.py, line 453)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 453\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.figure(figsize=(,5 5))\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Importaciones necesarias para el filtro Gaussiano\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# --- FUNCIONES ADICIONALES REQUERIDAS ---\n",
    "def percentile_normalize(tensor, percentile_cap=99.0):\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        tensor = torch.from_numpy(tensor).float() # Asegurar que es tensor de PyTorch\n",
    "\n",
    "    if tensor.numel() == 0:\n",
    "        return torch.zeros_like(tensor).numpy() # Devolver numpy si la entrada lo fue\n",
    "    \n",
    "    flat_tensor = tensor.flatten()\n",
    "    p_low = torch.quantile(flat_tensor, (100 - percentile_cap) / 100.0)\n",
    "    p_high = torch.quantile(flat_tensor, percentile_cap / 100.0)\n",
    "\n",
    "    range_val = p_high - p_low\n",
    "    if range_val < 1e-8:\n",
    "        tensor_norm = torch.zeros_like(tensor)\n",
    "    else:\n",
    "        tensor_norm = (tensor - p_low) / range_val\n",
    "        tensor_norm = torch.clamp(tensor_norm, 0, 1)\n",
    "    \n",
    "    return tensor_norm.numpy() if isinstance(tensor, torch.Tensor) else tensor_norm # Asegurar que el tipo de retorno coincida con la entrada\n",
    "\n",
    "\n",
    "# --- NUEVA FUNCIÓN: APLICAR SUAVIZADO GAUSSIANO A UN SOLO MAPA ---\n",
    "@torch.no_grad()\n",
    "def apply_gaussian_smoothing_to_single_map(score_map_tensor, sigma=10.0):\n",
    "    \"\"\"\n",
    "    Aplica un filtro Gaussiano a un único mapa de puntuación.\n",
    "    \n",
    "    Args:\n",
    "        score_map_tensor (torch.Tensor): Un tensor PyTorch 2D (H, W) del mapa de puntuación.\n",
    "        sigma (float): La desviación estándar para el filtro Gaussiano.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: El mapa de puntuación suavizado como un tensor PyTorch 2D (H, W).\n",
    "    \"\"\"\n",
    "    # Añadir dimensiones de batch y canal para GaussianBlur (de H,W a 1,1,H,W)\n",
    "    score_map_for_blur = score_map_tensor.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Calcular el tamaño del kernel basado en sigma\n",
    "    # Una heurística común es 6 * sigma + 1 para un kernel que cubra ~3 desviaciones estándar a cada lado.\n",
    "    gaussian_blur_kernel_size = int(sigma * 6 + 1)\n",
    "    # Asegurar que el tamaño del kernel sea impar\n",
    "    if gaussian_blur_kernel_size % 2 == 0:\n",
    "        gaussian_blur_kernel_size += 1\n",
    "\n",
    "    gaussian_blur = T.GaussianBlur(kernel_size=(gaussian_blur_kernel_size, gaussian_blur_kernel_size), sigma=(sigma, sigma))\n",
    "\n",
    "    # Mover el tensor a la GPU si está disponible para el cálculo, luego volver a la CPU\n",
    "    smoothed_map_tensor = gaussian_blur(score_map_for_blur.to('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    \n",
    "    # Eliminar las dimensiones de batch y canal extra y asegurar que está en CPU\n",
    "    return smoothed_map_tensor.squeeze().cpu()\n",
    "\n",
    "\n",
    "# --- NUEVA FUNCIÓN: EVALUACIÓN A NIVEL DE PÍXEL (AUROC-PÍXEL) ---\n",
    "# Esta función ahora solo maneja un mapa individual para su recolección de datos\n",
    "# La curva ROC global a nivel de píxel se calculará por separado.\n",
    "def get_pixel_level_data(predicted_score_map, ground_truth_mask_path):\n",
    "    \"\"\"\n",
    "    Carga la máscara de ground truth y prepara los datos aplanados (y_true, y_scores)\n",
    "    para el cálculo global de AUROC a nivel de píxel.\n",
    "\n",
    "    Args:\n",
    "        predicted_score_map (np.ndarray): Mapa de puntuación de anomalías predicho por el modelo\n",
    "                                         (ya suavizado y normalizado, tipo float).\n",
    "        ground_truth_mask_path (str): Ruta a la máscara binaria de ground truth (imagen .png, .jpg).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (y_true_pixels, y_scores_pixels) o (None, None) si hay un error.\n",
    "    \"\"\"\n",
    "    #print(f\"Shape of predicted_score_map: {predicted_score_map.shape}\")\n",
    "    #print(f\"Shape of ground_truth_mask_path: {ground_truth_mask_path}\")\n",
    "    try:\n",
    "        ground_truth_mask = cv2.imread(ground_truth_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if ground_truth_mask is None:\n",
    "            # print(f\"Advertencia: No se pudo cargar la máscara de ground truth: {ground_truth_mask_path}. Saltando.\")\n",
    "            return None, None\n",
    "\n",
    "        ground_truth_mask = (ground_truth_mask > 0).astype(np.uint8)\n",
    "\n",
    "        if predicted_score_map.shape != ground_truth_mask.shape:\n",
    "            # print(f\"Advertencia: Dimensiones no coinciden para {os.path.basename(ground_truth_mask_path)}. \"\n",
    "            #       f\"Mapa: {predicted_score_map.shape}, GT: {ground_truth_mask.shape}. Saltando.\")\n",
    "            return None, None\n",
    "\n",
    "        y_true_pixels = ground_truth_mask.flatten()\n",
    "        y_scores_pixels = predicted_score_map.flatten()\n",
    "\n",
    "        return y_true_pixels, y_scores_pixels\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Ocurrió un error inesperado durante la obtención de datos a nivel de píxel para {ground_truth_mask_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# --- CONFIGURACIÓN DE RUTAS ---\n",
    "BASE_MAHALANOBIS_MAPS_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion_screw'\n",
    "BASE_IMAGE_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test'\n",
    "BASE_GT_MASK_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth' # Nueva ruta\n",
    "BASE_PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion_screw/evaluacion_roc'\n",
    "\n",
    "ROC_DATA_SAVE_DIR = '/home/imercatoma/FeatUp/roc_data_for_combined_plots'\n",
    "\n",
    "os.makedirs(BASE_PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "os.makedirs(ROC_DATA_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- FUNCIONES EXISTENTES ---\n",
    "def load_mahalanobis_maps(base_dir):\n",
    "    all_mahalanobis_maps = {}\n",
    "    classes = []\n",
    "\n",
    "    print(\"--- 1. Detectando clases y cargando mapas de Mahalanobis ---\")\n",
    "\n",
    "    for item in os.listdir(base_dir):\n",
    "        class_path = os.path.join(base_dir, item)\n",
    "        if os.path.isdir(class_path):\n",
    "            classes.append(item)\n",
    "\n",
    "    classes.sort()\n",
    "    valid_classes = [cls for cls in classes if cls not in ['evaluacion_roc', 'roc_data_for_combined_plots']]\n",
    "    print(f\"    Clases detectadas: {valid_classes}\")\n",
    "\n",
    "    map_filepaths = {}\n",
    "\n",
    "    for cls in valid_classes:\n",
    "        class_specific_maps_dir = os.path.join(base_dir, cls, 'mahalanobis_score_maps')\n",
    "\n",
    "        map_files = glob.glob(os.path.join(class_specific_maps_dir, 'maha_*.npy'), recursive=False)\n",
    "\n",
    "        if not map_files:\n",
    "            print(f\"Advertencia: No se encontraron archivos .npy para la clase '{cls}' en {class_specific_maps_dir}\")\n",
    "            all_mahalanobis_maps[cls] = []\n",
    "            map_filepaths[cls] = []\n",
    "            continue\n",
    "\n",
    "        class_maps = []\n",
    "        class_file_names = []\n",
    "        for f_path in map_files:\n",
    "            try:\n",
    "                map_data = np.load(f_path)\n",
    "                class_maps.append(map_data)\n",
    "\n",
    "                base_name = os.path.basename(f_path)\n",
    "                image_id = base_name.replace('maha_', '').split('.')[0]\n",
    "                \n",
    "                if image_id:\n",
    "                    class_file_names.append(image_id)\n",
    "                else:\n",
    "                    class_maps.pop()\n",
    "            except Exception as e:\n",
    "                print(f\"Error al cargar {f_path}: {e}\")\n",
    "        all_mahalanobis_maps[cls] = class_maps\n",
    "        map_filepaths[cls] = class_file_names\n",
    "        print(f\"    Total de mapas cargados para '{cls}': {len(class_maps)}\")\n",
    "    print(\"--- Mapas cargados exitosamente ---\\n\")\n",
    "    return all_mahalanobis_maps, valid_classes, map_filepaths\n",
    "\n",
    "\n",
    "def find_global_min_max_and_top_percentile_avg(mahalanobis_maps_dict, percentile_for_avg=1.0):\n",
    "    all_pixel_values = []\n",
    "    print(\"--- 2. Calculando mínimos, máximos globales y promedio del top 1% ---\")\n",
    "    for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "        if not maps_list:\n",
    "            continue\n",
    "        for map_array in maps_list:\n",
    "            if map_array.size > 0:\n",
    "                all_pixel_values.extend(map_array.flatten())\n",
    "\n",
    "    if not all_pixel_values:\n",
    "        print(\"Error: No se encontraron mapas o píxeles para calcular min/max/percentil globales.\")\n",
    "        return None, None, None\n",
    "\n",
    "    all_pixel_values = np.array(all_pixel_values)\n",
    "    min_final = np.min(all_pixel_values)\n",
    "    max_final = np.max(all_pixel_values)\n",
    "    \n",
    "    percentile_value = np.percentile(all_pixel_values, 100 - percentile_for_avg)\n",
    "    \n",
    "    top_percentile_values = all_pixel_values[all_pixel_values >= percentile_value]\n",
    "\n",
    "    if top_percentile_values.size == 0:\n",
    "        avg_top_percentile = max_final\n",
    "        print(f\"    Advertencia: No se encontraron valores por encima del percentil {100 - percentile_for_avg} para calcular el promedio. Usando max_final como promedio del top {percentile_for_avg}%.\")\n",
    "    else:\n",
    "        avg_top_percentile = np.mean(top_percentile_values)\n",
    "\n",
    "    print(f\"    Mínimo global (min_final): {min_final}\")\n",
    "    print(f\"    Máximo global (max_final): {max_final}\")\n",
    "    print(f\"    Umbral del percentil {100 - percentile_for_avg} (para el top {percentile_for_avg}%): {percentile_value:.4f}\")\n",
    "    print(f\"    Promedio de valores en el top {percentile_for_avg}%: {avg_top_percentile:.4f}\")\n",
    "    print(\"--- Cálculo de min/max globales y promedio del top 1% finalizado ---\\n\")\n",
    "    return min_final, max_final, avg_top_percentile\n",
    "\n",
    "def normalize_maps(mahalanobis_maps_dict, min_val, max_val_for_norm):\n",
    "    normalized_mahalanobis_maps = {}\n",
    "    print(\"--- 3. Normalizando y aplicando filtro Gaussiano (Sigma 10.0) a mapas de Mahalanobis ---\")\n",
    "\n",
    "    if max_val_for_norm <= min_val:\n",
    "        print(\"Advertencia: max_val_for_norm es menor o igual a min_val. La normalización resultará en 0 o 1.\")\n",
    "        for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "            normalized_class_maps = []\n",
    "            for map_array in maps_list:\n",
    "                normalized_map_np = np.full_like(map_array, 0.0, dtype=np.float32)\n",
    "                if map_array.size > 0 and (map_array.max() >= max_val_for_norm and max_val_for_norm != min_val):\n",
    "                    normalized_map_np = np.full_like(map_array, 1.0, dtype=np.float32)\n",
    "                elif map_array.size > 0 and max_val_for_norm == min_val and map_array.max() > min_val:\n",
    "                    normalized_map_np = np.full_like(map_array, 1.0, dtype=np.float32)\n",
    "                \n",
    "                # Convertir a tensor, aplicar suavizado, convertir de nuevo a numpy\n",
    "                smoothed_map_tensor = apply_gaussian_smoothing_to_single_map(torch.from_numpy(normalized_map_np).float(), sigma=10.0)\n",
    "                normalized_class_maps.append(smoothed_map_tensor.numpy())\n",
    "            normalized_mahalanobis_maps[cls] = normalized_class_maps\n",
    "        print(\"--- Normalización y suavizado finalizados (caso especial) ---\\n\")\n",
    "        return normalized_mahalanobis_maps\n",
    "\n",
    "    for cls, maps_list in mahalanobis_maps_dict.items():\n",
    "        normalized_class_maps = []\n",
    "        for i, map_array in enumerate(maps_list):\n",
    "            normalized_map_np = (map_array - min_val) / (max_val_for_norm - min_val)\n",
    "            normalized_map_np = np.clip(normalized_map_np, 0, 1) # Normalización estándar 0-1\n",
    "\n",
    "            # Convertir numpy array a tensor de PyTorch\n",
    "            map_tensor = torch.from_numpy(normalized_map_np).float()\n",
    "\n",
    "            # Aplicar suavizado Gaussiano con sigma=10.0\n",
    "            smoothed_map_tensor = apply_gaussian_smoothing_to_single_map(map_tensor, sigma=10.0)\n",
    "\n",
    "            # Convertir el tensor suavizado de nuevo a numpy array\n",
    "            normalized_class_maps.append(smoothed_map_tensor.numpy())\n",
    "        normalized_mahalanobis_maps[cls] = normalized_class_maps\n",
    "    print(\"--- Normalización y suavizado de mapas finalizados ---\\n\")\n",
    "    return normalized_mahalanobis_maps\n",
    "\n",
    "\n",
    "def apply_threshold_and_filter(score_map, threshold, min_area_pixels=500):\n",
    "    binary_mask = (score_map > threshold).astype(np.uint8) * 255\n",
    "    if np.sum(binary_mask) == 0:\n",
    "        return np.zeros_like(binary_mask)\n",
    "    labeled_mask = label(binary_mask)\n",
    "    filtered_mask = np.zeros_like(binary_mask)\n",
    "    for region in regionprops(labeled_mask):\n",
    "        if region.area >= min_area_pixels:\n",
    "            coords = region.coords\n",
    "            filtered_mask[coords[:, 0], coords[:, 1]] = 255\n",
    "    return filtered_mask\n",
    "\n",
    "def classify_image_anomaly(predicted_mask):\n",
    "    return np.sum(predicted_mask) > 0\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, optimal_thresholds_for_plotting, save_path, thresholds_roc_values, curve_type=\"Image-level\", category_name=\"\"):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    title = f'Curva ROC de Detección de Anomalías ({curve_type})'\n",
    "    if category_name:\n",
    "        title += f' ({category_name})'\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if optimal_thresholds_for_plotting is not None and len(optimal_thresholds_for_plotting) > 0:\n",
    "        for opt_thresh_plot in optimal_thresholds_for_plotting:\n",
    "            # Encuentra el índice del umbral más cercano para la anotación\n",
    "            idx = np.argmin(np.abs(thresholds_roc_values - opt_thresh_plot))\n",
    "            plt.plot(fpr[idx], tpr[idx], 'o', color='red', markersize=8)\n",
    "            plt.annotate(f'{opt_thresh_plot:.2f}', (fpr[idx], tpr[idx]), textcoords=\"offset points\", xytext=(5,-10), ha='center', color='red')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Curva ROC ({curve_type}) guardada en: {save_path}\")\n",
    "\n",
    "def visualize_overlay(image_path, score_map, threshold, min_area_pixels, save_path):\n",
    "    try:\n",
    "        original_image = cv2.imread(image_path)\n",
    "        if original_image is None:\n",
    "            print(f\"Error: No se pudo cargar la imagen original desde {image_path}\")\n",
    "            return\n",
    "        original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        filtered_mask = apply_threshold_and_filter(score_map, threshold, min_area_pixels)\n",
    "        overlay_color = np.array([255, 0, 0], dtype=np.uint8)\n",
    "        overlay = np.zeros_like(original_image_rgb, dtype=np.uint8)\n",
    "        overlay[filtered_mask > 0] = overlay_color\n",
    "        alpha = 0.4\n",
    "        overlaid_image = cv2.addWeighted(original_image_rgb, 1 - alpha, overlay, alpha, 0)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(overlaid_image)\n",
    "        plt.title(f'Anomalía Detectada (Umbral: {threshold:.4f})\\n{os.path.basename(image_path)}')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al visualizar la superposición para {image_path}: {e}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path, threshold, display_labels_true, display_labels_pred, title_suffix=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=display_labels_pred,\n",
    "                yticklabels=display_labels_true)\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.title(f'Matriz de Confusión {title_suffix} (Umbral: {threshold:.4f})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Matriz de Confusión {title_suffix} guardada en: {save_path}\")\n",
    "\n",
    "def calculate_and_print_metrics(y_true, y_pred, threshold, min_connected_component_area, auc_value):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if cm.shape == (2,2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    else:\n",
    "        specificity = float('nan')\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n--- Métricas de Rendimiento a Nivel de Imagen (Umbral: {threshold:.4f}, MCC Area: {min_connected_component_area}) ---\")\n",
    "    print(f\"    Accuracy:        {accuracy:.4f}\")\n",
    "    print(f\"    Precision:       {precision:.4f}\")\n",
    "    print(f\"    Recall (Sensibilidad): {recall:.4f}\")\n",
    "    print(f\"    Especificidad: {specificity:.4f}\")\n",
    "    print(f\"    F1-Score:        {f1:.4f}\")\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    return {\n",
    "        \"Umbral\": f\"{threshold:.4f}\",\n",
    "        \"Min_Connected_Component_Area\": min_connected_component_area,\n",
    "        \"AUC\": f\"{auc_value:.4f}\",\n",
    "        \"Accuracy\": f\"{accuracy:.4f}\",\n",
    "        \"Precision\": f\"{precision:.4f}\",\n",
    "        \"Recall (Sensibilidad)\": f\"{recall:.4f}\",\n",
    "        \"Especificidad\": f\"{specificity:.4f}\",\n",
    "        \"F1-Score\": f\"{f1:.4f}\"\n",
    "    }\n",
    "    \n",
    "def get_top_n_values_from_maps(mahalanobis_maps_dict, map_file_ids_dict, n=10):\n",
    "    print(f\"\\n--- Top {n} valores más altos de Mahalanobis para cada mapa ---\")\n",
    "    for cls_name, maps_list in mahalanobis_maps_dict.items():\n",
    "        file_ids = map_file_ids_dict.get(cls_name, [])\n",
    "        if not maps_list:\n",
    "            print(f\"    No hay mapas para la clase '{cls_name}'.\")\n",
    "            continue\n",
    "        print(f\" Clase: '{cls_name}'\")\n",
    "        for i, score_map in enumerate(maps_list):\n",
    "            if score_map.size == 0:\n",
    "                print(f\"      Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'}: Vacío.\")\n",
    "                continue\n",
    "            \n",
    "            flat_scores = score_map.flatten()\n",
    "            top_n_values = np.sort(flat_scores)[::-1][:n]\n",
    "            print(f\"      Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'} (Top {n}): {[f'{val:.4f}' for val in top_n_values]}\")\n",
    "    print(\"--- Fin de la visualización de los top valores ---\")\n",
    "\n",
    "def print_raw_top_10_mahalanobis_scores_from_loaded(mahalanobis_maps_dict, map_file_ids_dict, n=10):\n",
    "    print(f\"\\n--- Top {n} valores de Mahalanobis (RAW - Sin normalizar) ---\")\n",
    "    \n",
    "    for cls_name, maps_list in mahalanobis_maps_dict.items():\n",
    "        file_ids = map_file_ids_dict.get(cls_name, [])\n",
    "        if not maps_list:\n",
    "            print(f\"    Clase: '{cls_name}' - No hay mapas cargados.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Clase: '{cls_name}'\")\n",
    "        for i, score_map in enumerate(maps_list):\n",
    "            image_id = file_ids[i] if i < len(file_ids) else f'Index {i}'\n",
    "            \n",
    "            if score_map.size == 0:\n",
    "                print(f\"    Imagen: {image_id} - Mapa vacío.\")\n",
    "                continue\n",
    "\n",
    "            top_n_values = np.sort(score_map.flatten())[-n:]\n",
    "            \n",
    "            print(f\"    Imagen: {image_id}\")\n",
    "            print(f\"    Top {n} valores: {[f'{val:.3f}' for val in top_n_values]}\")\n",
    "    print(\"--- Fin de la visualización de los top valores raw ---\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_multi_class_binary_prediction_confusion_matrix(y_true_class_names, y_pred_binary_labels, save_path, threshold, title_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Genera una matriz de confusión con las clases verdaderas originales en el eje Y\n",
    "    y las predicciones binarias ('Normal'/'Anómalo') en el eje X.\n",
    "    \n",
    "    Args:\n",
    "        y_true_class_names (list): Lista de nombres de clases verdaderas (strings, ej. 'good', 'crack').\n",
    "        y_pred_binary_labels (list): Lista de etiquetas predichas binarias (strings, 'Normal' o 'Anómalo').\n",
    "        save_path (str): Ruta completa donde se guardará el gráfico.\n",
    "        threshold (float): Umbral utilizado para la evaluación.\n",
    "        title_suffix (str): Sufijo para el título del gráfico.\n",
    "    \"\"\"\n",
    "    if len(y_true_class_names) != len(y_pred_binary_labels):\n",
    "        print(\"Error: Las listas de etiquetas verdaderas y predichas tienen longitudes diferentes.\")\n",
    "        return\n",
    "\n",
    "    # 1. Definir el orden de las clases verdaderas para el eje Y\n",
    "    true_classes_unique = sorted(list(set(y_true_class_names)))\n",
    "    if 'good' in true_classes_unique:\n",
    "        true_classes_unique.remove('good')\n",
    "        true_classes_unique.insert(0, 'good') # Asegurar que 'good' esté al principio\n",
    "\n",
    "    num_true_classes = len(true_classes_unique)\n",
    "    \n",
    "    # 2. Definir las etiquetas de las predicciones binarias para el eje X\n",
    "    predicted_binary_labels_display = ['Normal', 'Anómalo']\n",
    "    num_pred_classes = len(predicted_binary_labels_display)\n",
    "\n",
    "    # 3. Crear mapeos de etiquetas a índices numéricos\n",
    "    true_label_to_idx = {label: i for i, label in enumerate(true_classes_unique)}\n",
    "    pred_binary_label_to_idx = {'Normal': 0, 'Anómalo': 1} # 'Normal' -> 0, 'Anómalo' -> 1\n",
    "\n",
    "    # 4. Inicializar una matriz de ceros con las dimensiones exactas deseadas (num_true_classes x 2)\n",
    "    custom_cm = np.zeros((num_true_classes, num_pred_classes), dtype=int)\n",
    "\n",
    "    # 5. Rellenar la matriz de confusión personalizada\n",
    "    for i in range(len(y_true_class_names)):\n",
    "        true_class = y_true_class_names[i]\n",
    "        predicted_binary_label = y_pred_binary_labels[i]\n",
    "\n",
    "        true_idx = true_label_to_idx.get(true_class)\n",
    "        pred_idx = pred_binary_label_to_idx.get(predicted_binary_label)\n",
    "\n",
    "        # Solo si ambas etiquetas son válidas, incrementamos el contador\n",
    "        if true_idx is not None and pred_idx is not None:\n",
    "            custom_cm[true_idx, pred_idx] += 1\n",
    "        else:\n",
    "            print(f\"Advertencia: Etiqueta inesperada encontrada. Verdadera: '{true_class}', Predicha: '{predicted_binary_label}'\")\n",
    "\n",
    "    # 6. Generar el heatmap con la matriz personalizada\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(custom_cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=predicted_binary_labels_display,\n",
    "                yticklabels=true_classes_unique)\n",
    "\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Clase Verdadera')\n",
    "    plt.title(f'Matriz de Confusión (Umbral: {threshold:.4f})', loc='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"✅ Matriz de Confusión {title_suffix} guardada en: {save_path}\")\n",
    "\n",
    "\n",
    "# --- EJECUCIÓN DE LOS PASOS ---\n",
    "if __name__ == \"__main__\":\n",
    "    current_category = os.path.basename(os.path.normpath(BASE_MAHALANOBIS_MAPS_DIR))\n",
    "    print(f\"\\n***** Procesando categoría: {current_category.upper()} *****\\n\")\n",
    "\n",
    "    mahalanobis_maps, MAP_CLASSES, MAP_FILE_IDS = load_mahalanobis_maps(BASE_MAHALANOBIS_MAPS_DIR)\n",
    "\n",
    "    print_raw_top_10_mahalanobis_scores_from_loaded(mahalanobis_maps, MAP_FILE_IDS, n=10)\n",
    "    get_top_n_values_from_maps(mahalanobis_maps, MAP_FILE_IDS, n=10)\n",
    "\n",
    "    CLASSES = [cls for cls in MAP_CLASSES if cls not in ['evaluacion_roc', 'roc_data_for_combined_plots', '']]\n",
    "    CLASSES.sort()\n",
    "    print(f\"    Clases finales para procesamiento: {CLASSES}\")\n",
    "\n",
    "    class_to_id = {cls_name: i for i, cls_name in enumerate(CLASSES)}\n",
    "    id_to_class = {i: cls_name for i, cls_name in enumerate(CLASSES)}\n",
    "    print(f\"\\n    Mapeo de clases a IDs: {class_to_id}\")\n",
    "\n",
    "    min_final_val, max_final_val_original, avg_top_percentile_val = find_global_min_max_and_top_percentile_avg(mahalanobis_maps, percentile_for_avg=0.1)\n",
    "\n",
    "    if min_final_val is None or avg_top_percentile_val is None:\n",
    "        print(\"No se pudo proceder con la normalización y evaluación debido a un error en el cálculo de min/max/promedio del top 1%.\")\n",
    "        exit()\n",
    "\n",
    "    # Aquí es donde se llama a normalize_maps, que ahora incluye el suavizado Gaussiano\n",
    "    normalized_mahalanobis_maps = normalize_maps(mahalanobis_maps, min_final_val, avg_top_percentile_val)\n",
    "\n",
    "    print(f\"\\nProceso completado para las clases: {CLASSES}\")\n",
    "\n",
    "    print(\"\\n--- 4. Evaluando a nivel de imagen para la curva ROC y preparando datos para métricas ---\")\n",
    "\n",
    "    MIN_CONNECTED_COMPONENT_AREA = 0\n",
    "\n",
    "    all_true_labels_binary_roc = []\n",
    "    all_anomaly_scores_for_roc = []\n",
    "\n",
    "    # Nuevas listas para la evaluación global a nivel de píxel\n",
    "    all_true_pixels = []\n",
    "    all_predicted_scores_pixels = []\n",
    "\n",
    "    predicted_label_to_id_detailed = {}\n",
    "    predicted_normal_id_detailed = 0\n",
    "    predicted_label_to_id_detailed['Predicted Normal'] = predicted_normal_id_detailed\n",
    "    \n",
    "    predicted_class_id_counter = 1\n",
    "\n",
    "    if 'good' in CLASSES:\n",
    "        predicted_label_to_id_detailed[f'Predicted Anomaly (from good)'] = predicted_class_id_counter\n",
    "        predicted_class_id_counter += 1\n",
    "\n",
    "    anomaly_classes = [cls for cls in CLASSES if cls != 'good']\n",
    "    anomaly_classes.sort()\n",
    "    for cls_anomaly in anomaly_classes:\n",
    "        predicted_label_to_id_detailed[f'Predicted {cls_anomaly.capitalize()} Anomaly'] = predicted_class_id_counter\n",
    "        predicted_class_id_counter += 1\n",
    "\n",
    "    print(\"    Recolectando puntuaciones de anomalía y etiquetas verdaderas (para ROC y CM)...\")\n",
    "\n",
    "    for cls_name in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls_name, [])\n",
    "        file_ids = MAP_FILE_IDS.get(cls_name, [])\n",
    "\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        gt_label_is_anomaly = (cls_name != 'good')\n",
    "\n",
    "        for i, score_map in tqdm(enumerate(maps_list), desc=f\"    Procesando mapas de {cls_name}\"):\n",
    "            image_max_anomaly_score = 0.0\n",
    "            if score_map.size > 0:\n",
    "                image_max_anomaly_score = np.max(score_map)\n",
    "\n",
    "            all_true_labels_binary_roc.append(1 if gt_label_is_anomaly else 0)\n",
    "            all_anomaly_scores_for_roc.append(image_max_anomaly_score)\n",
    "\n",
    "            # --- Recolección de datos a nivel de píxel ---\n",
    "            image_id = file_ids[i]\n",
    "            gt_mask_sub_dir = cls_name \n",
    "            gt_mask_filename = f\"{image_id}_mask.png\" \n",
    "            ground_truth_mask_full_path = os.path.join(BASE_GT_MASK_DIR, gt_mask_sub_dir, gt_mask_filename)\n",
    "            \n",
    "            y_true_pixels_img, y_scores_pixels_img = get_pixel_level_data(score_map, ground_truth_mask_full_path)\n",
    "            if y_true_pixels_img is not None and y_scores_pixels_img is not None:\n",
    "                all_true_pixels.extend(y_true_pixels_img)\n",
    "                all_predicted_scores_pixels.extend(y_scores_pixels_img)\n",
    "\n",
    "\n",
    "    print(f\"\\n[DEBUG] all_true_labels_binary_roc (first 10): {all_true_labels_binary_roc[:10]}\")\n",
    "    print(f\"[DEBUG] all_anomaly_scores_for_roc (first 10): {[f'{s:.4f}' for s in all_anomaly_scores_for_roc[:10]]}\")\n",
    "    print(f\"[DEBUG] Unique values in all_true_labels_binary_roc: {np.unique(all_true_labels_binary_roc)}\")\n",
    "    print(f\"[DEBUG] Unique values in all_anomaly_scores_for_roc: {np.unique(all_anomaly_scores_for_roc)}\")\n",
    "\n",
    "    category_name_for_roc = current_category\n",
    "\n",
    "    # --- Cálculo y Ploteo de Curva ROC a Nivel de Imagen ---\n",
    "    if len(np.unique(all_true_labels_binary_roc)) < 2:\n",
    "        print(\"\\nAdvertencia: Solo hay una clase en all_true_labels_binary_roc. No se puede calcular la curva ROC a nivel de imagen.\")\n",
    "        roc_auc_image_level = float('nan')\n",
    "        fpr_image_level, tpr_image_level, thresholds_roc_raw_image_level = np.array([0,1]), np.array([0,1]), np.array([0,1])\n",
    "    elif len(np.unique(all_anomaly_scores_for_roc)) < 2 or np.all(all_anomaly_scores_for_roc == all_anomaly_scores_for_roc[0]):\n",
    "        print(\"\\nAdvertencia: all_anomaly_scores_for_roc contiene solo un valor único o muy pocos que impiden ROC a nivel de imagen.\")\n",
    "        roc_auc_image_level = 0.5 \n",
    "        fpr_image_level, tpr_image_level, thresholds_roc_raw_image_level = np.array([0,1]), np.array([0,1]), np.array([0,1])\n",
    "    else:\n",
    "        fpr_image_level, tpr_image_level, thresholds_roc_raw_image_level = roc_curve(all_true_labels_binary_roc, all_anomaly_scores_for_roc)\n",
    "        roc_auc_image_level = auc(fpr_image_level, tpr_image_level)\n",
    "\n",
    "    print(f\"\\n--- Cálculo de ROC y AUC (Nivel de Imagen) finalizado ---\")\n",
    "    print(f\"Área Bajo la Curva (AUC - Nivel de Imagen): {roc_auc_image_level:.4f}\")\n",
    "\n",
    "    roc_data_filename_image = f\"roc_data_image_level_{category_name_for_roc}.json\"\n",
    "    roc_data_filepath_image = os.path.join(ROC_DATA_SAVE_DIR, roc_data_filename_image)\n",
    "\n",
    "    roc_data_to_save_image = {\n",
    "        'category': category_name_for_roc,\n",
    "        'fpr': fpr_image_level.tolist(),\n",
    "        'tpr': tpr_image_level.tolist(),\n",
    "        'roc_auc': roc_auc_image_level\n",
    "    }\n",
    "\n",
    "    with open(roc_data_filepath_image, 'w') as f:\n",
    "        json.dump(roc_data_to_save_image, f)\n",
    "    print(f\"✅ Datos de la curva ROC (Nivel de Imagen) para '{category_name_for_roc}' guardados en: {roc_data_filepath_image}\")\n",
    "\n",
    "    optimal_thresholds_for_plotting_image = []\n",
    "    optimal_thresholds_for_metrics_image = []\n",
    "\n",
    "    if not np.isnan(roc_auc_image_level) and roc_auc_image_level > 0:\n",
    "        youden_j = tpr_image_level - fpr_image_level\n",
    "        best_idx = np.argmax(youden_j)\n",
    "\n",
    "        if len(thresholds_roc_raw_image_level) > best_idx and thresholds_roc_raw_image_level[best_idx] not in optimal_thresholds_for_metrics_image:\n",
    "            optimal_thresholds_for_metrics_image.append(thresholds_roc_raw_image_level[best_idx])\n",
    "            optimal_thresholds_for_plotting_image.append(thresholds_roc_raw_image_level[best_idx])\n",
    "        \n",
    "        # Añadir algunos umbrales representativos\n",
    "        unique_thresholds_sorted = sorted(list(np.unique(thresholds_roc_raw_image_level)))\n",
    "        num_to_add = 5 - len(optimal_thresholds_for_metrics_image)\n",
    "        if num_to_add > 0:\n",
    "            step = max(1, len(unique_thresholds_sorted) // (num_to_add + 1))\n",
    "            for i in range(step, len(unique_thresholds_sorted), step):\n",
    "                if len(optimal_thresholds_for_metrics_image) >= 5:\n",
    "                    break\n",
    "                current_threshold = unique_thresholds_sorted[i]\n",
    "                if 0.001 < current_threshold < 0.999 and current_threshold not in optimal_thresholds_for_metrics_image:\n",
    "                    idx = np.where(thresholds_roc_raw_image_level == current_threshold)[0][0]\n",
    "                    if (fpr_image_level[idx] > 0 or tpr_image_level[idx] > 0) and (fpr_image_level[idx] < 1 or tpr_image_level[idx] < 1):\n",
    "                        optimal_thresholds_for_metrics_image.append(current_threshold)\n",
    "                        optimal_thresholds_for_plotting_image.append(current_threshold)\n",
    "        \n",
    "        optimal_thresholds_for_metrics_image.sort()\n",
    "        optimal_thresholds_for_plotting_image.sort()\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Umbrales 'Óptimos' detectados (Nivel de Imagen) ---\")\n",
    "    if not optimal_thresholds_for_metrics_image:\n",
    "        print(\"    No se pudieron encontrar umbrales óptimos únicos en el rango (0,1) para el nivel de imagen.\")\n",
    "    for i, opt_thresh in enumerate(optimal_thresholds_for_metrics_image):\n",
    "        idx = np.argmin(np.abs(thresholds_roc_raw_image_level - opt_thresh))\n",
    "        print(f\"    Umbral {i+1}: {opt_thresh:.4f} (TPR: {tpr_image_level[idx]:.4f}, FPR: {fpr_image_level[idx]:.4f})\")\n",
    "\n",
    "    roc_save_path_image = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'roc_curve_image_level.png')\n",
    "    plot_roc_curve(fpr_image_level, tpr_image_level, roc_auc_image_level, optimal_thresholds_for_plotting_image, roc_save_path_image, thresholds_roc_raw_image_level, \"Image-level\", current_category)\n",
    "\n",
    "    selected_threshold_for_eval = None\n",
    "    if optimal_thresholds_for_metrics_image:\n",
    "        selected_threshold_for_eval = 0.54 #optimal_thresholds_for_metrics_image[0]\n",
    "        print(f\"\\n    Umbral seleccionado para visualización y métricas: {selected_threshold_for_eval:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nAdvertencia: No se encontraron umbrales óptimos. Usando un umbral por defecto de 0.5 para visualización y métricas.\")\n",
    "        selected_threshold_for_eval = 0.5\n",
    "\n",
    "    if selected_threshold_for_eval is None:\n",
    "        print(\"No se pudo determinar un umbral para la evaluación. No se realizarán las visualizaciones, matriz de confusión ni tabla de métricas.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"\\n--- Generando predicciones finales con el umbral seleccionado ({selected_threshold_for_eval:.4f}) ---\")\n",
    "    all_predicted_labels_cm_binary = []\n",
    "    all_true_labels_cm_detailed = []\n",
    "    all_predicted_labels_cm_detailed = []\n",
    "\n",
    "    for cls_name in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls_name, [])\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        gt_label_is_anomaly = (cls_name != 'good')\n",
    "        gt_label_for_class_id_true_detailed_cm = class_to_id[cls_name]\n",
    "\n",
    "        for score_map in tqdm(maps_list, desc=f\"    Aplicando umbral para {cls_name}\"):\n",
    "            binary_mask = apply_threshold_and_filter(score_map, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA)\n",
    "            is_predicted_anomaly = classify_image_anomaly(binary_mask)\n",
    "\n",
    "            all_predicted_labels_cm_binary.append(1 if is_predicted_anomaly else 0)\n",
    "\n",
    "            all_true_labels_cm_detailed.append(gt_label_for_class_id_true_detailed_cm)\n",
    "            if not is_predicted_anomaly:\n",
    "                all_predicted_labels_cm_detailed.append(predicted_label_to_id_detailed['Predicted Normal'])\n",
    "            else:\n",
    "                if cls_name == 'good':\n",
    "                    all_predicted_labels_cm_detailed.append(predicted_label_to_id_detailed['Predicted Anomaly (from good)'])\n",
    "                else:\n",
    "                    all_predicted_labels_cm_detailed.append(predicted_label_to_id_detailed[f'Predicted {cls_name.capitalize()} Anomaly'])\n",
    "\n",
    "\n",
    "    print(\"\\n--- 5.1: Generando Matriz de Confusión Binaria (Normal vs. Anómala) ---\")\n",
    "\n",
    "    cm_binary_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, f'confusion_matrix_binary_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "\n",
    "    display_labels_true_binary = ['Normal (Good)', 'Anomalous (Any Type)']\n",
    "    display_labels_pred_binary = ['Predicted Normal', 'Predicted Anomalous']\n",
    "\n",
    "    if len(all_true_labels_binary_roc) != len(all_predicted_labels_cm_binary):\n",
    "        print(f\"Error: Longitud de etiquetas verdaderas ({len(all_true_labels_binary_roc)}) y predichas ({len(all_predicted_labels_cm_binary)}) para CM binaria no coinciden.\")\n",
    "    else:\n",
    "        plot_confusion_matrix(all_true_labels_binary_roc, all_predicted_labels_cm_binary, cm_binary_save_path,\n",
    "                              selected_threshold_for_eval, display_labels_true_binary, display_labels_pred_binary,\n",
    "                              title_suffix=\" - Binary\")\n",
    "\n",
    "    \n",
    "    print(f\"\\n--- Generando predicciones finales con el umbral seleccionado ({selected_threshold_for_eval:.4f}) ---\")\n",
    "    all_predicted_labels_cm_binary = []\n",
    "    \n",
    "    # Estas son las listas que ya habías pedido y no se modifican.\n",
    "    all_true_class_names_for_cm = []\n",
    "    all_predicted_binary_labels_for_cm = [] \n",
    "\n",
    "    for cls_name in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls_name, [])\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        gt_label_is_anomaly = (cls_name != 'good')\n",
    "        \n",
    "        for score_map in tqdm(maps_list, desc=f\"    Aplicando umbral para {cls_name}\"):\n",
    "            binary_mask = apply_threshold_and_filter(score_map, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA)\n",
    "            is_predicted_anomaly = classify_image_anomaly(binary_mask)\n",
    "\n",
    "            # Para la matriz de confusión binaria 2x2 (True Anomaly vs Predicted Anomaly)\n",
    "            all_predicted_labels_cm_binary.append(1 if is_predicted_anomaly else 0)\n",
    "\n",
    "            # Para la matriz de confusión 5x2 (True Class vs Predicted Binary)\n",
    "            all_true_class_names_for_cm.append(cls_name) # Nombre de la clase verdadera\n",
    "            all_predicted_binary_labels_for_cm.append('Anómalo' if is_predicted_anomaly else 'Normal') # Predicción binaria\n",
    "\n",
    "    print(\"\\n--- 5.1: Generando Matriz de Confusión Binaria (Normal vs. Anómala) ---\")\n",
    "\n",
    "    cm_binary_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, f'confusion_matrix_binary_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "\n",
    "    display_labels_true_binary = ['Normal (Good)', 'Anomalous (Any Type)']\n",
    "    display_labels_pred_binary = ['Predicted Normal', 'Predicted Anomalous']\n",
    "\n",
    "    if len(all_true_labels_binary_roc) != len(all_predicted_labels_cm_binary):\n",
    "        print(f\"Error: Longitud de etiquetas verdaderas ({len(all_true_labels_binary_roc)}) y predichas ({len(all_predicted_labels_cm_binary)}) para CM binaria no coinciden.\")\n",
    "    else:\n",
    "        plot_confusion_matrix(all_true_labels_binary_roc, all_predicted_labels_cm_binary, cm_binary_save_path,\n",
    "                              selected_threshold_for_eval, display_labels_true_binary, display_labels_pred_binary,\n",
    "                              title_suffix=\" - Binary\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- 5.2: Generando Matriz de Confusión Detallada (True Class vs. Predicted Binary) ---\")\n",
    "\n",
    "    cm_multi_binary_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, f'confusion_matrix_multi_binary_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "    \n",
    "    # Llamada a la función corregida para la matriz 5x2\n",
    "    plot_multi_class_binary_prediction_confusion_matrix(\n",
    "        all_true_class_names_for_cm,\n",
    "        all_predicted_binary_labels_for_cm,\n",
    "        cm_multi_binary_save_path,\n",
    "        selected_threshold_for_eval,\n",
    "        title_suffix=\" - Multi-Class vs. Binary Prediction\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n--- 6. Calculando, mostrando y guardando Tabla de Métricas de Rendimiento (Nivel de Imagen) ---\")\n",
    "    metrics_data = calculate_and_print_metrics(all_true_labels_binary_roc, all_predicted_labels_cm_binary, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA, roc_auc_image_level)\n",
    "\n",
    "    # Convertir a JSON en lugar de Excel\n",
    "    image_level_metrics_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'image_level_metrics.json')\n",
    "\n",
    "    # Si ya existe, cargar y añadir. Si no, crear.\n",
    "    if os.path.exists(image_level_metrics_save_path):\n",
    "        try:\n",
    "            with open(image_level_metrics_save_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "            if not isinstance(existing_data, list): # Asegurarse de que sea una lista para añadir\n",
    "                existing_data = [existing_data] if existing_data else []\n",
    "            existing_data.append(metrics_data)\n",
    "            with open(image_level_metrics_save_path, 'w') as f:\n",
    "                json.dump(existing_data, f, indent=4)\n",
    "            print(f\"✅ Métricas añadidas al archivo JSON existente: {image_level_metrics_save_path}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"⚠️ Error al leer el archivo JSON existente. Creando uno nuevo. Error: {e}\")\n",
    "            with open(image_level_metrics_save_path, 'w') as f:\n",
    "                json.dump([metrics_data], f, indent=4)\n",
    "            print(f\"✅ Métricas guardadas en un nuevo archivo JSON: {image_level_metrics_save_path}\")\n",
    "    else:\n",
    "        with open(image_level_metrics_save_path, 'w') as f:\n",
    "            json.dump([metrics_data], f, indent=4)\n",
    "        print(f\"✅ Métricas guardadas en un nuevo archivo JSON: {image_level_metrics_save_path}\")\n",
    "\n",
    "    # --- NUEVO BLOQUE: EVALUACIÓN GLOBAL A NIVEL DE PÍXEL (AUROC-Píxel y Curva ROC) ---\n",
    "    print(\"\\n--- 7. Evaluando a nivel de Píxel (AUROC-Píxel Global y Curva ROC) ---\")\n",
    "\n",
    "    if len(np.unique(all_true_pixels)) < 2:\n",
    "        print(\"\\nAdvertencia: No hay suficientes clases en los píxeles de ground truth para calcular la curva ROC a nivel de píxel.\")\n",
    "        pixel_auroc_global = float('nan')\n",
    "        fpr_pixel_level, tpr_pixel_level, thresholds_roc_raw_pixel_level = np.array([0,1]), np.array([0,1]), np.array([0,1])\n",
    "    elif len(np.unique(all_predicted_scores_pixels)) < 2 or np.all(all_predicted_scores_pixels == all_predicted_scores_pixels[0]):\n",
    "        print(\"\\nAdvertencia: Los scores predichos a nivel de píxel contienen solo un valor único o muy pocos que impiden ROC.\")\n",
    "        pixel_auroc_global = 0.5\n",
    "        fpr_pixel_level, tpr_pixel_level, thresholds_roc_raw_pixel_level = np.array([0,1]), np.array([0,1]), np.array([0,1])\n",
    "    else:\n",
    "        fpr_pixel_level, tpr_pixel_level, thresholds_roc_raw_pixel_level = roc_curve(all_true_pixels, all_predicted_scores_pixels)\n",
    "        pixel_auroc_global = auc(fpr_pixel_level, tpr_pixel_level)\n",
    "\n",
    "    print(f\"\\n--- Cálculo de ROC y AUC (Nivel de Píxel Global) finalizado ---\")\n",
    "    print(f\"Área Bajo la Curva (AUC - Nivel de Píxel Global): {pixel_auroc_global:.4f}\")\n",
    "\n",
    "    # Guarda los datos de la curva ROC a nivel de píxel\n",
    "    roc_data_filename_pixel = f\"roc_data_pixel_level_{category_name_for_roc}.json\"\n",
    "    roc_data_filepath_pixel = os.path.join(ROC_DATA_SAVE_DIR, roc_data_filename_pixel)\n",
    "\n",
    "    roc_data_to_save_pixel = {\n",
    "        'category': category_name_for_roc,\n",
    "        'fpr': fpr_pixel_level.tolist(),\n",
    "        'tpr': tpr_pixel_level.tolist(),\n",
    "        'roc_auc': pixel_auroc_global\n",
    "    }\n",
    "\n",
    "    with open(roc_data_filepath_pixel, 'w') as f:\n",
    "        json.dump(roc_data_to_save_pixel, f)\n",
    "    print(f\"✅ Datos de la curva ROC (Nivel de Píxel) para '{category_name_for_roc}' guardados en: {roc_data_filepath_pixel}\")\n",
    "\n",
    "    # Plotea la curva ROC a nivel de píxel\n",
    "    roc_save_path_pixel = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'roc_curve_pixel_level.png')\n",
    "    plot_roc_curve(fpr_pixel_level, tpr_pixel_level, pixel_auroc_global, None, roc_save_path_pixel, thresholds_roc_raw_pixel_level, \"Pixel-level\", current_category)\n",
    "\n",
    "    # También puedes guardar el AUROC-Píxel global en un JSON para métricas generales\n",
    "    pixel_metrics_data = {\n",
    "        \"Overall_Pixel_AUROC\": f\"{pixel_auroc_global:.4f}\" if not np.isnan(pixel_auroc_global) else \"N/A\"\n",
    "    }\n",
    "    pixel_metrics_save_path = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'pixel_level_summary_metrics.json')\n",
    "    with open(pixel_metrics_save_path, 'w') as f:\n",
    "        json.dump(pixel_metrics_data, f, indent=4)\n",
    "    print(f\"✅ Métricas resumen a nivel de píxel guardadas en: {pixel_metrics_save_path}\")\n",
    "\n",
    "    # --- NUEVO BLOQUE: 8. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\n",
    "    print(\"\\n--- 8. Generando visualizaciones de máscaras de anomalía para TODOS los mapas de Mahalanobis cargados ---\")\n",
    "    print(f\"     (Las imágenes se guardarán en: {os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'overlays_all_images')})\")\n",
    "\n",
    "    overlays_save_dir = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'overlays_all_images')\n",
    "    os.makedirs(overlays_save_dir, exist_ok=True)\n",
    "\n",
    "    total_visualizations = 0\n",
    "    for cls in CLASSES:\n",
    "        maps_list = normalized_mahalanobis_maps.get(cls, [])\n",
    "        file_ids = MAP_FILE_IDS.get(cls, [])\n",
    "\n",
    "        if not maps_list:\n",
    "            continue\n",
    "\n",
    "        print(f\"     Procesando visualizaciones para la clase: '{cls}' ({len(maps_list)} imágenes)\")\n",
    "        for i, score_map in enumerate(tqdm(maps_list, desc=f\"     Generando overlays para {cls}\")):\n",
    "            image_id = file_ids[i]\n",
    "            # Construye la ruta a la imagen original correctamente\n",
    "            original_image_path = os.path.join(BASE_IMAGE_DIR, cls, image_id + '.png')\n",
    "\n",
    "            if os.path.exists(original_image_path):\n",
    "                save_viz_path = os.path.join(overlays_save_dir, f'overlay_{cls}_{image_id}_thresh_{selected_threshold_for_eval:.4f}.png')\n",
    "                visualize_overlay(original_image_path, score_map, selected_threshold_for_eval, MIN_CONNECTED_COMPONENT_AREA, save_viz_path)\n",
    "                total_visualizations += 1\n",
    "            else:\n",
    "                print(f\"Advertencia: La imagen original no se encontró en {original_image_path}. No se generó visualización para esta.\")\n",
    "\n",
    "    print(f\"\\n¡Se generaron {total_visualizations} visualizaciones de máscaras de anomalía!\")\n",
    "\n",
    "    print(\"\\n¡Proceso de evaluación completado!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_featup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
