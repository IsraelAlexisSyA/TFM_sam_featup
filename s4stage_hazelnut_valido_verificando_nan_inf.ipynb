{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta para guardar score maps: /home/imercatoma/FeatUp/graficas_evaluacion/good/mahalanobis_score_maps\n",
      "Cargando datos del coreset...\n",
      "Coreset cargado. Dimensión: torch.Size([10009, 384])\n",
      "NearestNeighbors finder inicializado.\n",
      "Cargando modelo DINOv2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo DINOv2 cargado.\n",
      "Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\n",
      "Modelo SAM2 cargado.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/good/000.png ---\n",
      "Ground Truth Mask Path para 000: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/good/000_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (391, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([391, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3679 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 2\n",
      "Mascara 1: Area=630909, IOU=0.9962953925132751, Stability Score=0.9905163049697876\n",
      "Mascara 2: Area=362088, IOU=0.9849311113357544, Stability Score=0.8678728938102722\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/query_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/query_mask_2.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 2\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 365.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 2\n",
      "Mascara 1: Area=638604, IOU=0.9972633123397827, Stability Score=0.9739595651626587\n",
      "Mascara 2: Area=398162, IOU=0.9915557503700256, Stability Score=0.9758809208869934\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/similar_mask_overlay_365_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/similar_mask_overlay_365_mask_2.png\n",
      "Máscaras procesadas para vecino 1: 2.\n",
      "--- Procesando vecino 2: 076.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 3\n",
      "Mascara 1: Area=660766, IOU=0.9970945119857788, Stability Score=0.974249005317688\n",
      "Mascara 2: Area=347489, IOU=0.9880197644233704, Stability Score=0.7952451705932617\n",
      "Mascara 3: Area=378508, IOU=0.9141557812690735, Stability Score=0.670792818069458\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/similar_mask_overlay_076_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/similar_mask_overlay_076_mask_2.png\n",
      "Máscara 3 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/similar_mask_overlay_076_mask_3.png\n",
      "Máscaras procesadas para vecino 2: 3.\n",
      "--- Procesando vecino 3: 046.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 2\n",
      "Mascara 1: Area=651717, IOU=0.9969251751899719, Stability Score=0.9739989638328552\n",
      "Mascara 2: Area=381827, IOU=0.9947112798690796, Stability Score=0.9846208095550537\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/similar_mask_overlay_046_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/000/processed_masks/similar_mask_overlay_046_mask_2.png\n",
      "Máscaras procesadas para vecino 3: 2.\n",
      "Tiempo total de ejecución de SAM: 125.5813 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([2, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([2, 384])\n",
      "Máximo de fobj_q_pooled: 5.985988140106201\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.18710847198963165\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9764, 0.8243, 0.9000],\n",
      "        [0.8453, 0.9718, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17388.9277,  3799.8679,  8103.0840],\n",
      "        [ 4687.2236, 16617.1113,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9647, 0.8359, 0.9000],\n",
      "        [0.8511, 0.9715, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[15478.8848,  4267.0210,  8103.0840],\n",
      "        [ 4971.5840, 16571.4395,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9727, 0.8487, 0.9000],\n",
      "        [0.8307, 0.9626, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16772.5527,  4851.3296,  8103.0840],\n",
      "        [ 4053.7625, 15157.2607,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5528, 0.1291],\n",
      "        [0.1444, 0.5473]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5528, 0.1291, 0.3180],\n",
      "        [0.1444, 0.5473, 0.3083],\n",
      "        [0.3027, 0.3236, 0.3737]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5528, 0.1291, 0.3180, 1.0000],\n",
      "        [0.1444, 0.5473, 0.3083, 1.0000],\n",
      "        [0.3027, 0.3236, 0.3737, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5528 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3180\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5473 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.3083\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5275, 0.1471],\n",
      "        [0.1589, 0.5358]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5275, 0.1471, 0.3254],\n",
      "        [0.1589, 0.5358, 0.3052],\n",
      "        [0.3135, 0.3171, 0.3694]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5275, 0.1471, 0.3254, 1.0000],\n",
      "        [0.1589, 0.5358, 0.3052, 1.0000],\n",
      "        [0.3135, 0.3171, 0.3694, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5275 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3254\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5358 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.3052\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5410, 0.1558],\n",
      "        [0.1420, 0.5287]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5410, 0.1558, 0.3032],\n",
      "        [0.1420, 0.5287, 0.3293],\n",
      "        [0.3169, 0.3155, 0.3676]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5410, 0.1558, 0.3032, 1.0000],\n",
      "        [0.1420, 0.5287, 0.3293, 1.0000],\n",
      "        [0.3169, 0.3155, 0.3676, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5410 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3032\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5287 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.3293\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "  Query 1: [(0, 1), (1, 1), (2, 1)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "  Query 1: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Total de mapas de matching válidos: 2\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 2\n",
      "Construyendo mapa agregado de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 2\n",
      "Max values across all combined_individual_score_maps: [135.7022247314453, 95.31671905517578]\n",
      "Construyendo mapa total de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion/good/mahalanobis_score_maps/maha_000.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [130.63783 130.64    130.64001 130.64177 130.6439  130.64615 130.64671\n",
      " 130.64862 130.64896 130.65085]\n",
      "Imagen: 001\n",
      "Top 10 valores: [121.93909  121.93981  121.94106  121.941605 121.94334  121.94579\n",
      " 121.94722  121.94844  121.94962  121.95089 ]\n",
      "Imagen: 002\n",
      "Top 10 valores: [159.20613 159.2099  159.21487 159.2168  159.21877 159.22012 159.22807\n",
      " 159.23143 159.23181 159.2352 ]\n",
      "Imagen: 003\n",
      "Top 10 valores: [90.54045  90.540596 90.54112  90.5427   90.54343  90.54347  90.54426\n",
      " 90.54447  90.54682  90.54753 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [177.4541  177.45674 177.49045 177.55031 177.58707 177.60652 177.61841\n",
      " 177.64578 177.64893 177.67104]\n",
      "Imagen: 005\n",
      "Top 10 valores: [100.25033  100.25131  100.25152  100.252045 100.25205  100.25245\n",
      " 100.254364 100.25468  100.25583  100.25591 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.55551  124.5569   124.558365 124.559746 124.56041  124.56084\n",
      " 124.56212  124.56332  124.56372  124.565   ]\n",
      "Imagen: 007\n",
      "Top 10 valores: [102.34186  102.3467   102.346725 102.353806 102.353905 102.35399\n",
      " 102.35615  102.35625  102.36113  102.363464]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/good/001.png ---\n",
      "Ground Truth Mask Path para 001: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/good/001_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (391, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([391, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.1916 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 1\n",
      "Mascara 1: Area=692203, IOU=0.9969401359558105, Stability Score=0.986197829246521\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/001/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 364.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 1\n",
      "Mascara 1: Area=691592, IOU=0.9976289868354797, Stability Score=0.9794809222221375\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/001/processed_masks/similar_mask_overlay_364_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 102.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 3\n",
      "Mascara 1: Area=679103, IOU=0.997260332107544, Stability Score=0.9754616618156433\n",
      "Mascara 2: Area=351990, IOU=0.9884939789772034, Stability Score=0.8633742332458496\n",
      "Mascara 3: Area=356947, IOU=0.9601908922195435, Stability Score=0.6853246092796326\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/001/processed_masks/similar_mask_overlay_102_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/001/processed_masks/similar_mask_overlay_102_mask_2.png\n",
      "Máscara 3 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/001/processed_masks/similar_mask_overlay_102_mask_3.png\n",
      "Máscaras procesadas para vecino 2: 3.\n",
      "--- Procesando vecino 3: 200.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 1\n",
      "Mascara 1: Area=667935, IOU=0.996697187423706, Stability Score=0.9784901142120361\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/001/processed_masks/similar_mask_overlay_200_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 117.5575 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.341162204742432\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.18449775874614716\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9716, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16578.8047,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9700, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16313.7451,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9648, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[15498.1748,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5885]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5885, 0.4115],\n",
      "        [0.4115, 0.5885]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5885, 0.4115, 1.0000],\n",
      "        [0.4115, 0.5885, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5885 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4115\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5866]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5866, 0.4134],\n",
      "        [0.4134, 0.5866]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5866, 0.4134, 1.0000],\n",
      "        [0.4134, 0.5866, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5866 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4134\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5804]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5804, 0.4196],\n",
      "        [0.4196, 0.5804]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5804, 0.4196, 1.0000],\n",
      "        [0.4196, 0.5804, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5804 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4196\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [131.04901123046875]\n",
      "Construyendo mapa total de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion/good/mahalanobis_score_maps/maha_001.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [130.63783 130.64    130.64001 130.64177 130.6439  130.64615 130.64671\n",
      " 130.64862 130.64896 130.65085]\n",
      "Imagen: 001\n",
      "Top 10 valores: [130.94908 130.95178 130.9522  130.95619 130.95853 130.95912 130.96074\n",
      " 130.96135 130.96301 130.96529]\n",
      "Imagen: 002\n",
      "Top 10 valores: [159.20613 159.2099  159.21487 159.2168  159.21877 159.22012 159.22807\n",
      " 159.23143 159.23181 159.2352 ]\n",
      "Imagen: 003\n",
      "Top 10 valores: [90.54045  90.540596 90.54112  90.5427   90.54343  90.54347  90.54426\n",
      " 90.54447  90.54682  90.54753 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [177.4541  177.45674 177.49045 177.55031 177.58707 177.60652 177.61841\n",
      " 177.64578 177.64893 177.67104]\n",
      "Imagen: 005\n",
      "Top 10 valores: [100.25033  100.25131  100.25152  100.252045 100.25205  100.25245\n",
      " 100.254364 100.25468  100.25583  100.25591 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.55551  124.5569   124.558365 124.559746 124.56041  124.56084\n",
      " 124.56212  124.56332  124.56372  124.565   ]\n",
      "Imagen: 007\n",
      "Top 10 valores: [102.34186  102.3467   102.346725 102.353806 102.353905 102.35399\n",
      " 102.35615  102.35625  102.36113  102.363464]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/good/002.png ---\n",
      "Ground Truth Mask Path para 002: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/good/002_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (391, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([391, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.4564 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 1\n",
      "Mascara 1: Area=714788, IOU=0.9962871074676514, Stability Score=0.9863422513008118\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/002/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 339.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 1\n",
      "Mascara 1: Area=708642, IOU=0.9971056580543518, Stability Score=0.9730634689331055\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/002/processed_masks/similar_mask_overlay_339_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 130.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 2\n",
      "Mascara 1: Area=702871, IOU=0.997661828994751, Stability Score=0.9774047136306763\n",
      "Mascara 2: Area=330521, IOU=0.8297341465950012, Stability Score=0.4493637979030609\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/002/processed_masks/similar_mask_overlay_130_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/002/processed_masks/similar_mask_overlay_130_mask_2.png\n",
      "Máscaras procesadas para vecino 2: 2.\n",
      "--- Procesando vecino 3: 361.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 1\n",
      "Mascara 1: Area=689105, IOU=0.9973211884498596, Stability Score=0.9751039743423462\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/002/processed_masks/similar_mask_overlay_361_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 123.0487 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 5.465260982513428\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.18073700368404388\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9743, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17037.0547,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9503, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[13400.8789,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9444, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[12635.3760,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5918]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5918, 0.4082],\n",
      "        [0.4082, 0.5918]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5918, 0.4082, 1.0000],\n",
      "        [0.4082, 0.5918, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5918 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4082\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5626]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5626, 0.4374],\n",
      "        [0.4374, 0.5626]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5626, 0.4374, 1.0000],\n",
      "        [0.4374, 0.5626, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5626 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4374\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5553]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5553, 0.4447],\n",
      "        [0.4447, 0.5553]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5553, 0.4447, 1.0000],\n",
      "        [0.4447, 0.5553, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5553 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4447\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [151.2084197998047]\n",
      "Construyendo mapa total de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion/good/mahalanobis_score_maps/maha_002.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [130.63783 130.64    130.64001 130.64177 130.6439  130.64615 130.64671\n",
      " 130.64862 130.64896 130.65085]\n",
      "Imagen: 001\n",
      "Top 10 valores: [130.94908 130.95178 130.9522  130.95619 130.95853 130.95912 130.96074\n",
      " 130.96135 130.96301 130.96529]\n",
      "Imagen: 002\n",
      "Top 10 valores: [151.03262 151.03616 151.04189 151.04536 151.04852 151.04869 151.05133\n",
      " 151.05453 151.05809 151.06123]\n",
      "Imagen: 003\n",
      "Top 10 valores: [90.54045  90.540596 90.54112  90.5427   90.54343  90.54347  90.54426\n",
      " 90.54447  90.54682  90.54753 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [177.4541  177.45674 177.49045 177.55031 177.58707 177.60652 177.61841\n",
      " 177.64578 177.64893 177.67104]\n",
      "Imagen: 005\n",
      "Top 10 valores: [100.25033  100.25131  100.25152  100.252045 100.25205  100.25245\n",
      " 100.254364 100.25468  100.25583  100.25591 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.55551  124.5569   124.558365 124.559746 124.56041  124.56084\n",
      " 124.56212  124.56332  124.56372  124.565   ]\n",
      "Imagen: 007\n",
      "Top 10 valores: [102.34186  102.3467   102.346725 102.353806 102.353905 102.35399\n",
      " 102.35615  102.35625  102.36113  102.363464]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/good/003.png ---\n",
      "Ground Truth Mask Path para 003: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/good/003_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (391, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([391, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.1184 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 2\n",
      "Mascara 1: Area=687012, IOU=0.9970623850822449, Stability Score=0.9865886569023132\n",
      "Mascara 2: Area=355233, IOU=0.9906294941902161, Stability Score=0.953530490398407\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/query_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/query_mask_2.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 2\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 102.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 3\n",
      "Mascara 1: Area=679103, IOU=0.997260332107544, Stability Score=0.9754616618156433\n",
      "Mascara 2: Area=351990, IOU=0.9884939789772034, Stability Score=0.8633742332458496\n",
      "Mascara 3: Area=356947, IOU=0.9601908922195435, Stability Score=0.6853246092796326\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/similar_mask_overlay_102_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/similar_mask_overlay_102_mask_2.png\n",
      "Máscara 3 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/similar_mask_overlay_102_mask_3.png\n",
      "Máscaras procesadas para vecino 1: 3.\n",
      "--- Procesando vecino 2: 364.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 1\n",
      "Mascara 1: Area=691592, IOU=0.9976289868354797, Stability Score=0.9794809222221375\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/similar_mask_overlay_364_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 049.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 3\n",
      "Mascara 1: Area=656344, IOU=0.9974708557128906, Stability Score=0.9759924411773682\n",
      "Mascara 2: Area=378870, IOU=0.9913723468780518, Stability Score=0.9696851968765259\n",
      "Mascara 3: Area=381112, IOU=0.932525634765625, Stability Score=0.5518852472305298\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/similar_mask_overlay_049_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/similar_mask_overlay_049_mask_2.png\n",
      "Máscara 3 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/003/processed_masks/similar_mask_overlay_049_mask_3.png\n",
      "Máscaras procesadas para vecino 3: 3.\n",
      "Tiempo total de ejecución de SAM: 123.8421 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([2, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([2, 384])\n",
      "Máximo de fobj_q_pooled: 5.352983474731445\n",
      "Mínimo de fobj_q_pooled: 0.0\n",
      "Máximo de d_M_q: 0.19516144692897797\n",
      "Mínimo de d_M_q: 0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9674, 0.8312, 0.9000],\n",
      "        [0.8672, 0.9747, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[15905.2598,  4071.9382,  8103.0840],\n",
      "        [ 5836.5942, 17106.8672,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9713, 0.8527, 0.9000],\n",
      "        [0.8306, 0.9716, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16525.8613,  5048.2134,  8103.0840],\n",
      "        [ 4050.0566, 16575.4844,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9725, 0.8316, 0.9000],\n",
      "        [0.8703, 0.9733, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16729.4844,  4089.6770,  8103.0840],\n",
      "        [ 6021.7178, 16867.3047,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5257, 0.1432],\n",
      "        [0.1714, 0.5344]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5257, 0.1432, 0.3312],\n",
      "        [0.1714, 0.5344, 0.2942],\n",
      "        [0.3030, 0.3224, 0.3746]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5257, 0.1432, 0.3312, 1.0000],\n",
      "        [0.1714, 0.5344, 0.2942, 1.0000],\n",
      "        [0.3030, 0.3224, 0.3746, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5257 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3312\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5344 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2942\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5387, 0.1558],\n",
      "        [0.1391, 0.5391]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5387, 0.1558, 0.3055],\n",
      "        [0.1391, 0.5391, 0.3219],\n",
      "        [0.3222, 0.3051, 0.3727]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5387, 0.1558, 0.3055, 1.0000],\n",
      "        [0.1391, 0.5391, 0.3219, 1.0000],\n",
      "        [0.3222, 0.3051, 0.3727, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5387 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3055\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5391 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.3219\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5306, 0.1425],\n",
      "        [0.1727, 0.5316]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5306, 0.1425, 0.3269],\n",
      "        [0.1727, 0.5316, 0.2957],\n",
      "        [0.2967, 0.3259, 0.3774]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5306, 0.1425, 0.3269, 1.0000],\n",
      "        [0.1727, 0.5316, 0.2957, 1.0000],\n",
      "        [0.2967, 0.3259, 0.3774, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5306 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3269\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5316 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2957\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "  Query 1: [(0, 1), (1, 1), (2, 1)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "  Query 1: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Total de mapas de matching válidos: 2\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 2\n",
      "Construyendo mapa agregado de matching...\n",
      "DEBUG: Percentile normalization - p_min: 35.58195114135742, p_max: 1024\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 2\n",
      "Max values across all combined_individual_score_maps: [89.83008575439453, 99.7080078125]\n",
      "Construyendo mapa total de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 35.58195114135742, p_max: 1024\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 35.58195114135742, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 35.58195114135742, p_max: 1024\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion/good/mahalanobis_score_maps/maha_003.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [130.63783 130.64    130.64001 130.64177 130.6439  130.64615 130.64671\n",
      " 130.64862 130.64896 130.65085]\n",
      "Imagen: 001\n",
      "Top 10 valores: [130.94908 130.95178 130.9522  130.95619 130.95853 130.95912 130.96074\n",
      " 130.96135 130.96301 130.96529]\n",
      "Imagen: 002\n",
      "Top 10 valores: [151.03262 151.03616 151.04189 151.04536 151.04852 151.04869 151.05133\n",
      " 151.05453 151.05809 151.06123]\n",
      "Imagen: 003\n",
      "Top 10 valores: [98.52873  98.53322  98.538284 98.54456  98.54473  98.5586   98.564125\n",
      " 98.58575  98.59151  98.597595]\n",
      "Imagen: 004\n",
      "Top 10 valores: [177.4541  177.45674 177.49045 177.55031 177.58707 177.60652 177.61841\n",
      " 177.64578 177.64893 177.67104]\n",
      "Imagen: 005\n",
      "Top 10 valores: [100.25033  100.25131  100.25152  100.252045 100.25205  100.25245\n",
      " 100.254364 100.25468  100.25583  100.25591 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.55551  124.5569   124.558365 124.559746 124.56041  124.56084\n",
      " 124.56212  124.56332  124.56372  124.565   ]\n",
      "Imagen: 007\n",
      "Top 10 valores: [102.34186  102.3467   102.346725 102.353806 102.353905 102.35399\n",
      " 102.35615  102.35625  102.36113  102.363464]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/good/004.png ---\n",
      "Ground Truth Mask Path para 004: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/good/004_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (391, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([391, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3438 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 2\n",
      "Mascara 1: Area=655565, IOU=0.9961053729057312, Stability Score=0.9869968295097351\n",
      "Mascara 2: Area=386847, IOU=0.9937195777893066, Stability Score=0.9322751760482788\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/query_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/query_mask_2.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 2\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 347.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 2\n",
      "Mascara 1: Area=651088, IOU=0.9971797466278076, Stability Score=0.9760681390762329\n",
      "Mascara 2: Area=366434, IOU=0.9900721311569214, Stability Score=0.817902147769928\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_347_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_347_mask_2.png\n",
      "Máscaras procesadas para vecino 1: 2.\n",
      "--- Procesando vecino 2: 284.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 3\n",
      "Mascara 1: Area=660756, IOU=0.9969164133071899, Stability Score=0.9758988618850708\n",
      "Mascara 2: Area=375336, IOU=0.992857813835144, Stability Score=0.9708637595176697\n",
      "Mascara 3: Area=378543, IOU=0.9571661353111267, Stability Score=0.5555034279823303\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_284_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_284_mask_2.png\n",
      "Máscara 3 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_284_mask_3.png\n",
      "Máscaras procesadas para vecino 2: 3.\n",
      "--- Procesando vecino 3: 323.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 330000): 3\n",
      "Mascara 1: Area=645009, IOU=0.9970824122428894, Stability Score=0.9710111618041992\n",
      "Mascara 2: Area=388940, IOU=0.9892665147781372, Stability Score=0.9826998710632324\n",
      "Mascara 3: Area=391514, IOU=0.9615949392318726, Stability Score=0.6946637034416199\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_323_mask_1.png\n",
      "Máscara 2 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_323_mask_2.png\n",
      "Máscara 3 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/004/processed_masks/similar_mask_overlay_323_mask_3.png\n",
      "Máscaras procesadas para vecino 3: 3.\n",
      "Tiempo total de ejecución de SAM: 123.3634 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([2, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([2, 384])\n",
      "Máximo de fobj_q_pooled: 5.800616264343262\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1945875585079193\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9768, 0.8331, 0.9000],\n",
      "        [0.8645, 0.9703, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17458.6172,  4152.1982,  8103.0840],\n",
      "        [ 5683.5991, 16362.9824,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9754, 0.8579, 0.9000],\n",
      "        [0.8226, 0.9582, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17217.4941,  5317.7876,  8103.0840],\n",
      "        [ 3738.4458, 14501.3896,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9697, 0.8356, 0.9000],\n",
      "        [0.8620, 0.9691, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16263.4307,  4254.6885,  8103.0840],\n",
      "        [ 5540.7568, 16169.0166,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840,  8103.0840]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5385, 0.1420],\n",
      "        [0.1663, 0.5307]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5385, 0.1420, 0.3195],\n",
      "        [0.1663, 0.5307, 0.3030],\n",
      "        [0.2952, 0.3273, 0.3774]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5385, 0.1420, 0.3195, 1.0000],\n",
      "        [0.1663, 0.5307, 0.3030, 1.0000],\n",
      "        [0.2952, 0.3273, 0.3774, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5385 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3195\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5307 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.3030\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5429, 0.1644],\n",
      "        [0.1372, 0.5220]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5429, 0.1644, 0.2927],\n",
      "        [0.1372, 0.5220, 0.3408],\n",
      "        [0.3199, 0.3136, 0.3665]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5429, 0.1644, 0.2927, 1.0000],\n",
      "        [0.1372, 0.5220, 0.3408, 1.0000],\n",
      "        [0.3199, 0.3136, 0.3665, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5429 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.2927\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5220 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.3408\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5283, 0.1480],\n",
      "        [0.1688, 0.5276]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5283, 0.1480, 0.3237],\n",
      "        [0.1688, 0.5276, 0.3036],\n",
      "        [0.3029, 0.3244, 0.3726]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5283, 0.1480, 0.3237, 1.0000],\n",
      "        [0.1688, 0.5276, 0.3036, 1.0000],\n",
      "        [0.3029, 0.3244, 0.3726, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 3.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5283 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3237\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.5276 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.3036\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "  Query 1: [(0, 1), (1, 1), (2, 1)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "  Query 1: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 0.0, p_max: 1024\n",
      "Total de mapas de matching válidos: 2\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 2\n",
      "Construyendo mapa agregado de matching...\n",
      "DEBUG: Percentile normalization - p_min: 38.92045974731445, p_max: 1024\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 2\n",
      "Max values across all combined_individual_score_maps: [121.20812225341797, 147.84889221191406]\n",
      "Construyendo mapa total de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 38.92045974731445, p_max: 1024\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "DEBUG: Percentile normalization - p_min: 38.92045974731445, p_max: 1024\n",
      "DEBUG: Percentile normalization - p_min: 38.92045974731445, p_max: 1024\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion/good/mahalanobis_score_maps/maha_004.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [130.63783 130.64    130.64001 130.64177 130.6439  130.64615 130.64671\n",
      " 130.64862 130.64896 130.65085]\n",
      "Imagen: 001\n",
      "Top 10 valores: [130.94908 130.95178 130.9522  130.95619 130.95853 130.95912 130.96074\n",
      " 130.96135 130.96301 130.96529]\n",
      "Imagen: 002\n",
      "Top 10 valores: [151.03262 151.03616 151.04189 151.04536 151.04852 151.04869 151.05133\n",
      " 151.05453 151.05809 151.06123]\n",
      "Imagen: 003\n",
      "Top 10 valores: [98.52873  98.53322  98.538284 98.54456  98.54473  98.5586   98.564125\n",
      " 98.58575  98.59151  98.597595]\n",
      "Imagen: 004\n",
      "Top 10 valores: [144.43504 144.54608 144.55737 144.63354 144.7055  144.72028 144.75497\n",
      " 144.76991 144.79724 144.80278]\n",
      "Imagen: 005\n",
      "Top 10 valores: [100.25033  100.25131  100.25152  100.252045 100.25205  100.25245\n",
      " 100.254364 100.25468  100.25583  100.25591 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.55551  124.5569   124.558365 124.559746 124.56041  124.56084\n",
      " 124.56212  124.56332  124.56372  124.565   ]\n",
      "Imagen: 007\n",
      "Top 10 valores: [102.34186  102.3467   102.346725 102.353806 102.353905 102.35399\n",
      " 102.35615  102.35625  102.36113  102.363464]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/good/005.png ---\n",
      "Ground Truth Mask Path para 005: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/ground_truth/good/005_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (391, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([391, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.1876 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 1\n",
      "Mascara 1: Area=682018, IOU=0.9966553449630737, Stability Score=0.988464891910553\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion/good/005/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 330000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 120.png ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 443\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Procesando vecino \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(similar_image_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# 1. Generate ALL masks for the current similar image\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m all_generated_masks \u001b[38;5;241m=\u001b[39m \u001b[43mmask_generator_similar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_np_similar_for_sam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# 2. Initialize a NEW list to store only the FILTERED masks\u001b[39;00m\n\u001b[1;32m    446\u001b[0m filtered_similar_masks_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sam2_repo_independent/sam2/automatic_mask_generator.py:196\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator.generate\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mGenerates masks for the given image.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m         the mask, given in XYWH format.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Generate masks\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m mask_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Encode masks\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco_rle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/sam2_repo_independent/sam2/automatic_mask_generator.py:233\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._generate_masks\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    231\u001b[0m data \u001b[38;5;241m=\u001b[39m MaskData()\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop_box, layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(crop_boxes, layer_idxs):\n\u001b[0;32m--> 233\u001b[0m     crop_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(crop_data)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Remove duplicate masks between crops\u001b[39;00m\n",
      "File \u001b[0;32m~/sam2_repo_independent/sam2/automatic_mask_generator.py:274\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._process_crop\u001b[0;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (points,) \u001b[38;5;129;01min\u001b[39;00m batch_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints_per_batch, points_for_image):\n\u001b[1;32m    271\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_batch(\n\u001b[1;32m    272\u001b[0m         points, cropped_im_size, crop_box, orig_size, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     )\n\u001b[0;32m--> 274\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m batch_data\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mreset_predictor()\n",
      "File \u001b[0;32m~/sam2_repo_independent/sam2/utils/amg.py:70\u001b[0m, in \u001b[0;36mMaskData.cat\u001b[0;34m(self, new_stats)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k], v], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m+\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaskData key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has an unsupported type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2_featup_env/lib/python3.10/copy.py:138\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    135\u001b[0m     memo \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    137\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m(x)\n\u001b[0;32m--> 138\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmemo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _nil:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# FeatUp utilities\n",
    "from featup.util import norm, unnorm\n",
    "from featup.plotting import plot_feats\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Anomaly region detection and visualization\n",
    "from skimage import measure\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# SAM2 imports\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import cv2\n",
    "\n",
    "# PCA for manual visualization\n",
    "from sklearn.decomposition import PCA\n",
    "# --- Enable loading of truncated images ---\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # Add this at the very top for global effect\n",
    "\n",
    "# --- Configuración ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224  # DINOv2 input size\n",
    "BACKBONE_PATCH_SIZE = 14  # DINOv2 ViT-S/14 patch size\n",
    "use_norm = True\n",
    "\n",
    "H_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "W_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "\n",
    "# Directorios\n",
    "TRAIN_GOOD_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/train/good'\n",
    "directorio_coreset = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/train/good'\n",
    "#PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/plots_final_eval/cut'\n",
    "# --- Imagen de Consulta ---\n",
    "BASE_PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion/good'  # Base directory for saving plots\n",
    "\n",
    "# Directory containing the test images \n",
    "TEST_IMAGES_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/good'\n",
    "\n",
    "# Create parent plot directory if it doesn't exist\n",
    "os.makedirs(BASE_PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "# --- NUEVA CARPETA PARA LOS MAPAS DE ANOMALÍAS ---\n",
    "MAHALANOBIS_SCORE_MAPS_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'mahalanobis_score_maps')\n",
    "os.makedirs(MAHALANOBIS_SCORE_MAPS_DIR, exist_ok=True)\n",
    "print(f\"Carpeta para guardar score maps: {MAHALANOBIS_SCORE_MAPS_DIR}\")\n",
    "\n",
    "# Coreset file paths\n",
    "core_bank_filenames_file = os.path.join(directorio_coreset, 'core_bank_filenames.pt')\n",
    "coreset_relevant_flat_features_bank_file = os.path.join(directorio_coreset, 'coreset_relevant_flat_features_bank.pt')\n",
    "template_features_bank_coreset_file = os.path.join(directorio_coreset, 'template_features_bank_coreset.pt')\n",
    "\n",
    "# --- Cargar Datos del Coreset ---\n",
    "print(\"Cargando datos del coreset...\")\n",
    "try:\n",
    "    coreset_relevant_filenames = torch.load(core_bank_filenames_file)\n",
    "    coreset_relevant_flat_features_bank = torch.load(coreset_relevant_flat_features_bank_file).to(device)\n",
    "    coreset_features = torch.load(template_features_bank_coreset_file).to(device)\n",
    "    print(f\"Coreset cargado. Dimensión: {coreset_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar archivos del coreset: {e}. Asegúrate de que la Etapa 1 se ejecutó.\")\n",
    "    exit()\n",
    "\n",
    "# Mover coreset a CPU para sklearn's NearestNeighbors\n",
    "coreset_features_cpu = coreset_features.cpu().numpy()\n",
    "# se calcula la distancia coseno == 1 - similitud coseno [0,1] 0 identico, 1 completamente diferente\n",
    "nn_finder = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='cosine').fit(coreset_features_cpu)\n",
    "print(\"NearestNeighbors finder inicializado.\")\n",
    "\n",
    "# --- Cargar Modelo DINOv2 ---\n",
    "print(\"Cargando modelo DINOv2...\")\n",
    "featup_local_path = \"/home/imercatoma/FeatUp\"\n",
    "upsampler = torch.hub.load(featup_local_path, 'dinov2', use_norm=use_norm, source='local').to(device)\n",
    "\n",
    "dinov2_model = upsampler.model\n",
    "dinov2_model.eval()\n",
    "print(\"Modelo DINOv2 cargado.\")\n",
    "\n",
    "# --- Transformación de Imagen ---\n",
    "transform = T.Compose([\n",
    "    T.Resize(input_size),\n",
    "    T.CenterCrop((input_size, input_size)),\n",
    "    T.ToTensor(),\n",
    "    norm\n",
    "])\n",
    "\n",
    "# --- Carga del Modelo SAM2 ---\n",
    "print(f\"Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\")\n",
    "checkpoint = \"/home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt\"\n",
    "model_cfg_name = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_model = build_sam2(model_cfg_name, checkpoint, device=device, apply_postprocessing=True)\n",
    "sam2_model.eval()\n",
    "print(\"Modelo SAM2 cargado.\")\n",
    "\n",
    "#### fin de carga de modelos\n",
    "\n",
    "# --- CONFIGURACIÓN PARA EL GUARDADO DE EXCEL ---\n",
    "EXCEL_OUTPUT_PATH = 'resultados_evaluacion_anomalias.xlsx'\n",
    "all_evaluation_results = [] # This list will accumulate results from all processed images\n",
    "\n",
    "# Opción 2: Procesar solo las primeras 10 imágenes (descomentar si prefieres esta opción)\n",
    "image_paths = glob.glob(os.path.join(TEST_IMAGES_DIR, '*.png'))\n",
    "image_paths.sort()\n",
    "\n",
    "######\n",
    "start_time_global = time.time()\n",
    "# --- Bucle para procesar cada imagen ---\n",
    "for query_image_path in image_paths:\n",
    "    start_time_total = time.time()\n",
    "    print(f\"\\n--- Procesando imagen: {query_image_path} ---\")\n",
    "\n",
    "    # Extraer el nombre base de la imagen (ej: '006.png')\n",
    "    base_image_name_with_ext = os.path.basename(query_image_path)\n",
    "    base_image_name = os.path.splitext(base_image_name_with_ext)[0] # '006'\n",
    "\n",
    "    # Construir la ruta de la máscara Ground Truth para la imagen actual\n",
    "    gt_mask_path = query_image_path.replace('test', 'ground_truth').replace('.png', '_mask.png')\n",
    "    print(f\"Ground Truth Mask Path para {base_image_name}: {gt_mask_path}\")\n",
    "\n",
    "    # --- Directorios de guardado específicos para esta imagen ---\n",
    "    PLOT_SAVE_ROOT_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, base_image_name)\n",
    "    os.makedirs(PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "    HEATMAPS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'individual_heatmaps')\n",
    "    os.makedirs(HEATMAPS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    ANOMALY_REGIONS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'detected_anomaly_regions')\n",
    "    os.makedirs(ANOMALY_REGIONS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    FEATUP_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'featup_feature_plots')\n",
    "    os.makedirs(FEATUP_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "    # --- Cargar la imagen de consulta CON ERROR HANDLING ---\n",
    "    query_img_pil = None # Initialize to None\n",
    "    try:\n",
    "        query_img_pil = Image.open(query_image_path).convert(\"RGB\")\n",
    "        W, H = query_img_pil.size # Get dimensions for consistent resizing\n",
    "    except OSError as e:\n",
    "        print(f\"ERROR: No se pudo cargar o procesar la imagen de consulta '{query_image_path}'. Error: {e}\")\n",
    "        print(\"Saltando a la siguiente imagen...\")\n",
    "        continue # Skip to the next image in the loop\n",
    "\n",
    "    # If query_img_pil is still None, it means an error occurred, so skip\n",
    "    if query_img_pil is None:\n",
    "        continue\n",
    "\n",
    "    # Definir el tamaño objetivo para las máscaras de evaluación (el mismo que el mapa de anomalías)\n",
    "    TARGET_EVAL_SIZE = (W, H)\n",
    "\n",
    "    #############----------- PROCESO   -----###############\n",
    "    \n",
    "    input_tensor = transform(query_img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_lr = dinov2_model(input_tensor)\n",
    "\n",
    "    query_lr_features = features_lr\n",
    "\n",
    "    # --- Función para buscar imágenes similares usando KNN ---\n",
    "    def buscar_imagenes_similares_knn(query_feature_map, pre_flattened_features_bank, k=3, nombres_archivos=None):\n",
    "        query_feat_flatten = query_feature_map.flatten().cpu().numpy()#dimension mapa desde banco torch.Size([1, 384, 16, 16])\n",
    "        print(f\"dimension mapa query\", query_feature_map.shape)\n",
    "        print(f\"dimension query flatten\", query_feat_flatten.shape)#dimension query flatten (98304,)\n",
    "        features_bank_for_knn = pre_flattened_features_bank.cpu().numpy() if isinstance(pre_flattened_features_bank, torch.Tensor) else pre_flattened_features_bank\n",
    "        print(f\"dimension query flatten\", features_bank_for_knn.shape)#dimension query flatten (213, 98304)\n",
    "        print(f\"dimensiones desde BANCO STAGE 1 stage\", pre_flattened_features_bank.shape)#dimensiones desde BANCO STAGE 1 stage torch.Size([213, 98304])\n",
    "        \n",
    "        \n",
    "        start_time_knn_dist = time.time()\n",
    "        distances = euclidean_distances([query_feat_flatten], features_bank_for_knn)\n",
    "        nearest_indices = np.argsort(distances[0])[:k]\n",
    "        end_time_knn_dist = time.time()\n",
    "        print(f\"Tiempo para calcular distancias KNN: {end_time_knn_dist - start_time_knn_dist:.4f} segundos\")\n",
    "\n",
    "        imagenes_similares = []\n",
    "        rutas_imagenes_similares = []\n",
    "        if nombres_archivos:\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(nombres_archivos[idx])\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, nombres_archivos[idx]))\n",
    "        else: # Fallback if no filenames provided (less common for this use case)\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(f\"Imagen_Banco_{idx:03d}.png\")\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, f\"Imagen_Banco_{idx:03d}.png\"))\n",
    "        return imagenes_similares, rutas_imagenes_similares, end_time_knn_dist\n",
    "\n",
    "    # --- Búsqueda KNN ---\n",
    "    print(\"\\nBuscando imágenes similares usando el banco pre-aplanado del Coreset...\")\n",
    "    imagenes_similares, rutas_imagenes_similares, time_knn_dist = buscar_imagenes_similares_knn(\n",
    "        query_lr_features, coreset_relevant_flat_features_bank, nombres_archivos=coreset_relevant_filenames\n",
    "    )\n",
    "\n",
    "    # --- Aplicar FeatUp para obtener características de alta resolución ---\n",
    "    def apply_featup_hr(image_path, featup_upsampler, image_transform, device):\n",
    "        image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = image_transform(image_pil).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            lr_feats = featup_upsampler.model(image_tensor)\n",
    "            hr_feats = featup_upsampler(image_tensor)\n",
    "        return lr_feats.cpu(), hr_feats.cpu()\n",
    "\n",
    "    # Características de la imagen de consulta\n",
    "    input_query_tensor_original = transform(Image.open(query_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    query_lr_feats_featup, query_hr_feats = apply_featup_hr(query_image_path, upsampler, transform, device)\n",
    "\n",
    "    # Características de las imágenes similares\n",
    "    similar_hr_feats_list = []\n",
    "    for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "        input_similar_tensor_original = transform(Image.open(similar_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "        similar_lr_feats, similar_hr_feats = apply_featup_hr(similar_image_path, upsampler, transform, device)\n",
    "        similar_hr_feats_list.append(similar_hr_feats)\n",
    "\n",
    "    ################################\n",
    "    ### Aplicando Máscaras SAM query y similares\n",
    "\n",
    "    def show_mask(mask, ax, random_color=False, borders=True):\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image_alpha = np.zeros((h, w, 4), dtype=np.float32)\n",
    "        mask_image_alpha[mask > 0] = color\n",
    "        if borders:\n",
    "            mask_uint8 = mask.astype(np.uint8) * 255\n",
    "            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contour_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=2)\n",
    "            contour_mask = (contour_image.astype(np.float32) / 255.0).sum(axis=-1) > 0\n",
    "            mask_image_alpha[contour_mask > 0, :3] = 1.0\n",
    "            mask_image_alpha[contour_mask > 0, 3] = 0.5\n",
    "        ax.imshow(mask_image_alpha)\n",
    "\n",
    "    def process_masks_with_hierarchy(image, masks, output_dir, filename_prefix, overlap_threshold=0.8):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        final_processed_masks_data = [] \n",
    "        original_mask_segments_for_comparison = [mask_data[\"segmentation\"] for mask_data in masks]\n",
    "\n",
    "        print(f\"Procesando jerárquicamente {len(masks)} máscaras...\")\n",
    "\n",
    "        for i, mask_data_a_original in enumerate(masks): \n",
    "            mask_data_a_processed = mask_data_a_original.copy() \n",
    "            mask_a_current_processing = np.copy(mask_data_a_original[\"segmentation\"]) \n",
    "\n",
    "            is_completely_internal_to_another = False \n",
    "            potential_holes_for_mask_a = [] \n",
    "\n",
    "            for j, mask_data_b_comparison in enumerate(masks): \n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                mask_b = original_mask_segments_for_comparison[j] \n",
    "\n",
    "                if np.sum(mask_a_current_processing) > 0 and np.all(np.logical_and(mask_a_current_processing, mask_b) == mask_a_current_processing):\n",
    "                    is_completely_internal_to_another = True\n",
    "                    break \n",
    "\n",
    "                intersection_ab = np.logical_and(mask_b, mask_a_current_processing)\n",
    "                area_b = np.sum(mask_b)\n",
    "                area_intersection_ab = np.sum(intersection_ab)\n",
    "\n",
    "                if area_b > 0 and (np.all(intersection_ab == mask_b) or \\\n",
    "                                (area_intersection_ab / area_b > overlap_threshold and area_intersection_ab > 0)):\n",
    "                    if np.sum(mask_b) < np.sum(mask_a_current_processing) * 0.9: \n",
    "                        potential_holes_for_mask_a.append(mask_b)\n",
    "\n",
    "            if is_completely_internal_to_another:\n",
    "                display_title = f'Máscara {i + 1} (Interna - Sin cambios significativos)'\n",
    "            else:\n",
    "                hollowed = False\n",
    "                for hole_mask in potential_holes_for_mask_a:\n",
    "                    mask_a_current_processing = np.logical_and(mask_a_current_processing, np.logical_not(hole_mask))\n",
    "                    hollowed = True\n",
    "                \n",
    "                mask_data_a_processed[\"segmentation\"] = mask_a_current_processing \n",
    "                if hollowed:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Hueca)'\n",
    "                else:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Sin huecos significativos)'\n",
    "\n",
    "            final_processed_masks_data.append(mask_data_a_processed) \n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(image) \n",
    "            show_mask(mask_data_a_processed[\"segmentation\"], plt.gca(), random_color=True) \n",
    "            plt.axis('off')\n",
    "            plt.title(display_title)\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{filename_prefix}_processed_mask_{i + 1}.png\")\n",
    "            plt.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Máscara procesada {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "        print(\"Procesamiento jerárquico de máscaras completado.\")\n",
    "        return final_processed_masks_data \n",
    "\n",
    "    def apply_morphological_closing(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            return masks_list\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando cierre morfológico con kernel {kernel_size}x{kernel_size}...\")\n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_smoothed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_CLOSE, kernel)\n",
    "            mask_data['segmentation'] = (mask_smoothed_np > 0).astype(bool)\n",
    "        print(\"Suavizado de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    def apply_morphological_opening(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            print(\"La lista de máscaras está vacía, no se aplica la apertura morfológica.\")\n",
    "            return masks_list\n",
    "        \n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando apertura morfológica con kernel {kernel_size}x{kernel_size}...\")\n",
    "        \n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            if mask_boolean.dtype != bool:\n",
    "                mask_boolean = mask_boolean.astype(bool)\n",
    "\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_processed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_OPEN, kernel)\n",
    "            mask_data['segmentation'] = (mask_processed_np > 0).astype(bool)\n",
    "            \n",
    "        print(\"Suavizado (apertura) de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    try:\n",
    "        image_for_sam_np = np.array(Image.open(query_image_path).convert(\"RGB\"))\n",
    "        print(f\"Dimensiones imagen SAM: {image_for_sam_np.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando imagen para SAM: {e}. Saltando SAM.\")\n",
    "        sam2_model = None\n",
    "        \n",
    "    PROCESSED_MASKS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"processed_masks\")\n",
    "\n",
    "    if sam2_model is not None:\n",
    "        points_grid_density = 16\n",
    "        min_mask_area_pixels = 3000\n",
    "\n",
    "        mask_generator_query = SAM2AutomaticMaskGenerator(\n",
    "            model=sam2_model,\n",
    "            points_per_side=points_grid_density,\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.8,\n",
    "            stability_score_thresh=0.8,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=min_mask_area_pixels,\n",
    "        )\n",
    "        \n",
    "        masks_data_query_image = mask_generator_query.generate(image_for_sam_np)\n",
    "\n",
    "\n",
    "        min_area_threshold = 330000#100000 # Define tu umbral de área mínima\n",
    "        max_area_threshold = 1000*1000\n",
    "        filtered_masks_data = []\n",
    "        for mask_data in masks_data_query_image:\n",
    "            mask_area = mask_data['area']  # El diccionario 'mask_data' ya contiene el área\n",
    "            if min_area_threshold <= mask_area <= max_area_threshold:\n",
    "                filtered_masks_data.append(mask_data)\n",
    "\n",
    "        masks_data_query_image = filtered_masks_data # Actualiza tu lista de máscaras\n",
    "        print(f\"Número de máscaras generadas DESPUÉS de filtrar (área >= {min_area_threshold}): {len(masks_data_query_image)}\")\n",
    "        for i, mask_data in enumerate(masks_data_query_image):\n",
    "            area = mask_data['area']\n",
    "            iou = mask_data.get('predicted_iou', 'N/A')  # Usar 'N/A' si no está disponible\n",
    "            stability_score = mask_data.get('stability_score', 'N/A')  # Usar 'N/A' si no está disponible\n",
    "            print(f\"Mascara {i + 1}: Area={area}, IOU={iou}, Stability Score={stability_score}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        def plot_individual_masks(masks_data, output_dir, filename_prefix=\"query_mask\", image_path=None):\n",
    "\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            if image_path:\n",
    "                try:\n",
    "                    image_original = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_np = np.array(image_original)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"No image path provided for overlay. Skipping.\")\n",
    "                return\n",
    "            \n",
    "            for i, mask_data in enumerate(masks_data):\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                mask_np = mask_data[\"segmentation\"]\n",
    "                plt.imshow(image_np)\n",
    "                show_mask(mask_np, plt.gca(), random_color=True)\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"Máscara {i + 1} - Área: {mask_data['area']}, IoU: {mask_data.get('predicted_iou', 'N/A')}\")\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"{filename_prefix}_{i + 1}.png\")\n",
    "                plt.savefig(output_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(f\"Máscara {i + 1} sobrepuesta guardada en: {output_path}\")\n",
    "\n",
    "        # Call the function to visualize and save the masks\n",
    "        plot_individual_masks(masks_data_query_image, PROCESSED_MASKS_DIR, filename_prefix=\"query_mask\", image_path=query_image_path)\n",
    "        \n",
    "        print(f\"Número de máscaras generadas DESPUÉS de filtrar (área >= {min_area_threshold}): {len(masks_data_query_image)}\")   \n",
    "        \n",
    "        mask_generator_similar = SAM2AutomaticMaskGenerator( \n",
    "            model=sam2_model,\n",
    "            points_per_side=64,#25\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.5,\n",
    "            stability_score_thresh=0.4,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=0,\n",
    "        )\n",
    "\n",
    "        print(\"\\nGenerando máscaras SAM para imágenes similares...\")\n",
    "        # --- Start of your main processing loop ---\n",
    "        start_time_sam = time.time()\n",
    "        similar_masks_raw_list=[]\n",
    "        \n",
    "        for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "                    \n",
    "            try:\n",
    "                image_np_similar_for_sam = np.array(Image.open(similar_image_path).convert('RGB'))\n",
    "                print(f\"--- Procesando vecino {j+1}: {os.path.basename(similar_image_path)} ---\")\n",
    "                \n",
    "                # 1. Generate ALL masks for the current similar image\n",
    "                all_generated_masks = mask_generator_similar.generate(image_np_similar_for_sam)\n",
    "                \n",
    "                # 2. Initialize a NEW list to store only the FILTERED masks\n",
    "                filtered_similar_masks_data = []\n",
    "\n",
    "                # 3. Iterate over the ALL_GENERATED_MASKS and add to the NEW list if they pass the filter\n",
    "                for mask_data in all_generated_masks: # <--- CRUCIAL CHANGE HERE!\n",
    "                    mask_area = mask_data['area']\n",
    "                    if min_area_threshold <= mask_area <= max_area_threshold:\n",
    "                        filtered_similar_masks_data.append(mask_data) # <--- Appending to a DIFFERENT list!\n",
    "\n",
    "                print(f\"Número de máscaras generadas y filtradas (área >= {min_area_threshold}): {len(filtered_similar_masks_data)}\")\n",
    "                for i, mask_data in enumerate(filtered_similar_masks_data): # <--- Iterate over the filtered list\n",
    "                    area = mask_data['area']\n",
    "                    iou = mask_data.get('predicted_iou', 'N/A')\n",
    "                    stability_score = mask_data.get('stability_score', 'N/A')\n",
    "                    print(f\"Mascara {i + 1}: Area={area}, IOU={iou}, Stability Score={stability_score}\")\n",
    "                    \n",
    "                similar_masks_raw_list.append(masks_data_query_image) # <--- Append the filtered list\n",
    "                \n",
    "                # Visualize and save individual masks overlaid on the similar images\n",
    "                def plot_masks_overlay_on_images(masks_data, image_path, output_dir, filename_prefix=\"similar_mask_overlay\"):\n",
    "                    \"\"\"\n",
    "                    Function to overlay masks on the original similar images and save them as images.\n",
    "\n",
    "                    Args:\n",
    "                        masks_data (list): List of mask data dictionaries containing 'segmentation', 'area', and 'predicted_iou'.\n",
    "                        image_path (str): Path to the original similar image.\n",
    "                        output_dir (str): Directory to save the overlay images.\n",
    "                        filename_prefix (str): Prefix for the saved overlay filenames.\n",
    "                    \"\"\"\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    try:\n",
    "                        image_original = Image.open(image_path).convert(\"RGB\")\n",
    "                        image_np = np.array(image_original)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {image_path}: {e}\")\n",
    "                        return\n",
    "\n",
    "                    for i, mask_data in enumerate(masks_data):\n",
    "                        plt.figure(figsize=(8, 8))\n",
    "                        mask_np = mask_data[\"segmentation\"]\n",
    "                        plt.imshow(image_np)\n",
    "                        show_mask(mask_np, plt.gca(), random_color=True)\n",
    "                        plt.axis('off')\n",
    "                        \n",
    "                        # Handling N/A for formatting\n",
    "                        iou_val = mask_data.get('predicted_iou', 'N/A')\n",
    "                        stability_val = mask_data.get('stability_score', 'N/A')\n",
    "                        iou_str = f\"{iou_val:.4f}\" if isinstance(iou_val, (int, float)) else str(iou_val)\n",
    "\n",
    "                        plt.title(f\"Máscara {i + 1} - Área: {mask_data['area']}, IoU: {iou_str}, Stability: {stability_val}\")\n",
    "\n",
    "                        # Use a more unique filename to avoid overwrites across different similar images\n",
    "                        # Assumes 'j' (index of the similar image) is accessible from the outer scope\n",
    "                        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                        output_path = os.path.join(output_dir, f\"{filename_prefix}_{base_filename}_mask_{i + 1}.png\")\n",
    "                        \n",
    "                        plt.savefig(output_path, bbox_inches='tight')\n",
    "                        plt.close()\n",
    "                        print(f\"Máscara {i + 1} sobrepuesta guardada en: {output_path}\")\n",
    "\n",
    "                # Call the function to overlay and save the masks for the current similar image\n",
    "                # Pass the filtered list and ensure a unique filename prefix\n",
    "                plot_masks_overlay_on_images(filtered_similar_masks_data, similar_image_path, PROCESSED_MASKS_DIR, filename_prefix=\"similar_mask_overlay\")\n",
    "                \n",
    "                print(f\"Máscaras procesadas para vecino {j+1}: {len(filtered_similar_masks_data)}.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando imagen similar {os.path.basename(similar_image_path)} para SAM: {e}\")\n",
    "                # It's usually a good idea to 'continue' here so the loop doesn't stop for one error\n",
    "                continue \n",
    "\n",
    "        end_time_sam = time.time()\n",
    "        print(f\"Tiempo total de ejecución de SAM: {end_time_sam - start_time_sam:.4f} segundos.\")\n",
    "\n",
    "        print(\"\\nAnálisis de SAM para una sola imagen completado.\")\n",
    "    \n",
    "    # Llamar a la función para procesar las máscaras de la query\n",
    "    # processed_masks_query = process_masks_with_hierarchy(image_for_sam_np, masks_data_query_image, PROCESSED_MASKS_DIR, \"query\")\n",
    "    # masks_data_query_image = processed_masks_query\n",
    "    # print(\"Shape de masks_data_query_image:\", len(masks_data_query_image))\n",
    "\n",
    "    #####################\n",
    "\n",
    "    # --- Implementación del punto 3.4.3. Object Feature Map ---\n",
    "    def process_masks_to_object_feature_maps(raw_masks, hr_feature_map, target_h, target_w, sam_processed_image_shape):\n",
    "        if not raw_masks:\n",
    "            print(\"Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\")\n",
    "            C_dim = hr_feature_map.shape[0] if hr_feature_map.ndim >= 3 else 0\n",
    "            return torch.empty(0, C_dim, target_h, target_w, device=hr_feature_map.device), \\\n",
    "                torch.empty(0, 1, target_h, target_w, device=hr_feature_map.device)\n",
    "\n",
    "        object_feature_maps_list = []\n",
    "        scaled_mask_append = []\n",
    "        C_dim = hr_feature_map.shape[0] \n",
    "\n",
    "        for mask_info in raw_masks:\n",
    "            mask_np = mask_info['segmentation'].astype(np.float32)\n",
    "            mask_tensor_original_res = torch.from_numpy(mask_np).unsqueeze(0).unsqueeze(0) #(1,1,H,W)\n",
    "            mask_tensor_original_res = mask_tensor_original_res.to(hr_feature_map.device)\n",
    "\n",
    "            scaled_mask = F.interpolate(mask_tensor_original_res,\n",
    "                                        size=(target_h, target_w),\n",
    "                                        mode='bilinear',\n",
    "                                        align_corners=False)\n",
    "            scaled_mask = (scaled_mask > 0.5).float()\n",
    "            scaled_mask_append.append(scaled_mask)\n",
    "            \n",
    "            if hr_feature_map.ndim == 3:\n",
    "                hr_feature_map_with_batch = hr_feature_map.unsqueeze(0) #(1,C,W,H)\n",
    "            else: \n",
    "                hr_feature_map_with_batch = hr_feature_map\n",
    "\n",
    "            object_feature_map_i = scaled_mask * hr_feature_map_with_batch\n",
    "            object_feature_maps_list.append(object_feature_map_i)\n",
    "\n",
    "        final_object_feature_maps = torch.cat(object_feature_maps_list, dim=0) \n",
    "        final_scaled_masks = torch.cat(scaled_mask_append, dim=0)\n",
    "        \n",
    "        return final_object_feature_maps, final_scaled_masks\n",
    "\n",
    "    # --- Visualización de Mapas de Características de Objeto ---\n",
    "    def visualize_object_feature_map(original_image_path, sam_mask_info, hr_feature_map_tensor,\n",
    "                                    object_feature_map_tensor, target_h, target_w,\n",
    "                                    plot_save_dir, plot_filename_prefix, mask_idx,\n",
    "                                    sam_processed_image_shape):\n",
    "        try:\n",
    "            original_img = Image.open(original_image_path).convert(\"RGB\")\n",
    "            sam_mask_np = sam_mask_info['segmentation']\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "            axes[0].imshow(original_img)\n",
    "            axes[0].set_title(f'Imagen Original\\n{os.path.basename(original_image_path)}')\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            mask_display = sam_mask_np \n",
    "            axes[1].imshow(original_img) \n",
    "            show_mask(mask_display, axes[1], random_color=False, borders=True) \n",
    "            axes[1].set_title(f'Máscara SAM {mask_idx}')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            if object_feature_map_tensor.numel() == 0:\n",
    "                axes[2].text(0.5, 0.5, \"No hay características de objeto\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                axes[2].set_title('Mapa de Características de Objeto (Vacío)')\n",
    "                axes[2].axis('off')\n",
    "            else:\n",
    "                ofm_cpu = object_feature_map_tensor.squeeze().cpu().numpy() \n",
    "                if ofm_cpu.ndim == 3: \n",
    "                    C, H, W = ofm_cpu.shape\n",
    "                    ofm_reshaped = ofm_cpu.transpose(1, 2, 0).reshape(-1, C) \n",
    "\n",
    "                    if C > 3: \n",
    "                        pca = PCA(n_components=3)\n",
    "                        ofm_pca = pca.fit_transform(ofm_reshaped)\n",
    "                        ofm_pca_normalized = (ofm_pca - ofm_pca.min()) / (ofm_pca.max() - ofm_pca.min() + 1e-8)\n",
    "                        ofm_display = ofm_pca_normalized.reshape(H, W, 3)\n",
    "                        axes[2].imshow(ofm_display)\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto (PCA)\\nMáscara {mask_idx}')\n",
    "                    else: \n",
    "                        if C == 1:\n",
    "                            ofm_display = ofm_cpu.squeeze()\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        elif C == 3:\n",
    "                            ofm_display = ofm_cpu.transpose(1, 2, 0) \n",
    "                            ofm_display_norm = (ofm_display - ofm_display.min()) / (ofm_display.max() - ofm_display.min() + 1e-8)\n",
    "                            axes[2].imshow(ofm_display_norm)\n",
    "                        else: \n",
    "                            ofm_display = ofm_cpu[0]\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto\\nMáscara {mask_idx}')\n",
    "                else: \n",
    "                    axes[2].text(0.5, 0.5, \"Formato de características de objeto inesperado\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                    axes[2].set_title('Mapa de Características de Objeto (Error)')\n",
    "\n",
    "                axes[2].axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{plot_filename_prefix}_mask_{mask_idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al visualizar el mapa de características de objeto para máscara {mask_idx} de {os.path.basename(original_image_path)}: {e}\")\n",
    "\n",
    "    # --- Aplicar el proceso a la imagen de consulta y a las imágenes de referencia ---\n",
    "\n",
    "    print(\"\\n--- Generando Mapas de Características de Objeto ---\")\n",
    "\n",
    "    TARGET_MASK_H = 8 * H_prime \n",
    "    TARGET_MASK_W = 8 * W_prime \n",
    "    print(f\"TARGET_MASK_H: {TARGET_MASK_H}\")\n",
    "    print(f\"TARGET_MASK_W: {TARGET_MASK_W}\")\n",
    "\n",
    "    fobj_q, scaled_masks_query = process_masks_to_object_feature_maps(\n",
    "        masks_data_query_image,\n",
    "        query_hr_feats.squeeze(0), \n",
    "        TARGET_MASK_H,\n",
    "        TARGET_MASK_W,\n",
    "        image_for_sam_np.shape \n",
    "    )\n",
    "\n",
    "    fobj_q = fobj_q.to(device)\n",
    "\n",
    "    print(f\"Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): {fobj_q.shape}\") \n",
    "\n",
    "    all_fobj_r_list = [] \n",
    "    for i, similar_hr_feats in enumerate(similar_hr_feats_list):\n",
    "        current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "        img_similar_pil = Image.open(rutas_imagenes_similares[i]).convert('RGB') \n",
    "        image_np_similar_for_sam_shape = np.array(img_similar_pil).shape\n",
    "\n",
    "        fobj_r_current, scaled_masks_similar = process_masks_to_object_feature_maps(\n",
    "            current_similar_masks_raw,\n",
    "            similar_hr_feats.squeeze(0), \n",
    "            TARGET_MASK_H,\n",
    "            TARGET_MASK_W,\n",
    "            image_np_similar_for_sam_shape \n",
    "        )\n",
    "        fobj_r_current = fobj_r_current.to(device)\n",
    "        \n",
    "        all_fobj_r_list.append(fobj_r_current)\n",
    "        print(f\"Dimensiones de fobj_r para vecino {i+1}: {fobj_r_current.shape}\") \n",
    "        print(\"\\nTipos de los elementos en all_fobj_r_list:\")\n",
    "        for idx, fobj_r in enumerate(all_fobj_r_list):\n",
    "            print(f\"Vecino {idx + 1}: Tipo de fobj_r:\", type(fobj_r))\n",
    "    print(\"\\nProceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\")\n",
    "\n",
    "\n",
    "    # -----------3.5.2 Object matching module-----------------\n",
    "    ## Matching\n",
    "    # --- Definición de la función show_anomalies_on_image ---\n",
    "    def show_anomalies_on_image(image_np, masks, anomalous_info, alpha=0.5, save_path=None):\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image_np)\n",
    "\n",
    "        for obj_id, similarity in anomalous_info: # Iterate through (id, similarity) tuples\n",
    "            # Extraer la máscara binaria real\n",
    "            mask = masks[obj_id]['segmentation']\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "\n",
    "            # Crear máscara en rojo\n",
    "            colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "            colored_mask[mask > 0] = [255, 0, 0]\n",
    "            plt.imshow(colored_mask, alpha=alpha)\n",
    "\n",
    "            # Calcular centroide para colocar el texto\n",
    "            ys, xs = np.where(mask > 0)\n",
    "            if len(xs) > 0 and len(ys) > 0:\n",
    "                cx = int(xs.mean())\n",
    "                cy = int(ys.mean())\n",
    "                \n",
    "                # Create text with index and percentage\n",
    "                text_label = f\"{obj_id} ({similarity*100:.2f}%)\"\n",
    "                plt.text(cx, cy, text_label, color='white', fontsize=10, fontweight='bold', ha='center', va='center',\n",
    "                        bbox=dict(facecolor='red', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "        plt.title(\"Objetos Anómalos en Rojo con Índice y Similitud\") # Updated title for clarity\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de anomalías guardado en: {save_path}\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    # --- Fin de la definición de la función show_anomalies_on_image ---\n",
    "    # --- Nuevas funciones de ploteo para la matriz P y P_augmented_full ---\n",
    "    def plot_assignment_matrix(P_matrix, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación P\"):\n",
    "\n",
    "        if isinstance(P_matrix, torch.Tensor):\n",
    "            #P_matrix = P_matrix.cpu().numpy()\n",
    "            P_matrix = P_matrix.detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(P_matrix.shape[1] * 0.8 + 2, P_matrix.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_matrix, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(reference_labels)), reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(query_labels)), query_labels)\n",
    "        plt.xlabel('Objetos de Referencia')\n",
    "        plt.ylabel('Objetos de Consulta')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_augmented_assignment_matrix(P_augmented_full, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación Aumentada (con Trash Bin)\"):\n",
    "\n",
    "        if isinstance(P_augmented_full, torch.Tensor):\n",
    "            #P_augmented_full = P_augmented_full.cpu().numpy()\n",
    "            P_augmented_full = P_augmented_full.detach().cpu().numpy()\n",
    "\n",
    "        # Añadir etiquetas para los trash bins\n",
    "        full_query_labels = [f\"Q_{i}\" for i in query_labels] + [\"Trash Bin (Q)\"]\n",
    "        full_reference_labels = [f\"R_{i}\" for i in reference_labels] + [\"Trash Bin (R)\"]\n",
    "\n",
    "        plt.figure(figsize=(P_augmented_full.shape[1] * 0.8 + 2, P_augmented_full.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_augmented_full, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(full_reference_labels)), full_reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(full_query_labels)), full_query_labels)\n",
    "        plt.xlabel('Objetos de Referencia y Trash Bin')\n",
    "        plt.ylabel('Objetos de Consulta y Trash Bin')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación aumentada guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# --- Fin de las nuevas funciones de ploteo ---\n",
    "\n",
    "    ## Matching-continue---\n",
    "    ## Matching\n",
    "    start_time_sam_matching = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    def apply_global_max_pool(feat_map):\n",
    "        return F.adaptive_max_pool2d(feat_map, output_size=1).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    class SimpleObjectMatchingModule(nn.Module):\n",
    "        def __init__(self, sinkhorn_iterations=100, sinkhorn_epsilon=0.1, bin_score_value=0.5):\n",
    "            super(SimpleObjectMatchingModule, self).__init__()\n",
    "            self.sinkhorn_iterations = sinkhorn_iterations\n",
    "            self.sinkhorn_epsilon = sinkhorn_epsilon\n",
    "            self.z = nn.Parameter(torch.tensor(bin_score_value, dtype=torch.float32))\n",
    "\n",
    "        def forward(self, d_M_q, d_N_r):\n",
    "            M = d_M_q.shape[0]\n",
    "            N = d_N_r.shape[0]\n",
    "\n",
    "            if M == 0 or N == 0:\n",
    "                return torch.empty(M, N, device=d_M_q.device), \\\n",
    "                    torch.empty(M+1, N+1, device=d_M_q.device)\n",
    "\n",
    "            score_matrix = torch.mm(d_M_q, d_N_r.T)\n",
    "            #print(\"score_matrix (antes de Sinkhorn):\\n\", score_matrix)\n",
    "\n",
    "            S_augmented = torch.zeros((M + 1, N + 1), device=d_M_q.device, dtype=d_M_q.dtype)\n",
    "            S_augmented[:M, :N] = score_matrix\n",
    "            S_augmented[:M, N] = self.z\n",
    "            S_augmented[M, :N] = self.z\n",
    "            S_augmented[M, N] = self.z\n",
    "            print(\"S_augmented antes de Sinkhorn:\\n\", S_augmented)\n",
    "\n",
    "            K = torch.exp(S_augmented / self.sinkhorn_epsilon)\n",
    "            print(\"K (antes de Sinkhorn):\\n\", K)\n",
    "            \n",
    "\n",
    "            for i in range(self.sinkhorn_iterations):\n",
    "                K = K / K.sum(dim=1, keepdim=True)\n",
    "                K = K / K.sum(dim=0, keepdim=True)\n",
    "                #print(f\"Iteración {i+1}: K.shape = {K}\")\n",
    "\n",
    "            P_augmented_full = K\n",
    "            P = P_augmented_full[:M, :N]\n",
    "\n",
    "            return P, P_augmented_full\n",
    "\n",
    "    if fobj_q.shape[0] == 0:\n",
    "        print(\"Advertencia: fobj_q tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "        continue\n",
    "\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        if fobj_r_current.shape[0] == 0:\n",
    "            print(\"Advertencia: fobj_r_current tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "            continue\n",
    "    \n",
    "    fobj_q_pooled = apply_global_max_pool(fobj_q)\n",
    "    print(\"Shape de fobj_q_pooled:\", fobj_q_pooled.shape)\n",
    "    print(\"Máximo de fobj_q_pooled:\", torch.max(fobj_q_pooled).item())\n",
    "    print(\"Mínimo de fobj_q_pooled:\", torch.min(fobj_q_pooled).item())\n",
    "\n",
    "    all_fobj_r_pooled_list = []\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        pooled_r = apply_global_max_pool(fobj_r_current)\n",
    "        all_fobj_r_pooled_list.append(pooled_r)\n",
    "        \n",
    "    d_M_q = F.normalize(fobj_q_pooled, p=2, dim=1) #shape (M, C)\n",
    "    d_N_r_list = [F.normalize(fobj_r_pooled, p=2, dim=1) \n",
    "                                for fobj_r_pooled in all_fobj_r_pooled_list]\n",
    "    print(\"Máximo de d_M_q:\", torch.max(d_M_q).item())\n",
    "    print(\"Mínimo de d_M_q:\", torch.min(d_M_q).item())\n",
    "\n",
    "    object_matching_module = SimpleObjectMatchingModule(\n",
    "        sinkhorn_iterations=100,\n",
    "        sinkhorn_epsilon=0.1,\n",
    "        bin_score_value=0.9 #2.36\n",
    "    ).to(device)\n",
    "\n",
    "    P_matrices = []\n",
    "    P_augmented_full_matrices = []\n",
    "\n",
    "    for i, d_N_r_current_image in enumerate(d_N_r_list):\n",
    "        d_M_q_cuda = d_M_q.to(device)\n",
    "        d_N_r_current_image_cuda = d_N_r_current_image.to(device)\n",
    "\n",
    "        P_current, P_augmented_current = object_matching_module(d_M_q_cuda, d_N_r_current_image_cuda)\n",
    "        P_matrices.append(P_current)\n",
    "        P_augmented_full_matrices.append(P_augmented_current)\n",
    "\n",
    "\n",
    "    print(\"\\n--- Matrices P y P_augmented_full generadas ---\")\n",
    "    # --- NUEVOS DICCIONARIOS CONSOLIDADOS ---\n",
    "    # Almacenarán para cada query_idx, las referencias que le corresponden de TODOS los vecinos.\n",
    "    M = d_M_q.shape[0]\n",
    "    all_matched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)} # M es el número de objetos de consulta (Iq)\n",
    "    all_closest_unmatched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)}\n",
    "    # Imprimir shapes de los diccionarios consolidados\n",
    "    #//////\n",
    "    print(\"\\n--- Resultados Consolidados ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {closest_unmatches}\")\n",
    "    #/////////////////\n",
    "    # Procesar matrices P y P_augmented_full para obtener índices\n",
    "    for i, (P, P_augmented_full) in enumerate(zip(P_matrices, P_augmented_full_matrices)):\n",
    "        current_neighbor_key = f\"Vecino_{i+1}\"\n",
    "        N_current = P.shape[1] \n",
    "\n",
    "        print(f\"\\n--- Vecino {current_neighbor_key} ---\")\n",
    "        print(f\"Matriz P (MxN) para el vecino {current_neighbor_key}:\")\n",
    "        print(P)\n",
    "        print(f\"Matriz P_augmented_full (M+1 x N+1) para el vecino {current_neighbor_key}:\")\n",
    "        print(P_augmented_full)\n",
    "\n",
    "        # Imprimir sumas de filas y columnas de P_augmented_full\n",
    "        augmented_with_totals = torch.cat([\n",
    "            torch.cat([P_augmented_full, P_augmented_full.sum(dim=0, keepdim=True)], dim=0),\n",
    "            torch.cat([P_augmented_full.sum(dim=1, keepdim=True), P_augmented_full.sum().unsqueeze(0).unsqueeze(0)], dim=0)\n",
    "        ], dim=1)\n",
    "        print(f\"Matriz P_augmented_full con totales (M+2 x N+2):\\n{augmented_with_totals}\")\n",
    "\n",
    "        print(f\"\\n--- Decisiones de Emparejamiento para el Vecino {current_neighbor_key} ---\")\n",
    "        for obj_idx in range(P.shape[0]):\n",
    "            \n",
    "            # Obtener la probabilidad más alta dentro de P y su índice\n",
    "            if N_current > 0:\n",
    "                max_prob_P = P[obj_idx].max().item()\n",
    "                max_idx_P = P[obj_idx].argmax().item()\n",
    "            else:\n",
    "                max_prob_P = -float('inf')\n",
    "                max_idx_P = -1\n",
    "\n",
    "            trash_bin_prob = P_augmented_full[obj_idx, -1].item() \n",
    "\n",
    "            print(f\"   Objeto de Consulta {obj_idx}:\")\n",
    "            print(f\"     Probabilidad máxima en P: {max_prob_P:.4f} en el índice {max_idx_P}\")\n",
    "            print(f\"     Probabilidad en el 'Trash Bin': {trash_bin_prob:.4f}\")\n",
    "\n",
    "\n",
    "        # Decisión y almacenamiento en los diccionarios consolidados\n",
    "            if trash_bin_prob > max_prob_P:\n",
    "                # Desemparejado: ahora añadimos el 'primer máximo' a la lista de ese objeto de consulta\n",
    "                if max_idx_P != -1: # Solo añadir si hay un 'primer máximo' válido\n",
    "                    all_closest_unmatched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto {max_idx_P}\")\n",
    "            else:\n",
    "                # Emparejado: añadir el emparejamiento real a la lista de ese objeto de consulta\n",
    "                all_matched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: EMPAREJADO con objeto de imagen {max_idx_P}\")\n",
    "\n",
    "\n",
    "    # --- Resultados Finales Consolidados ---\n",
    "    print(\"\\n--- Resultados Finales Consolidados (Índices) ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {closest_unmatches}\")\n",
    "\n",
    "\n",
    "    # --- AHORA SE NECESITAN ESTOS DICTIONARIOS PARA TU IMPLEMENTACIÓN DE MAHALANOBIS ---\n",
    "    # amm\n",
    "    print(\"--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\")\n",
    "    # --- Utility Functions ---\n",
    "\n",
    "    def percentile_normalize(data_tensor, percentile_cap=99.0):\n",
    "        # This function is for visualization, so if it receives NaN/Inf, it should handle them\n",
    "        # gracefully rather than discarding, to still show what's valid.\n",
    "        if data_tensor.numel() == 0 or data_tensor.max() == data_tensor.min():\n",
    "            return torch.zeros_like(data_tensor)\n",
    "\n",
    "        data_np = data_tensor.cpu().numpy()\n",
    "        \n",
    "        # Clean NaN/Inf for percentile calculation to avoid errors in np.percentile\n",
    "        if np.isnan(data_np).any() or np.isinf(data_np).any():\n",
    "            data_np_cleaned = np.nan_to_num(data_np, nan=0.0, posinf=data_np[np.isfinite(data_np)].max() if np.isfinite(data_np).any() else 0.0, neginf=data_np[np.isfinite(data_np)].min() if np.isfinite(data_np).any() else 0.0)\n",
    "            # Using max/min of finite values for inf to keep scale, or 0 if no finite values.\n",
    "            print(f\"WARNING: NaN/Inf detected in data for percentile normalization. Cleaning for visualization.\")\n",
    "            data_np = data_np_cleaned\n",
    "\n",
    "        p_min = np.percentile(data_np, 1.0)\n",
    "        p_max = 320\n",
    "        print(f\"DEBUG: Percentile normalization - p_min: {p_min}, p_max: {p_max}\")\n",
    "\n",
    "        if p_max <= p_min + 1e-8:\n",
    "            return torch.zeros_like(data_tensor)\n",
    "\n",
    "        normalized_tensor = (data_tensor - p_min) / (p_max - p_min)\n",
    "        normalized_tensor = torch.clamp(normalized_tensor, 0.0, 1.0)\n",
    "        return normalized_tensor\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_mahalanobis_map_single(query_fmap, ref_fmaps, regularization=1e-5, pixel_batch_size=4096):\n",
    "        device = query_fmap.device\n",
    "        k = len(ref_fmaps)\n",
    "        C, H, W = query_fmap.shape\n",
    "\n",
    "        if k < 2:\n",
    "            # Returning a map of zeros, but you could also return None to indicate invalid\n",
    "            # For now, stick to zeros as it's cleaner for subsequent processing, and let\n",
    "            # the calling function decide to discard based on this or actual NaN/Inf later.\n",
    "            return torch.zeros(H, W, device=device, dtype=torch.float32)\n",
    "\n",
    "        query_fmap_float32 = query_fmap.to(torch.float32)\n",
    "        ref_fmaps_float32 = [fmap.to(torch.float32) for fmap in ref_fmaps]\n",
    "\n",
    "        ref_stack = torch.stack(ref_fmaps_float32, dim=0).permute(0, 2, 3, 1)\n",
    "        query_fmap_permuted = query_fmap_float32.permute(1, 2, 0)\n",
    "\n",
    "        N_pixels = H * W\n",
    "        ref_vectors_flat = ref_stack.reshape(k, N_pixels, C)\n",
    "        query_vectors_flat = query_fmap_permuted.reshape(N_pixels, C)\n",
    "\n",
    "        mu = ref_vectors_flat.mean(dim=0)\n",
    "        \n",
    "        maha_map_flat = torch.zeros(N_pixels, device=device, dtype=torch.float32)\n",
    "\n",
    "        for i in range(0, N_pixels, pixel_batch_size):\n",
    "            end_idx = min(i + pixel_batch_size, N_pixels)\n",
    "            current_pixel_batch_size = end_idx - i\n",
    "\n",
    "            mu_batch = mu[i:end_idx]\n",
    "            query_vectors_flat_batch = query_vectors_flat[i:end_idx]\n",
    "            \n",
    "            delta_batch = ref_vectors_flat[:, i:end_idx, :] - mu_batch.unsqueeze(0)\n",
    "            delta_reshaped_batch = delta_batch.permute(1, 0, 2)\n",
    "            cov_batch = (delta_reshaped_batch.transpose(-1, -2) @ delta_reshaped_batch) / (k - 1)\n",
    "            \n",
    "            cov_batch += regularization * torch.eye(C, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            try:\n",
    "                cov_inv_batch = torch.linalg.inv(cov_batch)\n",
    "            except RuntimeError:\n",
    "                # If inverse fails, these pixels are problematic, return a \"problem\" value\n",
    "                maha_map_flat[i:end_idx] = float('nan') # Mark as NaN\n",
    "                continue\n",
    "\n",
    "            diff_batch = query_vectors_flat_batch - mu_batch\n",
    "            maha_val_squared_batch = (diff_batch.unsqueeze(1) @ cov_inv_batch @ diff_batch.unsqueeze(2)).squeeze()\n",
    "            \n",
    "            maha_map_flat[i:end_idx] = torch.sqrt(torch.relu(maha_val_squared_batch))\n",
    "            \n",
    "            del mu_batch, query_vectors_flat_batch, delta_batch, delta_reshaped_batch, cov_batch, cov_inv_batch, diff_batch, maha_val_squared_batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        maha_map = maha_map_flat.reshape(H, W)\n",
    "        \n",
    "        # Crucial change: Don't clean here. Let the caller decide to discard.\n",
    "        # We only check if it contains NaN/Inf.\n",
    "        if torch.isnan(maha_map).any() or torch.isinf(maha_map).any():\n",
    "            print(f\"DEBUG: NaN/Inf detected in raw Mahalanobis map (shape {maha_map.shape}). This map will be marked for potential discard by caller.\")\n",
    "            # Return the map as is, with NaNs/Infs, so the caller can check it.\n",
    "        \n",
    "        return maha_map\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def compute_matching_score_map(\n",
    "        fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        matching_maha_maps = []\n",
    "        all_raw_maha_values = [] \n",
    "        \n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx]\n",
    "            device = query_fmap.device\n",
    "\n",
    "            matched_ref_fmaps_list = []\n",
    "            for neighbor_idx, ref_idx in all_matched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                matched_ref_fmaps_list.append(ref_fmap)\n",
    "                \n",
    "            if len(matched_ref_fmaps_list) >= 2:\n",
    "                maha_map_raw = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=matched_ref_fmaps_list,\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            else:\n",
    "                map_H, map_W = query_fmap.shape[1], query_fmap.shape[2]\n",
    "                maha_map_raw = torch.zeros((map_H, map_W), device=device) # Assign zero if less than two matches\n",
    "            \n",
    "            # Check here: If the map is invalid, do NOT add it to the list\n",
    "            if torch.isnan(maha_map_raw).any() or torch.isinf(maha_map_raw).any():\n",
    "                print(f\"WARNING: Discarding Matching Score Map for Query Object {query_idx} due to NaN/Inf values.\")\n",
    "                # Do not append this map\n",
    "            else:\n",
    "                all_raw_maha_values.append(maha_map_raw.flatten().cpu()) \n",
    "                matching_maha_maps.append(maha_map_raw.cpu())\n",
    "\n",
    "                if plot_save_dir:\n",
    "                    plt.figure(figsize=(6, 5))\n",
    "                    maha_map_for_plot = matching_maha_maps[-1] # This map is guaranteed to be clean\n",
    "                    plot_normalized_maha = percentile_normalize(maha_map_for_plot, percentile_cap=99.0)\n",
    "                    plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                    plt.title(f\"Matching Score Map (Percentile Normalized) - Obj {query_idx}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                    plt.tight_layout()\n",
    "                    save_path = os.path.join(plot_save_dir, f\"matching_score_percentile_norm_obj_{query_idx}.png\")\n",
    "                    plt.savefig(save_path)\n",
    "                    plt.close()\n",
    "\n",
    "        global_min_maha = 0.0\n",
    "        global_max_maha = 1.0\n",
    "\n",
    "        if all_raw_maha_values:\n",
    "            combined_raw_values = torch.cat(all_raw_maha_values)\n",
    "            global_min_maha = combined_raw_values.min().item()\n",
    "            global_max_maha = combined_raw_values.max().item()\n",
    "            if global_max_maha <= global_min_maha:\n",
    "                global_max_maha = global_min_maha + 1e-8 \n",
    "\n",
    "        return matching_maha_maps, (global_min_maha, global_max_maha)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_unmatched_score_map(\n",
    "        fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        \n",
    "        unmatched_maha_maps = []\n",
    "\n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx] \n",
    "            device = query_fmap.device\n",
    "            map_H, map_W = query_fmap.shape[1], query_fmap.shape[2] \n",
    "\n",
    "            closest_ref_fmaps = []\n",
    "            for neighbor_idx, ref_idx in all_closest_unmatched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap_closest = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                closest_ref_fmaps.append(ref_fmap_closest)\n",
    "\n",
    "            if len(closest_ref_fmaps) == 0:\n",
    "                maha_map_to_return = torch.zeros((map_H, map_W), device=device)\n",
    "                \n",
    "            elif len(closest_ref_fmaps) == 1:\n",
    "                single_ref_fmap = closest_ref_fmaps[0]\n",
    "                effective_ref_fmaps = [single_ref_fmap, single_ref_fmap] \n",
    "                \n",
    "                maha_map_to_return = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=effective_ref_fmaps, \n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                maha_map_to_return = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=closest_ref_fmaps,\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            \n",
    "            # Check here: If the map is invalid, do NOT add it to the list\n",
    "            if torch.isnan(maha_map_to_return).any() or torch.isinf(maha_map_to_return).any():\n",
    "                print(f\"WARNING: Discarding Unmatched Score Map for Query Object {query_idx} due to NaN/Inf values.\")\n",
    "                # Do not append this map\n",
    "            else:\n",
    "                unmatched_maha_maps.append(maha_map_to_return.cpu())\n",
    "\n",
    "                if plot_save_dir:\n",
    "                    plt.figure(figsize=(6, 5))\n",
    "                    maha_map_for_plot = unmatched_maha_maps[-1] # This map is guaranteed to be clean\n",
    "                    plot_normalized_maha = percentile_normalize(maha_map_for_plot, percentile_cap=99.0)\n",
    "                    plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                    plt.title(f\"Unmatched Anomaly Map (Percentile Normalized) - Obj {query_idx}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                    plt.tight_layout()\n",
    "                    save_path = os.path.join(plot_save_dir, f\"unmatched_anomaly_percentile_norm_obj_{query_idx}.png\")\n",
    "                    plt.savefig(save_path)\n",
    "                    plt.close()\n",
    "\n",
    "        return unmatched_maha_maps\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def build_aggregated_score_map(individual_score_maps_list, final_size=(1024, 1024), title_prefix=\"Global Score Map\", plot_save_dir=None, filename_prefix=\"global_score_map\"):\n",
    "\n",
    "        H_out, W_out = final_size\n",
    "        aggregated_score_map = torch.zeros((H_out, W_out), device='cpu') \n",
    "\n",
    "        if not individual_score_maps_list:\n",
    "            print(f\"INFO: No valid individual score maps to aggregate for '{title_prefix}'. Returning empty map.\")\n",
    "            return aggregated_score_map\n",
    "        \n",
    "        for i, score_map in enumerate(individual_score_maps_list):\n",
    "            if torch.isnan(score_map).any() or torch.isinf(score_map).any():\n",
    "                print(f\"CRITICAL WARNING: NaN/Inf detectado en un mapa de puntuación individual {i} después de verificaciones. Saltando.\")\n",
    "                continue\n",
    "                \n",
    "            if score_map.dim() == 2:\n",
    "                score_map_tensor = score_map.unsqueeze(0).unsqueeze(0) \n",
    "            else:\n",
    "                print(f\"WARNING: El mapa de puntuación individual {i} tiene dimensiones inesperadas {score_map.dim()}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            score_resized = F.interpolate(\n",
    "                score_map_tensor.to('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "                size=(H_out, W_out),\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            ).squeeze().cpu()\n",
    "            \n",
    "            aggregated_score_map = torch.max(aggregated_score_map, score_resized)\n",
    "        \n",
    "        # Aplicación del filtro Gaussiano\n",
    "        aggregated_score_map_for_blur = aggregated_score_map.unsqueeze(0)\n",
    "        \n",
    "        gaussian_blur_kernel_size = 19 \n",
    "        \n",
    "        gaussian_blur = T.GaussianBlur(kernel_size=(gaussian_blur_kernel_size, gaussian_blur_kernel_size), sigma=(3.0, 3.0))\n",
    "        \n",
    "        aggregated_score_map_smoothed = gaussian_blur(aggregated_score_map_for_blur)\n",
    "        \n",
    "        aggregated_score_map = aggregated_score_map_smoothed.squeeze(0)\n",
    "\n",
    "        # Verificación final y limpieza después de la agregación y el suavizado\n",
    "        if torch.isnan(aggregated_score_map).any() or torch.isinf(aggregated_score_map).any():\n",
    "            print(f\"ADVERTENCIA CRÍTICA: NaN/Inf detectado en el mapa de puntuación agregado '{title_prefix}' después de la agregación y suavizado. Limpiando para la salida.\")\n",
    "            aggregated_score_map = torch.nan_to_num(aggregated_score_map, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if plot_save_dir:\n",
    "            os.makedirs(plot_save_dir, exist_ok=True)\n",
    "            \n",
    "            plt.figure(figsize=(8, 7))\n",
    "            map_for_plot = aggregated_score_map \n",
    "            plot_normalized_map = percentile_normalize(map_for_plot, percentile_cap=99.0)\n",
    "\n",
    "            plt.imshow(plot_normalized_map.numpy(), cmap=\"hot\", vmin=0, vmax=1)\n",
    "            plt.title(title_prefix + \" (Normalizado por Percentil & Suavizado)\") \n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Puntuación Acumulada (Normalizada para visualización)\")\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_prefix}_percentile_norm_smoothed.png\") \n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "\n",
    "        return aggregated_score_map\n",
    "\n",
    "    def overlay_anomaly_map_on_image(image_rgb_path, anomaly_map, alpha=0.7, cmap='magma', plot_save_dir=None, filename_suffix=\"overlay\"):\n",
    "        try:\n",
    "            image_original_loaded = Image.open(image_rgb_path).convert(\"RGB\")\n",
    "            image_np = np.array(image_original_loaded)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Image not found at {image_rgb_path}. Cannot overlay anomaly map.\")\n",
    "            return\n",
    "\n",
    "        if isinstance(anomaly_map, torch.Tensor):\n",
    "            anomaly_np = anomaly_map.cpu().numpy()\n",
    "        else:\n",
    "            anomaly_np = anomaly_map\n",
    "\n",
    "        # Ensure anomaly_np is clean before sending to percentile_normalize for plotting\n",
    "        if np.isnan(anomaly_np).any() or np.isinf(anomaly_np).any():\n",
    "            print(f\"WARNING: NaN/Inf detected in anomaly map for overlay. Cleaning up for visualization.\")\n",
    "            anomaly_np = np.nan_to_num(anomaly_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        anomaly_norm = percentile_normalize(torch.from_numpy(anomaly_np), percentile_cap=99.0).numpy()\n",
    "\n",
    "        if anomaly_norm.shape[:2] != image_np.shape[:2]:\n",
    "            anomaly_norm = np.array(Image.fromarray(anomaly_norm).resize(\n",
    "                (image_np.shape[1], image_np.shape[0]), resample=Image.BILINEAR\n",
    "            ))\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(image_np)\n",
    "        #plt.imshow(anomaly_norm, cmap=cmap, alpha=alpha)\n",
    "        plt.imshow(anomaly_norm, cmap=cmap, alpha=alpha,vmin=0, vmax=1)\n",
    "        plt.title(\"Anomaly Heatmap Overlay (Percentile Normalized)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if plot_save_dir:\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_suffix}_percentile_norm.png\")\n",
    "            plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "    # --- Main script execution ---\n",
    "    # (Variables like PLOT_SAVE_ROOT_DIR, MAHALANOBIS_SCORE_MAPS_DIR,\n",
    "    # query_image_path, base_image_name, fobj_q, all_fobj_r_list,\n",
    "    # all_matched_ref_indices_by_query_obj, all_closest_unmatched_ref_indices_by_query_obj\n",
    "    # should be defined in your execution environment)\n",
    "\n",
    "    print(\"--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\")\n",
    "\n",
    "    # Assuming start_time_total is defined here or earlier\n",
    "    # start_time_total = time.time() # Example\n",
    "\n",
    "    print(\"pre1: Moviendo feature objects de query a GPU...\")\n",
    "    if isinstance(fobj_q, list):\n",
    "        fobj_q = [fmap.to('cuda') for fmap in fobj_q]\n",
    "    else:\n",
    "        fobj_q = fobj_q.to('cuda')\n",
    "\n",
    "    print(\"pre2: Moviendo feature objects de referencia a GPU...\")\n",
    "    all_fobj_r_list_gpu = []\n",
    "    for inner_list in all_fobj_r_list:\n",
    "        all_fobj_r_list_gpu.append([fmap.to('cuda') for fmap in inner_list])\n",
    "\n",
    "    all_fobj_r_list = all_fobj_r_list_gpu\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"preparación de GPU completa.\")\n",
    "\n",
    "    print(\"Calculando mapas de puntuación de matching...\")\n",
    "    all_matching_score_maps, matched_maha_range_global = compute_matching_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-2, # Keep your refined regularization value here\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        pixel_batch_size=4096\n",
    "    )\n",
    "    print(f\"Total de mapas de matching válidos: {len(all_matching_score_maps)}\")\n",
    "\n",
    "\n",
    "    print(\"Calculando mapas de puntuación de unmatched...\")\n",
    "    all_unmatched_score_maps = compute_unmatched_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj=all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-2, # Keep your refined regularization value here\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        pixel_batch_size=4096\n",
    "    )\n",
    "    print(f\"Total de mapas de unmatched válidos: {len(all_unmatched_score_maps)}\")\n",
    "\n",
    "    image_original = Image.open(query_image_path)\n",
    "    H, W = image_original.size\n",
    "\n",
    "    print(\"Construyendo mapa agregado de matching...\")\n",
    "    global_matched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_matching_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Matched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_matched_anomaly_raw\")\n",
    "\n",
    "    print(\"Construyendo mapa agregado de unmatched...\")\n",
    "    global_unmatched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_unmatched_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Unmatched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_unmatched_anomaly_raw\")\n",
    "\n",
    "    combined_individual_score_maps = []\n",
    "    num_queries = len(fobj_q)\n",
    "    for i in range(num_queries):\n",
    "        # Retrieve maps from the potentially filtered lists\n",
    "        # Note: The order/count in all_matching_score_maps and all_unmatched_score_maps\n",
    "        # might not perfectly match query_idx if maps were discarded.\n",
    "        # To correctly combine, you might need a more robust way to associate.\n",
    "        # For now, let's assume they are still ordered by query_idx if not discarded.\n",
    "        # This part might need refinement if map discarding leads to mismatch.\n",
    "        \n",
    "        # Let's filter here again based on the original fobj_q indices to be safe\n",
    "        # This is a placeholder for more robust association if needed.\n",
    "        matched_map_for_query = None\n",
    "        if i < len(all_matching_score_maps): # Simple check assuming order\n",
    "            matched_map_for_query = all_matching_score_maps[i]\n",
    "            \n",
    "        unmatched_map_for_query = None\n",
    "        if i < len(all_unmatched_score_maps): # Simple check assuming order\n",
    "            unmatched_map_for_query = all_unmatched_score_maps[i]\n",
    "        \n",
    "        # Only combine if both maps are available and valid for this query_idx\n",
    "        if matched_map_for_query is not None and unmatched_map_for_query is not None and \\\n",
    "        not (torch.isnan(matched_map_for_query).any() or torch.isinf(matched_map_for_query).any()) and \\\n",
    "        not (torch.isnan(unmatched_map_for_query).any() or torch.isinf(unmatched_map_for_query).any()):\n",
    "            \n",
    "            combined_map_for_query_i = matched_map_for_query + unmatched_map_for_query\n",
    "            combined_individual_score_maps.append(combined_map_for_query_i)\n",
    "        else:\n",
    "            print(f\"INFO: Query Object {i} is partially or fully discarded for combined map due to missing/invalid individual maps.\")\n",
    "\n",
    "\n",
    "    print(f\"Number of valid combined individual score maps for aggregation: {len(combined_individual_score_maps)}\")\n",
    "    if combined_individual_score_maps:\n",
    "        all_max_values = [m.max().item() for m in combined_individual_score_maps]\n",
    "        print(f\"Max values across all combined_individual_score_maps: {all_max_values}\")\n",
    "\n",
    "    print(\"Construyendo mapa total de anomalías...\")\n",
    "    global_total_anomaly_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=combined_individual_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Total Anomaly Map (Sum of RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_total_anomaly_raw\")\n",
    "\n",
    "    print(\"Generando superposiciones de mapas de anomalías...\")\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_matched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_matched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_unmatched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_unmatched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_total_anomaly_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_total_anomaly_overlay_raw\")\n",
    "\n",
    "    score_map_filename = f\"maha_{base_image_name}.npy\"\n",
    "    score_map_save_path = os.path.join(MAHALANOBIS_SCORE_MAPS_DIR, score_map_filename)\n",
    "\n",
    "    score_map_to_save = global_total_anomaly_score_map.cpu().numpy()\n",
    "\n",
    "    np.save(score_map_save_path, score_map_to_save)\n",
    "    print(\"finalizado iteracion\")\n",
    "\n",
    "    # Assuming start_time_total and start_time_global are defined somewhere\n",
    "    # end_time_total = time.time()\n",
    "    # total_time = end_time_total - start_time_total\n",
    "    # print(f\"Tiempo total de ejecución iteracion: {total_time:.2f} segundos\")\n",
    "\n",
    "    # Check and report NaN/Inf in the final saved map\n",
    "    nan_count = np.isnan(score_map_to_save).sum()\n",
    "    inf_count = np.isinf(score_map_to_save).sum()\n",
    "\n",
    "    if nan_count > 0 or inf_count > 0:\n",
    "        print(f\"\\n--- REPORTE FINAL DE INCONSISTENCIAS ---\")\n",
    "        print(f\"ATENCIÓN: El mapa de Mahalanobis final guardado '{score_map_save_path}' contiene:\")\n",
    "        print(f\"  - {nan_count} valores NaN (Not a Number)\")\n",
    "        print(f\"  - {inf_count} valores Inf (Infinito)\")\n",
    "        print(f\"A pesar de los descartes, si estos valores aparecen aquí, significa que la agregación o una etapa posterior pudo haberlos reintroducido o que un mapa descartado era la única fuente.\")\n",
    "        print(f\"Este mapa final fue limpiado para asegurar que sea numéricamente manejable.\")\n",
    "    else:\n",
    "        print(f\"\\n--- REPORTE FINAL DE INCONSISTENCIAS ---\")\n",
    "        print(f\"No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '{score_map_save_path}'.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Top 10 valores del mapa global de anomalía ---\")\n",
    "    for query_image_path in image_paths:\n",
    "        base_image_name_with_ext = os.path.basename(query_image_path)\n",
    "        base_image_name = os.path.splitext(base_image_name_with_ext)[0]\n",
    "        score_map_filename = f\"maha_{base_image_name}.npy\"\n",
    "        score_map_path = os.path.join(MAHALANOBIS_SCORE_MAPS_DIR, score_map_filename)\n",
    "\n",
    "        try:\n",
    "            score_map = np.load(score_map_path)\n",
    "            top_10_values = np.sort(score_map.flatten())[-10:]\n",
    "            print(f\"Imagen: {base_image_name}\")\n",
    "            print(f\"Top 10 valores: {top_10_values}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: No se encontró el archivo de mapa de puntuación para la imagen '{base_image_name}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Ocurrió un problema al procesar la imagen '{base_image_name}'. Detalles: {e}\")\n",
    "\n",
    "\n",
    "print(\"finalizado\")\n",
    "# end_time_global = time.time()\n",
    "# total_global_time = end_time_global - start_time_global\n",
    "# print(f\"Tiempo total de ejecución global: {total_global_time:.2f} segundos\")\n",
    "\n",
    "# --- Imprimir los 10 valores más altos del mapa global de anomalía para cada imagen ---\n",
    "# --- NUEVA FUNCIÓN: Obtener y mostrar los top N valores más altos ---\n",
    "def get_top_n_values_from_maps(mahalanobis_maps_dict, map_file_ids_dict, n=10):\n",
    "    print(f\"\\n--- Top {n} valores más altos de Mahalanobis para cada mapa ---\")\n",
    "    for cls_name, maps_list in mahalanobis_maps_dict.items():\n",
    "        file_ids = map_file_ids_dict.get(cls_name, [])\n",
    "        if not maps_list:\n",
    "            print(f\"   No hay mapas para la clase '{cls_name}'.\")\n",
    "            continue\n",
    "        print(f\" Clase: '{cls_name}'\")\n",
    "        for i, score_map in enumerate(maps_list):\n",
    "            if score_map.size == 0:\n",
    "                print(f\"     Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'}: Vacío.\")\n",
    "                continue\n",
    "            \n",
    "            flat_scores = score_map.flatten()\n",
    "            # Sort in descending order and take the top N\n",
    "            top_n_values = np.sort(flat_scores)[::-1][:n]\n",
    "            print(f\"     Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'} (Top {n}): {[f'{val:.4f}' for val in top_n_values]}\")\n",
    "    print(\"--- Fin de la visualización de los top valores ---\")\n",
    "# Load the Mahalanobis score map for the current query image\n",
    "try:\n",
    "    score_map = np.load(score_map_save_path)\n",
    "    top_10_values = np.sort(score_map.flatten())[-10:]\n",
    "    print(f\"Imagen: {os.path.basename(query_image_path)}\")\n",
    "    print(f\"Top 10 valores: {top_10_values}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo de mapa de puntuación para la imagen '{os.path.basename(query_image_path)}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Ocurrió un problema al procesar la imagen '{os.path.basename(query_image_path)}'. Detalles: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_featup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
