{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta para guardar score maps: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/mahalanobis_score_maps\n",
      "Cargando datos del coreset...\n",
      "Coreset cargado. Dimensión: torch.Size([8192, 384])\n",
      "NearestNeighbors finder inicializado.\n",
      "Cargando modelo DINOv2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo DINOv2 cargado.\n",
      "Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\n",
      "Modelo SAM2 cargado.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/good/000.png ---\n",
      "Ground Truth Mask Path para 000: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/good/000_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2611 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=99212, IOU=0.967674732208252, Stability Score=0.9661882519721985\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/000/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 060.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98814, IOU=0.9694907665252686, Stability Score=0.9645093679428101\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/000/processed_masks/similar_mask_overlay_060_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 148.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99067, IOU=0.977931559085846, Stability Score=0.9659727215766907\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/000/processed_masks/similar_mask_overlay_148_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 108.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98505, IOU=0.9766190648078918, Stability Score=0.964866042137146\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/000/processed_masks/similar_mask_overlay_108_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.2765 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.658102512359619\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.13071134686470032\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9897, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19877.9160,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9868, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19302.5312,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9874, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19423.5391,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6103]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6103, 0.3897],\n",
      "        [0.3897, 0.6103]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6103, 0.3897, 1.0000],\n",
      "        [0.3897, 0.6103, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6103 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3897\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6068]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6068, 0.3932],\n",
      "        [0.3932, 0.6068]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6068, 0.3932, 1.0000],\n",
      "        [0.3932, 0.6068, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6068 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3932\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6076]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6076, 0.3924],\n",
      "        [0.3924, 0.6076]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6076, 0.3924, 1.0000],\n",
      "        [0.3924, 0.6076, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6076 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3924\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [306176.65625]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/mahalanobis_score_maps/maha_000.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [145007.36 145222.17 146522.27 146744.16 147355.33 147460.77 151676.84\n",
      " 152366.38 152473.66 153185.92]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '001'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '002'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '003'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '040'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/good/001.png ---\n",
      "Ground Truth Mask Path para 001: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/good/001_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.5329 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97583, IOU=0.9480241537094116, Stability Score=0.95577073097229\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/001/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 248.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97799, IOU=0.9612789154052734, Stability Score=0.9607868790626526\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/001/processed_masks/similar_mask_overlay_248_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 105.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97565, IOU=0.9657941460609436, Stability Score=0.9635220170021057\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/001/processed_masks/similar_mask_overlay_105_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 015.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98450, IOU=0.9397732615470886, Stability Score=0.9668242931365967\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/001/processed_masks/similar_mask_overlay_015_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.5259 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.6985654830932617\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1368923932313919\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9803, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18093.9746,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9803, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18080.8125,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9777, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17630.9727,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5991]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5991, 0.4009],\n",
      "        [0.4009, 0.5991]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5991, 0.4009, 1.0000],\n",
      "        [0.4009, 0.5991, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5991 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4009\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5990, 0.4010],\n",
      "        [0.4010, 0.5990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5990, 0.4010, 1.0000],\n",
      "        [0.4010, 0.5990, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5990 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4010\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5960]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5960, 0.4040],\n",
      "        [0.4040, 0.5960]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5960, 0.4040, 1.0000],\n",
      "        [0.4040, 0.5960, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5960 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4040\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [73024.5234375]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/mahalanobis_score_maps/maha_001.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [145007.36 145222.17 146522.27 146744.16 147355.33 147460.77 151676.84\n",
      " 152366.38 152473.66 153185.92]\n",
      "Imagen: 001\n",
      "Top 10 valores: [70008.91  70022.28  70028.336 70031.15  70033.91  70038.73  70041.086\n",
      " 70043.61  70044.12  70046.125]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '002'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '003'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '040'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/good/002.png ---\n",
      "Ground Truth Mask Path para 002: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/good/002_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3976 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97914, IOU=0.9716282486915588, Stability Score=0.9624249339103699\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/002/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 105.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97565, IOU=0.9657941460609436, Stability Score=0.9635220170021057\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/002/processed_masks/similar_mask_overlay_105_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 015.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98450, IOU=0.9397732615470886, Stability Score=0.9668242931365967\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/002/processed_masks/similar_mask_overlay_015_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 046.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97534, IOU=0.9683951735496521, Stability Score=0.9624007940292358\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/002/processed_masks/similar_mask_overlay_046_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.5267 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.8018579483032227\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.14072273671627045\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9820, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18392.7812,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9851, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18981.6816,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9821, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18421.1504,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6011]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6011, 0.3989],\n",
      "        [0.3989, 0.6011]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6011, 0.3989, 1.0000],\n",
      "        [0.3989, 0.6011, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6011 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3989\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6048]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6048, 0.3952],\n",
      "        [0.3952, 0.6048]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6048, 0.3952, 1.0000],\n",
      "        [0.3952, 0.6048, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6048 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3952\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6012]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6012, 0.3988],\n",
      "        [0.3988, 0.6012]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6012, 0.3988, 1.0000],\n",
      "        [0.3988, 0.6012, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6012 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3988\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [79726.9296875]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/mahalanobis_score_maps/maha_002.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [145007.36 145222.17 146522.27 146744.16 147355.33 147460.77 151676.84\n",
      " 152366.38 152473.66 153185.92]\n",
      "Imagen: 001\n",
      "Top 10 valores: [70008.91  70022.28  70028.336 70031.15  70033.91  70038.73  70041.086\n",
      " 70043.61  70044.12  70046.125]\n",
      "Imagen: 002\n",
      "Top 10 valores: [42796.99  42827.84  42891.4   42957.957 42986.87  43017.117 43103.246\n",
      " 43234.418 43487.684 43641.59 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '003'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '040'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/good/003.png ---\n",
      "Ground Truth Mask Path para 003: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/good/003_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2636 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98917, IOU=0.9503232836723328, Stability Score=0.9585051536560059\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/003/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 162.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98054, IOU=0.9581800699234009, Stability Score=0.9540802836418152\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/003/processed_masks/similar_mask_overlay_162_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 134.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98987, IOU=0.9696258902549744, Stability Score=0.9599682688713074\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/003/processed_masks/similar_mask_overlay_134_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 186.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98654, IOU=0.9584981203079224, Stability Score=0.9560182094573975\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/003/processed_masks/similar_mask_overlay_186_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.1876 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.0120849609375\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1420971006155014\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9847, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18893.0977,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9799, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18012.2285,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9874, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19425.8340,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6043]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6043, 0.3957],\n",
      "        [0.3957, 0.6043]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6043, 0.3957, 1.0000],\n",
      "        [0.3957, 0.6043, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6043 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3957\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5985]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5985, 0.4015],\n",
      "        [0.4015, 0.5985]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5985, 0.4015, 1.0000],\n",
      "        [0.4015, 0.5985, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5985 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4015\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6076]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6076, 0.3924],\n",
      "        [0.3924, 0.6076]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6076, 0.3924, 1.0000],\n",
      "        [0.3924, 0.6076, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6076 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3924\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [82843.875]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/mahalanobis_score_maps/maha_003.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [145007.36 145222.17 146522.27 146744.16 147355.33 147460.77 151676.84\n",
      " 152366.38 152473.66 153185.92]\n",
      "Imagen: 001\n",
      "Top 10 valores: [70008.91  70022.28  70028.336 70031.15  70033.91  70038.73  70041.086\n",
      " 70043.61  70044.12  70046.125]\n",
      "Imagen: 002\n",
      "Top 10 valores: [42796.99  42827.84  42891.4   42957.957 42986.87  43017.117 43103.246\n",
      " 43234.418 43487.684 43641.59 ]\n",
      "Imagen: 003\n",
      "Top 10 valores: [56056.56  56085.293 56214.44  56252.516 56334.168 56351.77  56442.13\n",
      " 56638.336 56768.074 56827.38 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '040'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/good/004.png ---\n",
      "Ground Truth Mask Path para 004: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/good/004_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2854 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98686, IOU=0.9752727746963501, Stability Score=0.9685684442520142\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/004/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 112.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97256, IOU=0.9606473445892334, Stability Score=0.9658211469650269\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/004/processed_masks/similar_mask_overlay_112_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 207.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98578, IOU=0.9661169648170471, Stability Score=0.9670854210853577\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/004/processed_masks/similar_mask_overlay_207_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 093.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98190, IOU=0.9689868092536926, Stability Score=0.9684847593307495\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/004/processed_masks/similar_mask_overlay_093_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.1657 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.258460998535156\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1552073061466217\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9889, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19702.8262,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9879, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19512.2461,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9864, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19221.1172,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6093]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6093, 0.3907],\n",
      "        [0.3907, 0.6093]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6093, 0.3907, 1.0000],\n",
      "        [0.3907, 0.6093, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6093 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3907\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6081]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6081, 0.3919],\n",
      "        [0.3919, 0.6081]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6081, 0.3919, 1.0000],\n",
      "        [0.3919, 0.6081, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6081 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3919\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6063]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6063, 0.3937],\n",
      "        [0.3937, 0.6063]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6063, 0.3937, 1.0000],\n",
      "        [0.3937, 0.6063, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6063 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3937\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [110664.5234375]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/mahalanobis_score_maps/maha_004.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [145007.36 145222.17 146522.27 146744.16 147355.33 147460.77 151676.84\n",
      " 152366.38 152473.66 153185.92]\n",
      "Imagen: 001\n",
      "Top 10 valores: [70008.91  70022.28  70028.336 70031.15  70033.91  70038.73  70041.086\n",
      " 70043.61  70044.12  70046.125]\n",
      "Imagen: 002\n",
      "Top 10 valores: [42796.99  42827.84  42891.4   42957.957 42986.87  43017.117 43103.246\n",
      " 43234.418 43487.684 43641.59 ]\n",
      "Imagen: 003\n",
      "Top 10 valores: [56056.56  56085.293 56214.44  56252.516 56334.168 56351.77  56442.13\n",
      " 56638.336 56768.074 56827.38 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [56277.38  56407.71  56518.633 56629.176 56672.99  56739.902 57728.55\n",
      " 57844.305 58208.523 58324.332]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '023'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '024'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '025'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '026'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '027'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '028'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '029'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '030'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '031'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '032'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '033'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '034'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '035'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '036'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '037'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '038'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '039'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '040'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/good/005.png ---\n",
      "Ground Truth Mask Path para 005: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/good/005_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2908 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=99144, IOU=0.9672757387161255, Stability Score=0.9625323414802551\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/005/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 031.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98927, IOU=0.9719960689544678, Stability Score=0.9653773307800293\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/005/processed_masks/similar_mask_overlay_031_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 194.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98372, IOU=0.9735779762268066, Stability Score=0.963062584400177\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/005/processed_masks/similar_mask_overlay_194_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 311.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98820, IOU=0.9674769043922424, Stability Score=0.9645028710365295\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/good7/005/processed_masks/similar_mask_overlay_311_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.4973 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.293704986572266\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.15481188893318176\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9827, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18532.5312,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9832, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18627.5586,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9813, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18263.8711,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6020]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6020, 0.3980],\n",
      "        [0.3980, 0.6020]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6020, 0.3980, 1.0000],\n",
      "        [0.3980, 0.6020, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6020 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3980\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6026]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6026, 0.3974],\n",
      "        [0.3974, 0.6026]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6026, 0.3974, 1.0000],\n",
      "        [0.3974, 0.6026, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6026 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3974\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6002]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6002, 0.3998],\n",
      "        [0.3998, 0.6002]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6002, 0.3998, 1.0000],\n",
      "        [0.3998, 0.6002, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6002 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3998\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [131839.953125]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# FeatUp utilities\n",
    "from featup.util import norm, unnorm\n",
    "from featup.plotting import plot_feats\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Anomaly region detection and visualization\n",
    "from skimage import measure\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# SAM2 imports\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import cv2\n",
    "\n",
    "# PCA for manual visualization\n",
    "from sklearn.decomposition import PCA\n",
    "# --- Enable loading of truncated images ---\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # Add this at the very top for global effect\n",
    "\n",
    "# --- Configuración ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224  # DINOv2 input size\n",
    "BACKBONE_PATCH_SIZE = 14  # DINOv2 ViT-S/14 patch size\n",
    "use_norm = True\n",
    "\n",
    "H_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "W_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "\n",
    "# Directorios\n",
    "TRAIN_GOOD_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/train/good'\n",
    "directorio_coreset = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/train/good/archivos_coreset'\n",
    "#PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/plots_final_eval/cut'\n",
    "# --- Imagen de Consulta ---\n",
    "BASE_PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion_screw/good7'  # Base directory for saving plots\n",
    "\n",
    "# Directory containing the test images \n",
    "TEST_IMAGES_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/good'\n",
    "\n",
    "# Create parent plot directory if it doesn't exist\n",
    "os.makedirs(BASE_PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "# --- NUEVA CARPETA PARA LOS MAPAS DE ANOMALÍAS ---\n",
    "MAHALANOBIS_SCORE_MAPS_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'mahalanobis_score_maps')\n",
    "os.makedirs(MAHALANOBIS_SCORE_MAPS_DIR, exist_ok=True)\n",
    "print(f\"Carpeta para guardar score maps: {MAHALANOBIS_SCORE_MAPS_DIR}\")\n",
    "\n",
    "# Coreset file paths\n",
    "core_bank_filenames_file = os.path.join(directorio_coreset, 'core_bank_filenames.pt')\n",
    "coreset_relevant_flat_features_bank_file = os.path.join(directorio_coreset, 'coreset_relevant_flat_features_bank.pt')\n",
    "template_features_bank_coreset_file = os.path.join(directorio_coreset, 'template_features_bank_coreset.pt')\n",
    "\n",
    "# --- Cargar Datos del Coreset ---\n",
    "print(\"Cargando datos del coreset...\")\n",
    "try:\n",
    "    coreset_relevant_filenames = torch.load(core_bank_filenames_file)\n",
    "    coreset_relevant_flat_features_bank = torch.load(coreset_relevant_flat_features_bank_file).to(device)\n",
    "    coreset_features = torch.load(template_features_bank_coreset_file).to(device)\n",
    "    print(f\"Coreset cargado. Dimensión: {coreset_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar archivos del coreset: {e}. Asegúrate de que la Etapa 1 se ejecutó.\")\n",
    "    exit()\n",
    "\n",
    "# Mover coreset a CPU para sklearn's NearestNeighbors\n",
    "coreset_features_cpu = coreset_features.cpu().numpy()\n",
    "# se calcula la distancia coseno == 1 - similitud coseno [0,1] 0 identico, 1 completamente diferente\n",
    "nn_finder = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='cosine').fit(coreset_features_cpu)\n",
    "print(\"NearestNeighbors finder inicializado.\")\n",
    "\n",
    "# --- Cargar Modelo DINOv2 ---\n",
    "print(\"Cargando modelo DINOv2...\")\n",
    "featup_local_path = \"/home/imercatoma/FeatUp\"\n",
    "upsampler = torch.hub.load(featup_local_path, 'dinov2', use_norm=use_norm, source='local').to(device)\n",
    "\n",
    "dinov2_model = upsampler.model\n",
    "dinov2_model.eval()\n",
    "print(\"Modelo DINOv2 cargado.\")\n",
    "\n",
    "# --- Transformación de Imagen ---\n",
    "transform = T.Compose([\n",
    "    T.Resize(input_size),\n",
    "    T.CenterCrop((input_size, input_size)),\n",
    "    T.ToTensor(),\n",
    "    norm\n",
    "])\n",
    "\n",
    "# --- Carga del Modelo SAM2 ---\n",
    "print(f\"Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\")\n",
    "checkpoint = \"/home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt\"\n",
    "model_cfg_name = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_model = build_sam2(model_cfg_name, checkpoint, device=device, apply_postprocessing=True)\n",
    "sam2_model.eval()\n",
    "print(\"Modelo SAM2 cargado.\")\n",
    "\n",
    "#### fin de carga de modelos\n",
    "\n",
    "# --- CONFIGURACIÓN PARA EL GUARDADO DE EXCEL ---\n",
    "EXCEL_OUTPUT_PATH = 'resultados_evaluacion_anomalias.xlsx'\n",
    "all_evaluation_results = [] # This list will accumulate results from all processed images\n",
    "\n",
    "# Opción 2: Procesar solo las primeras 10 imágenes (descomentar si prefieres esta opción)\n",
    "image_paths = glob.glob(os.path.join(TEST_IMAGES_DIR, '*.png'))\n",
    "image_paths.sort()\n",
    "\n",
    "######\n",
    "start_time_global = time.time()\n",
    "# --- Bucle para procesar cada imagen ---\n",
    "for query_image_path in image_paths:\n",
    "    start_time_total = time.time()\n",
    "    print(f\"\\n--- Procesando imagen: {query_image_path} ---\")\n",
    "\n",
    "    # Extraer el nombre base de la imagen (ej: '006.png')\n",
    "    base_image_name_with_ext = os.path.basename(query_image_path)\n",
    "    base_image_name = os.path.splitext(base_image_name_with_ext)[0] # '006'\n",
    "\n",
    "    # Construir la ruta de la máscara Ground Truth para la imagen actual\n",
    "    gt_mask_path = query_image_path.replace('test', 'ground_truth').replace('.png', '_mask.png')\n",
    "    print(f\"Ground Truth Mask Path para {base_image_name}: {gt_mask_path}\")\n",
    "\n",
    "    # --- Directorios de guardado específicos para esta imagen ---\n",
    "    PLOT_SAVE_ROOT_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, base_image_name)\n",
    "    os.makedirs(PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "    HEATMAPS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'individual_heatmaps')\n",
    "    os.makedirs(HEATMAPS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    ANOMALY_REGIONS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'detected_anomaly_regions')\n",
    "    os.makedirs(ANOMALY_REGIONS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    FEATUP_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'featup_feature_plots')\n",
    "    os.makedirs(FEATUP_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "    # --- Cargar la imagen de consulta CON ERROR HANDLING ---\n",
    "    query_img_pil = None # Initialize to None\n",
    "    try:\n",
    "        query_img_pil = Image.open(query_image_path).convert(\"RGB\")\n",
    "        W, H = query_img_pil.size # Get dimensions for consistent resizing\n",
    "    except OSError as e:\n",
    "        print(f\"ERROR: No se pudo cargar o procesar la imagen de consulta '{query_image_path}'. Error: {e}\")\n",
    "        print(\"Saltando a la siguiente imagen...\")\n",
    "        continue # Skip to the next image in the loop\n",
    "\n",
    "    # If query_img_pil is still None, it means an error occurred, so skip\n",
    "    if query_img_pil is None:\n",
    "        continue\n",
    "\n",
    "    # Definir el tamaño objetivo para las máscaras de evaluación (el mismo que el mapa de anomalías)\n",
    "    TARGET_EVAL_SIZE = (W, H)\n",
    "\n",
    "    #############----------- PROCESO   -----###############\n",
    "    \n",
    "    input_tensor = transform(query_img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_lr = dinov2_model(input_tensor)\n",
    "\n",
    "    query_lr_features = features_lr\n",
    "\n",
    "    # --- Función para buscar imágenes similares usando KNN ---\n",
    "    def buscar_imagenes_similares_knn(query_feature_map, pre_flattened_features_bank, k=3, nombres_archivos=None):\n",
    "        query_feat_flatten = query_feature_map.flatten().cpu().numpy()#dimension mapa desde banco torch.Size([1, 384, 16, 16])\n",
    "        print(f\"dimension mapa query\", query_feature_map.shape)\n",
    "        print(f\"dimension query flatten\", query_feat_flatten.shape)#dimension query flatten (98304,)\n",
    "        features_bank_for_knn = pre_flattened_features_bank.cpu().numpy() if isinstance(pre_flattened_features_bank, torch.Tensor) else pre_flattened_features_bank\n",
    "        print(f\"dimension query flatten\", features_bank_for_knn.shape)#dimension query flatten (213, 98304)\n",
    "        print(f\"dimensiones desde BANCO STAGE 1 stage\", pre_flattened_features_bank.shape)#dimensiones desde BANCO STAGE 1 stage torch.Size([213, 98304])\n",
    "        \n",
    "        \n",
    "        start_time_knn_dist = time.time()\n",
    "        distances = euclidean_distances([query_feat_flatten], features_bank_for_knn)\n",
    "        nearest_indices = np.argsort(distances[0])[:k]\n",
    "        end_time_knn_dist = time.time()\n",
    "        print(f\"Tiempo para calcular distancias KNN: {end_time_knn_dist - start_time_knn_dist:.4f} segundos\")\n",
    "\n",
    "        imagenes_similares = []\n",
    "        rutas_imagenes_similares = []\n",
    "        if nombres_archivos:\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(nombres_archivos[idx])\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, nombres_archivos[idx]))\n",
    "        else: # Fallback if no filenames provided (less common for this use case)\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(f\"Imagen_Banco_{idx:03d}.png\")\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, f\"Imagen_Banco_{idx:03d}.png\"))\n",
    "        return imagenes_similares, rutas_imagenes_similares, end_time_knn_dist\n",
    "\n",
    "    # --- Búsqueda KNN ---\n",
    "    print(\"\\nBuscando imágenes similares usando el banco pre-aplanado del Coreset...\")\n",
    "    imagenes_similares, rutas_imagenes_similares, time_knn_dist = buscar_imagenes_similares_knn(\n",
    "        query_lr_features, coreset_relevant_flat_features_bank, nombres_archivos=coreset_relevant_filenames\n",
    "    )\n",
    "\n",
    "    # --- Aplicar FeatUp para obtener características de alta resolución ---\n",
    "    def apply_featup_hr(image_path, featup_upsampler, image_transform, device):\n",
    "        image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = image_transform(image_pil).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            lr_feats = featup_upsampler.model(image_tensor)\n",
    "            hr_feats = featup_upsampler(image_tensor)\n",
    "        return lr_feats.cpu(), hr_feats.cpu()\n",
    "\n",
    "    # Características de la imagen de consulta\n",
    "    input_query_tensor_original = transform(Image.open(query_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    query_lr_feats_featup, query_hr_feats = apply_featup_hr(query_image_path, upsampler, transform, device)\n",
    "\n",
    "    # Características de las imágenes similares\n",
    "    similar_hr_feats_list = []\n",
    "    for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "        input_similar_tensor_original = transform(Image.open(similar_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "        similar_lr_feats, similar_hr_feats = apply_featup_hr(similar_image_path, upsampler, transform, device)\n",
    "        similar_hr_feats_list.append(similar_hr_feats)\n",
    "\n",
    "    ################################\n",
    "    ### Aplicando Máscaras SAM query y similares\n",
    "\n",
    "    def show_mask(mask, ax, random_color=False, borders=True):\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image_alpha = np.zeros((h, w, 4), dtype=np.float32)\n",
    "        mask_image_alpha[mask > 0] = color\n",
    "        if borders:\n",
    "            mask_uint8 = mask.astype(np.uint8) * 255\n",
    "            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contour_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=2)\n",
    "            contour_mask = (contour_image.astype(np.float32) / 255.0).sum(axis=-1) > 0\n",
    "            mask_image_alpha[contour_mask > 0, :3] = 1.0\n",
    "            mask_image_alpha[contour_mask > 0, 3] = 0.5\n",
    "        ax.imshow(mask_image_alpha)\n",
    "\n",
    "    def process_masks_with_hierarchy(image, masks, output_dir, filename_prefix, overlap_threshold=0.8):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        final_processed_masks_data = [] \n",
    "        original_mask_segments_for_comparison = [mask_data[\"segmentation\"] for mask_data in masks]\n",
    "\n",
    "        print(f\"Procesando jerárquicamente {len(masks)} máscaras...\")\n",
    "\n",
    "        for i, mask_data_a_original in enumerate(masks): \n",
    "            mask_data_a_processed = mask_data_a_original.copy() \n",
    "            mask_a_current_processing = np.copy(mask_data_a_original[\"segmentation\"]) \n",
    "\n",
    "            is_completely_internal_to_another = False \n",
    "            potential_holes_for_mask_a = [] \n",
    "\n",
    "            for j, mask_data_b_comparison in enumerate(masks): \n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                mask_b = original_mask_segments_for_comparison[j] \n",
    "\n",
    "                if np.sum(mask_a_current_processing) > 0 and np.all(np.logical_and(mask_a_current_processing, mask_b) == mask_a_current_processing):\n",
    "                    is_completely_internal_to_another = True\n",
    "                    break \n",
    "\n",
    "                intersection_ab = np.logical_and(mask_b, mask_a_current_processing)\n",
    "                area_b = np.sum(mask_b)\n",
    "                area_intersection_ab = np.sum(intersection_ab)\n",
    "\n",
    "                if area_b > 0 and (np.all(intersection_ab == mask_b) or \\\n",
    "                                (area_intersection_ab / area_b > overlap_threshold and area_intersection_ab > 0)):\n",
    "                    if np.sum(mask_b) < np.sum(mask_a_current_processing) * 0.9: \n",
    "                        potential_holes_for_mask_a.append(mask_b)\n",
    "\n",
    "            if is_completely_internal_to_another:\n",
    "                display_title = f'Máscara {i + 1} (Interna - Sin cambios significativos)'\n",
    "            else:\n",
    "                hollowed = False\n",
    "                for hole_mask in potential_holes_for_mask_a:\n",
    "                    mask_a_current_processing = np.logical_and(mask_a_current_processing, np.logical_not(hole_mask))\n",
    "                    hollowed = True\n",
    "                \n",
    "                mask_data_a_processed[\"segmentation\"] = mask_a_current_processing \n",
    "                if hollowed:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Hueca)'\n",
    "                else:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Sin huecos significativos)'\n",
    "\n",
    "            final_processed_masks_data.append(mask_data_a_processed) \n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(image) \n",
    "            show_mask(mask_data_a_processed[\"segmentation\"], plt.gca(), random_color=True) \n",
    "            plt.axis('off')\n",
    "            plt.title(display_title)\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{filename_prefix}_processed_mask_{i + 1}.png\")\n",
    "            plt.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Máscara procesada {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "        print(\"Procesamiento jerárquico de máscaras completado.\")\n",
    "        return final_processed_masks_data \n",
    "\n",
    "    def apply_morphological_closing(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            return masks_list\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando cierre morfológico con kernel {kernel_size}x{kernel_size}...\")\n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_smoothed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_CLOSE, kernel)\n",
    "            mask_data['segmentation'] = (mask_smoothed_np > 0).astype(bool)\n",
    "        print(\"Suavizado de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    def apply_morphological_opening(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            print(\"La lista de máscaras está vacía, no se aplica la apertura morfológica.\")\n",
    "            return masks_list\n",
    "        \n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando apertura morfológica con kernel {kernel_size}x{kernel_size}...\")\n",
    "        \n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            if mask_boolean.dtype != bool:\n",
    "                mask_boolean = mask_boolean.astype(bool)\n",
    "\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_processed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_OPEN, kernel)\n",
    "            mask_data['segmentation'] = (mask_processed_np > 0).astype(bool)\n",
    "            \n",
    "        print(\"Suavizado (apertura) de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    try:\n",
    "        image_for_sam_np = np.array(Image.open(query_image_path).convert(\"RGB\"))\n",
    "        print(f\"Dimensiones imagen SAM: {image_for_sam_np.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando imagen para SAM: {e}. Saltando SAM.\")\n",
    "        sam2_model = None\n",
    "        \n",
    "    PROCESSED_MASKS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"processed_masks\")\n",
    "\n",
    "    if sam2_model is not None:\n",
    "        points_grid_density = 16\n",
    "        min_mask_area_pixels = 3000\n",
    "\n",
    "        mask_generator_query = SAM2AutomaticMaskGenerator(\n",
    "            model=sam2_model,\n",
    "            points_per_side=points_grid_density,\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.85,\n",
    "            stability_score_thresh=0.8,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=min_mask_area_pixels,\n",
    "        )\n",
    "        \n",
    "        masks_data_query_image = mask_generator_query.generate(image_for_sam_np)\n",
    "\n",
    "\n",
    "        min_area_threshold = 75000#100000 # Define tu umbral de área mínima\n",
    "        max_area_threshold = 120000\n",
    "        filtered_masks_data = []\n",
    "        for mask_data in masks_data_query_image:\n",
    "            mask_area = mask_data['area']  # El diccionario 'mask_data' ya contiene el área\n",
    "            if min_area_threshold <= mask_area <= max_area_threshold:\n",
    "                filtered_masks_data.append(mask_data)\n",
    "\n",
    "        masks_data_query_image = filtered_masks_data # Actualiza tu lista de máscaras\n",
    "        print(f\"Número de máscaras generadas DESPUÉS de filtrar (área >= {min_area_threshold}): {len(masks_data_query_image)}\")\n",
    "        for i, mask_data in enumerate(masks_data_query_image):\n",
    "            area = mask_data['area']\n",
    "            iou = mask_data.get('predicted_iou', 'N/A')  # Usar 'N/A' si no está disponible\n",
    "            stability_score = mask_data.get('stability_score', 'N/A')  # Usar 'N/A' si no está disponible\n",
    "            print(f\"Mascara {i + 1}: Area={area}, IOU={iou}, Stability Score={stability_score}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        def plot_individual_masks(masks_data, output_dir, filename_prefix=\"query_mask\", image_path=None):\n",
    "\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            if image_path:\n",
    "                try:\n",
    "                    image_original = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_np = np.array(image_original)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"No image path provided for overlay. Skipping.\")\n",
    "                return\n",
    "            \n",
    "            for i, mask_data in enumerate(masks_data):\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                mask_np = mask_data[\"segmentation\"]\n",
    "                plt.imshow(image_np)\n",
    "                show_mask(mask_np, plt.gca(), random_color=True)\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"Máscara {i + 1} - Área: {mask_data['area']}, IoU: {mask_data.get('predicted_iou', 'N/A')}\")\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"{filename_prefix}_{i + 1}.png\")\n",
    "                plt.savefig(output_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(f\"Máscara {i + 1} sobrepuesta guardada en: {output_path}\")\n",
    "\n",
    "        # Call the function to visualize and save the masks\n",
    "        plot_individual_masks(masks_data_query_image, PROCESSED_MASKS_DIR, filename_prefix=\"query_mask\", image_path=query_image_path)\n",
    "        \n",
    "        print(f\"Número de máscaras generadas DESPUÉS de filtrar (área >= {min_area_threshold}): {len(masks_data_query_image)}\")   \n",
    "        \n",
    "        mask_generator_similar = SAM2AutomaticMaskGenerator( \n",
    "            model=sam2_model,\n",
    "            points_per_side=16,#25\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.85,\n",
    "            stability_score_thresh=0.8,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=3000,\n",
    "        )\n",
    "\n",
    "        print(\"\\nGenerando máscaras SAM para imágenes similares...\")\n",
    "        # --- Start of your main processing loop ---\n",
    "        start_time_sam = time.time()\n",
    "        similar_masks_raw_list=[]\n",
    "        \n",
    "        for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "                    \n",
    "            try:\n",
    "                image_np_similar_for_sam = np.array(Image.open(similar_image_path).convert('RGB'))\n",
    "                print(f\"--- Procesando vecino {j+1}: {os.path.basename(similar_image_path)} ---\")\n",
    "                \n",
    "                # 1. Generate ALL masks for the current similar image\n",
    "                all_generated_masks = mask_generator_similar.generate(image_np_similar_for_sam)\n",
    "                \n",
    "                # 2. Initialize a NEW list to store only the FILTERED masks\n",
    "                filtered_similar_masks_data = []\n",
    "\n",
    "                # 3. Iterate over the ALL_GENERATED_MASKS and add to the NEW list if they pass the filter\n",
    "                for mask_data in all_generated_masks: # <--- CRUCIAL CHANGE HERE!\n",
    "                    mask_area = mask_data['area']\n",
    "                    if min_area_threshold <= mask_area <= max_area_threshold:\n",
    "                        filtered_similar_masks_data.append(mask_data) # <--- Appending to a DIFFERENT list!\n",
    "\n",
    "                print(f\"Número de máscaras generadas y filtradas (área >= {min_area_threshold}): {len(filtered_similar_masks_data)}\")\n",
    "                for i, mask_data in enumerate(filtered_similar_masks_data): # <--- Iterate over the filtered list\n",
    "                    area = mask_data['area']\n",
    "                    iou = mask_data.get('predicted_iou', 'N/A')\n",
    "                    stability_score = mask_data.get('stability_score', 'N/A')\n",
    "                    print(f\"Mascara {i + 1}: Area={area}, IOU={iou}, Stability Score={stability_score}\")\n",
    "                    \n",
    "                similar_masks_raw_list.append(filtered_similar_masks_data) # <--- Append the filtered list\n",
    "                \n",
    "                # Visualize and save individual masks overlaid on the similar images\n",
    "                def plot_masks_overlay_on_images(masks_data, image_path, output_dir, filename_prefix=\"similar_mask_overlay\"):\n",
    "                    \"\"\"\n",
    "                    Function to overlay masks on the original similar images and save them as images.\n",
    "\n",
    "                    Args:\n",
    "                        masks_data (list): List of mask data dictionaries containing 'segmentation', 'area', and 'predicted_iou'.\n",
    "                        image_path (str): Path to the original similar image.\n",
    "                        output_dir (str): Directory to save the overlay images.\n",
    "                        filename_prefix (str): Prefix for the saved overlay filenames.\n",
    "                    \"\"\"\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    try:\n",
    "                        image_original = Image.open(image_path).convert(\"RGB\")\n",
    "                        image_np = np.array(image_original)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {image_path}: {e}\")\n",
    "                        return\n",
    "\n",
    "                    for i, mask_data in enumerate(masks_data):\n",
    "                        plt.figure(figsize=(8, 8))\n",
    "                        mask_np = mask_data[\"segmentation\"]\n",
    "                        plt.imshow(image_np)\n",
    "                        show_mask(mask_np, plt.gca(), random_color=True)\n",
    "                        plt.axis('off')\n",
    "                        \n",
    "                        # Handling N/A for formatting\n",
    "                        iou_val = mask_data.get('predicted_iou', 'N/A')\n",
    "                        stability_val = mask_data.get('stability_score', 'N/A')\n",
    "                        iou_str = f\"{iou_val:.4f}\" if isinstance(iou_val, (int, float)) else str(iou_val)\n",
    "\n",
    "                        plt.title(f\"Máscara {i + 1} - Área: {mask_data['area']}, IoU: {iou_str}, Stability: {stability_val}\")\n",
    "\n",
    "                        # Use a more unique filename to avoid overwrites across different similar images\n",
    "                        # Assumes 'j' (index of the similar image) is accessible from the outer scope\n",
    "                        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                        output_path = os.path.join(output_dir, f\"{filename_prefix}_{base_filename}_mask_{i + 1}.png\")\n",
    "                        \n",
    "                        plt.savefig(output_path, bbox_inches='tight')\n",
    "                        plt.close()\n",
    "                        print(f\"Máscara {i + 1} sobrepuesta guardada en: {output_path}\")\n",
    "\n",
    "                # Call the function to overlay and save the masks for the current similar image\n",
    "                # Pass the filtered list and ensure a unique filename prefix\n",
    "                plot_masks_overlay_on_images(filtered_similar_masks_data, similar_image_path, PROCESSED_MASKS_DIR, filename_prefix=\"similar_mask_overlay\")\n",
    "                \n",
    "                print(f\"Máscaras procesadas para vecino {j+1}: {len(filtered_similar_masks_data)}.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando imagen similar {os.path.basename(similar_image_path)} para SAM: {e}\")\n",
    "                # It's usually a good idea to 'continue' here so the loop doesn't stop for one error\n",
    "                continue \n",
    "\n",
    "        end_time_sam = time.time()\n",
    "        print(f\"Tiempo total de ejecución de SAM: {end_time_sam - start_time_sam:.4f} segundos.\")\n",
    "\n",
    "        print(\"\\nAnálisis de SAM para una sola imagen completado.\")\n",
    "    \n",
    "    # Llamar a la función para procesar las máscaras de la query\n",
    "    # processed_masks_query = process_masks_with_hierarchy(image_for_sam_np, masks_data_query_image, PROCESSED_MASKS_DIR, \"query\")\n",
    "    # masks_data_query_image = processed_masks_query\n",
    "    # print(\"Shape de masks_data_query_image:\", len(masks_data_query_image))\n",
    "\n",
    "    #####################\n",
    "\n",
    "    # --- Implementación del punto 3.4.3. Object Feature Map ---\n",
    "    def process_masks_to_object_feature_maps(raw_masks, hr_feature_map, target_h, target_w, sam_processed_image_shape):\n",
    "        if not raw_masks:\n",
    "            print(\"Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\")\n",
    "            C_dim = hr_feature_map.shape[0] if hr_feature_map.ndim >= 3 else 0\n",
    "            return torch.empty(0, C_dim, target_h, target_w, device=hr_feature_map.device), \\\n",
    "                torch.empty(0, 1, target_h, target_w, device=hr_feature_map.device)\n",
    "\n",
    "        object_feature_maps_list = []\n",
    "        scaled_mask_append = []\n",
    "        C_dim = hr_feature_map.shape[0] \n",
    "\n",
    "        for mask_info in raw_masks:\n",
    "            mask_np = mask_info['segmentation'].astype(np.float32)\n",
    "            mask_tensor_original_res = torch.from_numpy(mask_np).unsqueeze(0).unsqueeze(0) #(1,1,H,W)\n",
    "            mask_tensor_original_res = mask_tensor_original_res.to(hr_feature_map.device)\n",
    "\n",
    "            scaled_mask = F.interpolate(mask_tensor_original_res,\n",
    "                                        size=(target_h, target_w),\n",
    "                                        mode='bilinear',\n",
    "                                        align_corners=False)\n",
    "            scaled_mask = (scaled_mask > 0.5).float()\n",
    "            scaled_mask_append.append(scaled_mask)\n",
    "            \n",
    "            if hr_feature_map.ndim == 3:\n",
    "                hr_feature_map_with_batch = hr_feature_map.unsqueeze(0) #(1,C,W,H)\n",
    "            else: \n",
    "                hr_feature_map_with_batch = hr_feature_map\n",
    "\n",
    "            object_feature_map_i = scaled_mask * hr_feature_map_with_batch\n",
    "            object_feature_maps_list.append(object_feature_map_i)\n",
    "\n",
    "        final_object_feature_maps = torch.cat(object_feature_maps_list, dim=0) \n",
    "        final_scaled_masks = torch.cat(scaled_mask_append, dim=0)\n",
    "        \n",
    "        return final_object_feature_maps, final_scaled_masks\n",
    "\n",
    "    # --- Visualización de Mapas de Características de Objeto ---\n",
    "    def visualize_object_feature_map(original_image_path, sam_mask_info, hr_feature_map_tensor,\n",
    "                                    object_feature_map_tensor, target_h, target_w,\n",
    "                                    plot_save_dir, plot_filename_prefix, mask_idx,\n",
    "                                    sam_processed_image_shape):\n",
    "        try:\n",
    "            original_img = Image.open(original_image_path).convert(\"RGB\")\n",
    "            sam_mask_np = sam_mask_info['segmentation']\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "            axes[0].imshow(original_img)\n",
    "            axes[0].set_title(f'Imagen Original\\n{os.path.basename(original_image_path)}')\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            mask_display = sam_mask_np \n",
    "            axes[1].imshow(original_img) \n",
    "            show_mask(mask_display, axes[1], random_color=False, borders=True) \n",
    "            axes[1].set_title(f'Máscara SAM {mask_idx}')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            if object_feature_map_tensor.numel() == 0:\n",
    "                axes[2].text(0.5, 0.5, \"No hay características de objeto\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                axes[2].set_title('Mapa de Características de Objeto (Vacío)')\n",
    "                axes[2].axis('off')\n",
    "            else:\n",
    "                ofm_cpu = object_feature_map_tensor.squeeze().cpu().numpy() \n",
    "                if ofm_cpu.ndim == 3: \n",
    "                    C, H, W = ofm_cpu.shape\n",
    "                    ofm_reshaped = ofm_cpu.transpose(1, 2, 0).reshape(-1, C) \n",
    "\n",
    "                    if C > 3: \n",
    "                        pca = PCA(n_components=3)\n",
    "                        ofm_pca = pca.fit_transform(ofm_reshaped)\n",
    "                        ofm_pca_normalized = (ofm_pca - ofm_pca.min()) / (ofm_pca.max() - ofm_pca.min() + 1e-8)\n",
    "                        ofm_display = ofm_pca_normalized.reshape(H, W, 3)\n",
    "                        axes[2].imshow(ofm_display)\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto (PCA)\\nMáscara {mask_idx}')\n",
    "                    else: \n",
    "                        if C == 1:\n",
    "                            ofm_display = ofm_cpu.squeeze()\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        elif C == 3:\n",
    "                            ofm_display = ofm_cpu.transpose(1, 2, 0) \n",
    "                            ofm_display_norm = (ofm_display - ofm_display.min()) / (ofm_display.max() - ofm_display.min() + 1e-8)\n",
    "                            axes[2].imshow(ofm_display_norm)\n",
    "                        else: \n",
    "                            ofm_display = ofm_cpu[0]\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto\\nMáscara {mask_idx}')\n",
    "                else: \n",
    "                    axes[2].text(0.5, 0.5, \"Formato de características de objeto inesperado\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                    axes[2].set_title('Mapa de Características de Objeto (Error)')\n",
    "\n",
    "                axes[2].axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{plot_filename_prefix}_mask_{mask_idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al visualizar el mapa de características de objeto para máscara {mask_idx} de {os.path.basename(original_image_path)}: {e}\")\n",
    "\n",
    "    # --- Aplicar el proceso a la imagen de consulta y a las imágenes de referencia ---\n",
    "\n",
    "    print(\"\\n--- Generando Mapas de Características de Objeto ---\")\n",
    "\n",
    "    TARGET_MASK_H = 8 * H_prime \n",
    "    TARGET_MASK_W = 8 * W_prime \n",
    "    print(f\"TARGET_MASK_H: {TARGET_MASK_H}\")\n",
    "    print(f\"TARGET_MASK_W: {TARGET_MASK_W}\")\n",
    "\n",
    "    fobj_q, scaled_masks_query = process_masks_to_object_feature_maps(\n",
    "        masks_data_query_image,\n",
    "        query_hr_feats.squeeze(0), \n",
    "        TARGET_MASK_H,\n",
    "        TARGET_MASK_W,\n",
    "        image_for_sam_np.shape \n",
    "    )\n",
    "\n",
    "    fobj_q = fobj_q.to(device)\n",
    "\n",
    "    print(f\"Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): {fobj_q.shape}\") \n",
    "\n",
    "    all_fobj_r_list = [] \n",
    "    for i, similar_hr_feats in enumerate(similar_hr_feats_list):\n",
    "        current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "        img_similar_pil = Image.open(rutas_imagenes_similares[i]).convert('RGB') \n",
    "        image_np_similar_for_sam_shape = np.array(img_similar_pil).shape\n",
    "\n",
    "        fobj_r_current, scaled_masks_similar = process_masks_to_object_feature_maps(\n",
    "            current_similar_masks_raw,\n",
    "            similar_hr_feats.squeeze(0), \n",
    "            TARGET_MASK_H,\n",
    "            TARGET_MASK_W,\n",
    "            image_np_similar_for_sam_shape \n",
    "        )\n",
    "        fobj_r_current = fobj_r_current.to(device)\n",
    "        \n",
    "        all_fobj_r_list.append(fobj_r_current)\n",
    "        print(f\"Dimensiones de fobj_r para vecino {i+1}: {fobj_r_current.shape}\") \n",
    "        print(\"\\nTipos de los elementos en all_fobj_r_list:\")\n",
    "        for idx, fobj_r in enumerate(all_fobj_r_list):\n",
    "            print(f\"Vecino {idx + 1}: Tipo de fobj_r:\", type(fobj_r))\n",
    "    print(\"\\nProceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\")\n",
    "\n",
    "\n",
    "    # -----------3.5.2 Object matching module-----------------\n",
    "    ## Matching\n",
    "    # --- Definición de la función show_anomalies_on_image ---\n",
    "    def show_anomalies_on_image(image_np, masks, anomalous_info, alpha=0.5, save_path=None):\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image_np)\n",
    "\n",
    "        for obj_id, similarity in anomalous_info: # Iterate through (id, similarity) tuples\n",
    "            # Extraer la máscara binaria real\n",
    "            mask = masks[obj_id]['segmentation']\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "\n",
    "            # Crear máscara en rojo\n",
    "            colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "            colored_mask[mask > 0] = [255, 0, 0]\n",
    "            plt.imshow(colored_mask, alpha=alpha)\n",
    "\n",
    "            # Calcular centroide para colocar el texto\n",
    "            ys, xs = np.where(mask > 0)\n",
    "            if len(xs) > 0 and len(ys) > 0:\n",
    "                cx = int(xs.mean())\n",
    "                cy = int(ys.mean())\n",
    "                \n",
    "                # Create text with index and percentage\n",
    "                text_label = f\"{obj_id} ({similarity*100:.2f}%)\"\n",
    "                plt.text(cx, cy, text_label, color='white', fontsize=10, fontweight='bold', ha='center', va='center',\n",
    "                        bbox=dict(facecolor='red', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "        plt.title(\"Objetos Anómalos en Rojo con Índice y Similitud\") # Updated title for clarity\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de anomalías guardado en: {save_path}\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    # --- Fin de la definición de la función show_anomalies_on_image ---\n",
    "    # --- Nuevas funciones de ploteo para la matriz P y P_augmented_full ---\n",
    "    def plot_assignment_matrix(P_matrix, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación P\"):\n",
    "\n",
    "        if isinstance(P_matrix, torch.Tensor):\n",
    "            #P_matrix = P_matrix.cpu().numpy()\n",
    "            P_matrix = P_matrix.detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(P_matrix.shape[1] * 0.8 + 2, P_matrix.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_matrix, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(reference_labels)), reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(query_labels)), query_labels)\n",
    "        plt.xlabel('Objetos de Referencia')\n",
    "        plt.ylabel('Objetos de Consulta')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_augmented_assignment_matrix(P_augmented_full, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación Aumentada (con Trash Bin)\"):\n",
    "\n",
    "        if isinstance(P_augmented_full, torch.Tensor):\n",
    "            #P_augmented_full = P_augmented_full.cpu().numpy()\n",
    "            P_augmented_full = P_augmented_full.detach().cpu().numpy()\n",
    "\n",
    "        # Añadir etiquetas para los trash bins\n",
    "        full_query_labels = [f\"Q_{i}\" for i in query_labels] + [\"Trash Bin (Q)\"]\n",
    "        full_reference_labels = [f\"R_{i}\" for i in reference_labels] + [\"Trash Bin (R)\"]\n",
    "\n",
    "        plt.figure(figsize=(P_augmented_full.shape[1] * 0.8 + 2, P_augmented_full.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_augmented_full, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(full_reference_labels)), full_reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(full_query_labels)), full_query_labels)\n",
    "        plt.xlabel('Objetos de Referencia y Trash Bin')\n",
    "        plt.ylabel('Objetos de Consulta y Trash Bin')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación aumentada guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# --- Fin de las nuevas funciones de ploteo ---\n",
    "\n",
    "    ## Matching-continue---\n",
    "    ## Matching\n",
    "    start_time_sam_matching = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    def apply_global_max_pool(feat_map):\n",
    "        return F.adaptive_max_pool2d(feat_map, output_size=1).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    class SimpleObjectMatchingModule(nn.Module):\n",
    "        def __init__(self, sinkhorn_iterations=100, sinkhorn_epsilon=0.1, bin_score_value=0.5):\n",
    "            super(SimpleObjectMatchingModule, self).__init__()\n",
    "            self.sinkhorn_iterations = sinkhorn_iterations\n",
    "            self.sinkhorn_epsilon = sinkhorn_epsilon\n",
    "            self.z = nn.Parameter(torch.tensor(bin_score_value, dtype=torch.float32))\n",
    "\n",
    "        def forward(self, d_M_q, d_N_r):\n",
    "            M = d_M_q.shape[0]\n",
    "            N = d_N_r.shape[0]\n",
    "\n",
    "            if M == 0 or N == 0:\n",
    "                return torch.empty(M, N, device=d_M_q.device), \\\n",
    "                    torch.empty(M+1, N+1, device=d_M_q.device)\n",
    "\n",
    "            score_matrix = torch.mm(d_M_q, d_N_r.T)\n",
    "            #print(\"score_matrix (antes de Sinkhorn):\\n\", score_matrix)\n",
    "\n",
    "            S_augmented = torch.zeros((M + 1, N + 1), device=d_M_q.device, dtype=d_M_q.dtype)\n",
    "            S_augmented[:M, :N] = score_matrix\n",
    "            S_augmented[:M, N] = self.z\n",
    "            S_augmented[M, :N] = self.z\n",
    "            S_augmented[M, N] = self.z\n",
    "            print(\"S_augmented antes de Sinkhorn:\\n\", S_augmented)\n",
    "\n",
    "            K = torch.exp(S_augmented / self.sinkhorn_epsilon)\n",
    "            print(\"K (antes de Sinkhorn):\\n\", K)\n",
    "            \n",
    "\n",
    "            for i in range(self.sinkhorn_iterations):\n",
    "                K = K / K.sum(dim=1, keepdim=True)\n",
    "                K = K / K.sum(dim=0, keepdim=True)\n",
    "                #print(f\"Iteración {i+1}: K.shape = {K}\")\n",
    "\n",
    "            P_augmented_full = K\n",
    "            P = P_augmented_full[:M, :N]\n",
    "\n",
    "            return P, P_augmented_full\n",
    "\n",
    "    if fobj_q.shape[0] == 0:\n",
    "        print(\"Advertencia: fobj_q tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "        continue\n",
    "\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        if fobj_r_current.shape[0] == 0:\n",
    "            print(\"Advertencia: fobj_r_current tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "            continue\n",
    "    \n",
    "    fobj_q_pooled = apply_global_max_pool(fobj_q)\n",
    "    print(\"Shape de fobj_q_pooled:\", fobj_q_pooled.shape)\n",
    "    print(\"Máximo de fobj_q_pooled:\", torch.max(fobj_q_pooled).item())\n",
    "    print(\"Mínimo de fobj_q_pooled:\", torch.min(fobj_q_pooled).item())\n",
    "\n",
    "    all_fobj_r_pooled_list = []\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        pooled_r = apply_global_max_pool(fobj_r_current)\n",
    "        all_fobj_r_pooled_list.append(pooled_r)\n",
    "        \n",
    "    d_M_q = F.normalize(fobj_q_pooled, p=2, dim=1) #shape (M, C)\n",
    "    d_N_r_list = [F.normalize(fobj_r_pooled, p=2, dim=1) \n",
    "                                for fobj_r_pooled in all_fobj_r_pooled_list]\n",
    "    print(\"Máximo de d_M_q:\", torch.max(d_M_q).item())\n",
    "    print(\"Mínimo de d_M_q:\", torch.min(d_M_q).item())\n",
    "\n",
    "    object_matching_module = SimpleObjectMatchingModule(\n",
    "        sinkhorn_iterations=100,\n",
    "        sinkhorn_epsilon=0.1,\n",
    "        bin_score_value=0.9 #2.36\n",
    "    ).to(device)\n",
    "\n",
    "    P_matrices = []\n",
    "    P_augmented_full_matrices = []\n",
    "\n",
    "    for i, d_N_r_current_image in enumerate(d_N_r_list):\n",
    "        d_M_q_cuda = d_M_q.to(device)\n",
    "        d_N_r_current_image_cuda = d_N_r_current_image.to(device)\n",
    "\n",
    "        P_current, P_augmented_current = object_matching_module(d_M_q_cuda, d_N_r_current_image_cuda)\n",
    "        P_matrices.append(P_current)\n",
    "        P_augmented_full_matrices.append(P_augmented_current)\n",
    "\n",
    "\n",
    "    print(\"\\n--- Matrices P y P_augmented_full generadas ---\")\n",
    "    # --- NUEVOS DICCIONARIOS CONSOLIDADOS ---\n",
    "    # Almacenarán para cada query_idx, las referencias que le corresponden de TODOS los vecinos.\n",
    "    M = d_M_q.shape[0]\n",
    "    all_matched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)} # M es el número de objetos de consulta (Iq)\n",
    "    all_closest_unmatched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)}\n",
    "    # Imprimir shapes de los diccionarios consolidados\n",
    "    #//////\n",
    "    print(\"\\n--- Resultados Consolidados ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {closest_unmatches}\")\n",
    "    #/////////////////\n",
    "    # Procesar matrices P y P_augmented_full para obtener índices\n",
    "    for i, (P, P_augmented_full) in enumerate(zip(P_matrices, P_augmented_full_matrices)):\n",
    "        current_neighbor_key = f\"Vecino_{i+1}\"\n",
    "        N_current = P.shape[1] \n",
    "\n",
    "        print(f\"\\n--- Vecino {current_neighbor_key} ---\")\n",
    "        print(f\"Matriz P (MxN) para el vecino {current_neighbor_key}:\")\n",
    "        print(P)\n",
    "        print(f\"Matriz P_augmented_full (M+1 x N+1) para el vecino {current_neighbor_key}:\")\n",
    "        print(P_augmented_full)\n",
    "\n",
    "        # Imprimir sumas de filas y columnas de P_augmented_full\n",
    "        augmented_with_totals = torch.cat([\n",
    "            torch.cat([P_augmented_full, P_augmented_full.sum(dim=0, keepdim=True)], dim=0),\n",
    "            torch.cat([P_augmented_full.sum(dim=1, keepdim=True), P_augmented_full.sum().unsqueeze(0).unsqueeze(0)], dim=0)\n",
    "        ], dim=1)\n",
    "        print(f\"Matriz P_augmented_full con totales (M+2 x N+2):\\n{augmented_with_totals}\")\n",
    "\n",
    "        print(f\"\\n--- Decisiones de Emparejamiento para el Vecino {current_neighbor_key} ---\")\n",
    "        for obj_idx in range(P.shape[0]):\n",
    "            \n",
    "            # Obtener la probabilidad más alta dentro de P y su índice\n",
    "            if N_current > 0:\n",
    "                max_prob_P = P[obj_idx].max().item()\n",
    "                max_idx_P = P[obj_idx].argmax().item()\n",
    "            else:\n",
    "                max_prob_P = -float('inf')\n",
    "                max_idx_P = -1\n",
    "\n",
    "            trash_bin_prob = P_augmented_full[obj_idx, -1].item() \n",
    "\n",
    "            print(f\"   Objeto de Consulta {obj_idx}:\")\n",
    "            print(f\"     Probabilidad máxima en P: {max_prob_P:.4f} en el índice {max_idx_P}\")\n",
    "            print(f\"     Probabilidad en el 'Trash Bin': {trash_bin_prob:.4f}\")\n",
    "\n",
    "\n",
    "        # Decisión y almacenamiento en los diccionarios consolidados\n",
    "            if trash_bin_prob > max_prob_P:\n",
    "                # Desemparejado: ahora añadimos el 'primer máximo' a la lista de ese objeto de consulta\n",
    "                if max_idx_P != -1: # Solo añadir si hay un 'primer máximo' válido\n",
    "                    all_closest_unmatched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto {max_idx_P}\")\n",
    "            else:\n",
    "                # Emparejado: añadir el emparejamiento real a la lista de ese objeto de consulta\n",
    "                all_matched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: EMPAREJADO con objeto de imagen {max_idx_P}\")\n",
    "\n",
    "\n",
    "    # --- Resultados Finales Consolidados ---\n",
    "    print(\"\\n--- Resultados Finales Consolidados (Índices) ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {closest_unmatches}\")\n",
    "\n",
    "\n",
    "    # --- AHORA SE NECESITAN ESTOS DICTIONARIOS PARA TU IMPLEMENTACIÓN DE MAHALANOBIS ---\n",
    "    # amm\n",
    "    print(\"--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\")\n",
    "    # --- Utility Functions ---\n",
    "\n",
    "    def percentile_normalize(data_tensor, percentile_cap=99.0):\n",
    "        # This function is for visualization, so if it receives NaN/Inf, it should handle them\n",
    "        # gracefully rather than discarding, to still show what's valid.\n",
    "        if data_tensor.numel() == 0 or data_tensor.max() == data_tensor.min():\n",
    "            return torch.zeros_like(data_tensor)\n",
    "\n",
    "        data_np = data_tensor.cpu().numpy()\n",
    "        \n",
    "        # Clean NaN/Inf for percentile calculation to avoid errors in np.percentile\n",
    "        if np.isnan(data_np).any() or np.isinf(data_np).any():\n",
    "            data_np_cleaned = np.nan_to_num(data_np, nan=0.0, posinf=data_np[np.isfinite(data_np)].max() if np.isfinite(data_np).any() else 0.0, neginf=data_np[np.isfinite(data_np)].min() if np.isfinite(data_np).any() else 0.0)\n",
    "            # Using max/min of finite values for inf to keep scale, or 0 if no finite values.\n",
    "            print(f\"WARNING: NaN/Inf detected in data for percentile normalization. Cleaning for visualization.\")\n",
    "            data_np = data_np_cleaned\n",
    "\n",
    "        p_min = np.percentile(data_np, 1.0)\n",
    "        p_max = np.percentile(data_np, percentile_cap)\n",
    "\n",
    "        if p_max <= p_min + 1e-8:\n",
    "            return torch.zeros_like(data_tensor)\n",
    "\n",
    "        normalized_tensor = (data_tensor - p_min) / (p_max - p_min)\n",
    "        normalized_tensor = torch.clamp(normalized_tensor, 0.0, 1.0)\n",
    "        return normalized_tensor\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_mahalanobis_map_single(query_fmap, ref_fmaps, regularization=1e-5, pixel_batch_size=4096):\n",
    "        device = query_fmap.device\n",
    "        k = len(ref_fmaps)\n",
    "        C, H, W = query_fmap.shape\n",
    "\n",
    "        if k < 2:\n",
    "            # Returning a map of zeros, but you could also return None to indicate invalid\n",
    "            # For now, stick to zeros as it's cleaner for subsequent processing, and let\n",
    "            # the calling function decide to discard based on this or actual NaN/Inf later.\n",
    "            return torch.zeros(H, W, device=device, dtype=torch.float32)\n",
    "\n",
    "        query_fmap_float32 = query_fmap.to(torch.float32)\n",
    "        ref_fmaps_float32 = [fmap.to(torch.float32) for fmap in ref_fmaps]\n",
    "\n",
    "        ref_stack = torch.stack(ref_fmaps_float32, dim=0).permute(0, 2, 3, 1)\n",
    "        query_fmap_permuted = query_fmap_float32.permute(1, 2, 0)\n",
    "\n",
    "        N_pixels = H * W\n",
    "        ref_vectors_flat = ref_stack.reshape(k, N_pixels, C)\n",
    "        query_vectors_flat = query_fmap_permuted.reshape(N_pixels, C)\n",
    "\n",
    "        mu = ref_vectors_flat.mean(dim=0)\n",
    "        \n",
    "        maha_map_flat = torch.zeros(N_pixels, device=device, dtype=torch.float32)\n",
    "\n",
    "        for i in range(0, N_pixels, pixel_batch_size):\n",
    "            end_idx = min(i + pixel_batch_size, N_pixels)\n",
    "            current_pixel_batch_size = end_idx - i\n",
    "\n",
    "            mu_batch = mu[i:end_idx]\n",
    "            query_vectors_flat_batch = query_vectors_flat[i:end_idx]\n",
    "            \n",
    "            delta_batch = ref_vectors_flat[:, i:end_idx, :] - mu_batch.unsqueeze(0)\n",
    "            delta_reshaped_batch = delta_batch.permute(1, 0, 2)\n",
    "            cov_batch = (delta_reshaped_batch.transpose(-1, -2) @ delta_reshaped_batch) / (k - 1)\n",
    "            \n",
    "            cov_batch += regularization * torch.eye(C, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            try:\n",
    "                cov_inv_batch = torch.linalg.inv(cov_batch)\n",
    "            except RuntimeError:\n",
    "                # If inverse fails, these pixels are problematic, return a \"problem\" value\n",
    "                maha_map_flat[i:end_idx] = float('nan') # Mark as NaN\n",
    "                continue\n",
    "\n",
    "            diff_batch = query_vectors_flat_batch - mu_batch\n",
    "            maha_val_squared_batch = (diff_batch.unsqueeze(1) @ cov_inv_batch @ diff_batch.unsqueeze(2)).squeeze()\n",
    "            \n",
    "            maha_map_flat[i:end_idx] = torch.sqrt(torch.relu(maha_val_squared_batch))\n",
    "            \n",
    "            del mu_batch, query_vectors_flat_batch, delta_batch, delta_reshaped_batch, cov_batch, cov_inv_batch, diff_batch, maha_val_squared_batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        maha_map = maha_map_flat.reshape(H, W)\n",
    "        \n",
    "        # Crucial change: Don't clean here. Let the caller decide to discard.\n",
    "        # We only check if it contains NaN/Inf.\n",
    "        if torch.isnan(maha_map).any() or torch.isinf(maha_map).any():\n",
    "            print(f\"DEBUG: NaN/Inf detected in raw Mahalanobis map (shape {maha_map.shape}). This map will be marked for potential discard by caller.\")\n",
    "            # Return the map as is, with NaNs/Infs, so the caller can check it.\n",
    "        \n",
    "        return maha_map\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def compute_matching_score_map(\n",
    "        fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        matching_maha_maps = []\n",
    "        all_raw_maha_values = [] \n",
    "        \n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx]\n",
    "            device = query_fmap.device\n",
    "\n",
    "            matched_ref_fmaps_list = []\n",
    "            for neighbor_idx, ref_idx in all_matched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                matched_ref_fmaps_list.append(ref_fmap)\n",
    "                \n",
    "            if len(matched_ref_fmaps_list) >= 2:\n",
    "                maha_map_raw = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=matched_ref_fmaps_list,\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            else:\n",
    "                map_H, map_W = query_fmap.shape[1], query_fmap.shape[2]\n",
    "                maha_map_raw = torch.zeros((map_H, map_W), device=device) # Assign zero if less than two matches\n",
    "            \n",
    "            # Check here: If the map is invalid, do NOT add it to the list\n",
    "            if torch.isnan(maha_map_raw).any() or torch.isinf(maha_map_raw).any():\n",
    "                print(f\"WARNING: Discarding Matching Score Map for Query Object {query_idx} due to NaN/Inf values.\")\n",
    "                # Do not append this map\n",
    "            else:\n",
    "                all_raw_maha_values.append(maha_map_raw.flatten().cpu()) \n",
    "                matching_maha_maps.append(maha_map_raw.cpu())\n",
    "\n",
    "                if plot_save_dir:\n",
    "                    plt.figure(figsize=(6, 5))\n",
    "                    maha_map_for_plot = matching_maha_maps[-1] # This map is guaranteed to be clean\n",
    "                    plot_normalized_maha = percentile_normalize(maha_map_for_plot, percentile_cap=99.0)\n",
    "                    plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                    plt.title(f\"Matching Score Map (Percentile Normalized) - Obj {query_idx}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                    plt.tight_layout()\n",
    "                    save_path = os.path.join(plot_save_dir, f\"matching_score_percentile_norm_obj_{query_idx}.png\")\n",
    "                    plt.savefig(save_path)\n",
    "                    plt.close()\n",
    "\n",
    "        global_min_maha = 0.0\n",
    "        global_max_maha = 1.0\n",
    "\n",
    "        if all_raw_maha_values:\n",
    "            combined_raw_values = torch.cat(all_raw_maha_values)\n",
    "            global_min_maha = combined_raw_values.min().item()\n",
    "            global_max_maha = combined_raw_values.max().item()\n",
    "            if global_max_maha <= global_min_maha:\n",
    "                global_max_maha = global_min_maha + 1e-8 \n",
    "\n",
    "        return matching_maha_maps, (global_min_maha, global_max_maha)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_unmatched_score_map(\n",
    "        fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        \n",
    "        unmatched_maha_maps = []\n",
    "\n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx] \n",
    "            device = query_fmap.device\n",
    "            map_H, map_W = query_fmap.shape[1], query_fmap.shape[2] \n",
    "\n",
    "            closest_ref_fmaps = []\n",
    "            for neighbor_idx, ref_idx in all_closest_unmatched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap_closest = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                closest_ref_fmaps.append(ref_fmap_closest)\n",
    "\n",
    "            if len(closest_ref_fmaps) == 0:\n",
    "                maha_map_to_return = torch.zeros((map_H, map_W), device=device)\n",
    "                \n",
    "            elif len(closest_ref_fmaps) == 1:\n",
    "                single_ref_fmap = closest_ref_fmaps[0]\n",
    "                effective_ref_fmaps = [single_ref_fmap, single_ref_fmap] \n",
    "                \n",
    "                maha_map_to_return = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=effective_ref_fmaps, \n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                maha_map_to_return = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=closest_ref_fmaps,\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            \n",
    "            # Check here: If the map is invalid, do NOT add it to the list\n",
    "            if torch.isnan(maha_map_to_return).any() or torch.isinf(maha_map_to_return).any():\n",
    "                print(f\"WARNING: Discarding Unmatched Score Map for Query Object {query_idx} due to NaN/Inf values.\")\n",
    "                # Do not append this map\n",
    "            else:\n",
    "                unmatched_maha_maps.append(maha_map_to_return.cpu())\n",
    "\n",
    "                if plot_save_dir:\n",
    "                    plt.figure(figsize=(6, 5))\n",
    "                    maha_map_for_plot = unmatched_maha_maps[-1] # This map is guaranteed to be clean\n",
    "                    plot_normalized_maha = percentile_normalize(maha_map_for_plot, percentile_cap=99.0)\n",
    "                    plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                    plt.title(f\"Unmatched Anomaly Map (Percentile Normalized) - Obj {query_idx}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                    plt.tight_layout()\n",
    "                    save_path = os.path.join(plot_save_dir, f\"unmatched_anomaly_percentile_norm_obj_{query_idx}.png\")\n",
    "                    plt.savefig(save_path)\n",
    "                    plt.close()\n",
    "\n",
    "        return unmatched_maha_maps\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def build_aggregated_score_map(individual_score_maps_list, final_size=(1024, 1024), title_prefix=\"Global Score Map\", plot_save_dir=None, filename_prefix=\"global_score_map\"):\n",
    "\n",
    "        H_out, W_out = final_size\n",
    "        aggregated_score_map = torch.zeros((H_out, W_out), device='cpu') \n",
    "\n",
    "        if not individual_score_maps_list:\n",
    "            print(f\"INFO: No valid individual score maps to aggregate for '{title_prefix}'. Returning empty map.\")\n",
    "            return aggregated_score_map\n",
    "        \n",
    "        for i, score_map in enumerate(individual_score_maps_list):\n",
    "            if torch.isnan(score_map).any() or torch.isinf(score_map).any():\n",
    "                print(f\"CRITICAL WARNING: NaN/Inf detectado en un mapa de puntuación individual {i} después de verificaciones. Saltando.\")\n",
    "                continue\n",
    "                \n",
    "            if score_map.dim() == 2:\n",
    "                score_map_tensor = score_map.unsqueeze(0).unsqueeze(0) \n",
    "            else:\n",
    "                print(f\"WARNING: El mapa de puntuación individual {i} tiene dimensiones inesperadas {score_map.dim()}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            score_resized = F.interpolate(\n",
    "                score_map_tensor.to('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "                size=(H_out, W_out),\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            ).squeeze().cpu()\n",
    "            \n",
    "            aggregated_score_map = torch.max(aggregated_score_map, score_resized)\n",
    "        \n",
    "        # Aplicación del filtro Gaussiano\n",
    "        aggregated_score_map_for_blur = aggregated_score_map.unsqueeze(0)\n",
    "        \n",
    "        gaussian_blur_kernel_size = 19 \n",
    "        \n",
    "        gaussian_blur = T.GaussianBlur(kernel_size=(gaussian_blur_kernel_size, gaussian_blur_kernel_size), sigma=(3.0, 3.0))\n",
    "        \n",
    "        aggregated_score_map_smoothed = gaussian_blur(aggregated_score_map_for_blur)\n",
    "        \n",
    "        aggregated_score_map = aggregated_score_map_smoothed.squeeze(0)\n",
    "\n",
    "        # Verificación final y limpieza después de la agregación y el suavizado\n",
    "        if torch.isnan(aggregated_score_map).any() or torch.isinf(aggregated_score_map).any():\n",
    "            print(f\"ADVERTENCIA CRÍTICA: NaN/Inf detectado en el mapa de puntuación agregado '{title_prefix}' después de la agregación y suavizado. Limpiando para la salida.\")\n",
    "            aggregated_score_map = torch.nan_to_num(aggregated_score_map, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if plot_save_dir:\n",
    "            os.makedirs(plot_save_dir, exist_ok=True)\n",
    "            \n",
    "            plt.figure(figsize=(8, 7))\n",
    "            map_for_plot = aggregated_score_map \n",
    "            plot_normalized_map = percentile_normalize(map_for_plot, percentile_cap=99.0)\n",
    "\n",
    "            plt.imshow(plot_normalized_map.numpy(), cmap=\"hot\")\n",
    "            plt.title(title_prefix + \" (Normalizado por Percentil & Suavizado)\") \n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Puntuación Acumulada (Normalizada para visualización)\")\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_prefix}_percentile_norm_smoothed.png\") \n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "\n",
    "        return aggregated_score_map\n",
    "\n",
    "    def overlay_anomaly_map_on_image(image_rgb_path, anomaly_map, alpha=0.7, cmap='magma', plot_save_dir=None, filename_suffix=\"overlay\"):\n",
    "        try:\n",
    "            image_original_loaded = Image.open(image_rgb_path).convert(\"RGB\")\n",
    "            image_np = np.array(image_original_loaded)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Image not found at {image_rgb_path}. Cannot overlay anomaly map.\")\n",
    "            return\n",
    "\n",
    "        if isinstance(anomaly_map, torch.Tensor):\n",
    "            anomaly_np = anomaly_map.cpu().numpy()\n",
    "        else:\n",
    "            anomaly_np = anomaly_map\n",
    "\n",
    "        # Ensure anomaly_np is clean before sending to percentile_normalize for plotting\n",
    "        if np.isnan(anomaly_np).any() or np.isinf(anomaly_np).any():\n",
    "            print(f\"WARNING: NaN/Inf detected in anomaly map for overlay. Cleaning up for visualization.\")\n",
    "            anomaly_np = np.nan_to_num(anomaly_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        anomaly_norm = percentile_normalize(torch.from_numpy(anomaly_np), percentile_cap=99.0).numpy()\n",
    "\n",
    "        if anomaly_norm.shape[:2] != image_np.shape[:2]:\n",
    "            anomaly_norm = np.array(Image.fromarray(anomaly_norm).resize(\n",
    "                (image_np.shape[1], image_np.shape[0]), resample=Image.BILINEAR\n",
    "            ))\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(image_np)\n",
    "        plt.imshow(anomaly_norm, cmap=cmap, alpha=alpha)\n",
    "        plt.title(\"Anomaly Heatmap Overlay (Percentile Normalized)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if plot_save_dir:\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_suffix}_percentile_norm.png\")\n",
    "            plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "    # --- Main script execution ---\n",
    "    # (Variables like PLOT_SAVE_ROOT_DIR, MAHALANOBIS_SCORE_MAPS_DIR,\n",
    "    # query_image_path, base_image_name, fobj_q, all_fobj_r_list,\n",
    "    # all_matched_ref_indices_by_query_obj, all_closest_unmatched_ref_indices_by_query_obj\n",
    "    # should be defined in your execution environment)\n",
    "\n",
    "    print(\"--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\")\n",
    "\n",
    "    # Assuming start_time_total is defined here or earlier\n",
    "    # start_time_total = time.time() # Example\n",
    "\n",
    "    print(\"pre1: Moviendo feature objects de query a GPU...\")\n",
    "    if isinstance(fobj_q, list):\n",
    "        fobj_q = [fmap.to('cuda') for fmap in fobj_q]\n",
    "    else:\n",
    "        fobj_q = fobj_q.to('cuda')\n",
    "\n",
    "    print(\"pre2: Moviendo feature objects de referencia a GPU...\")\n",
    "    all_fobj_r_list_gpu = []\n",
    "    for inner_list in all_fobj_r_list:\n",
    "        all_fobj_r_list_gpu.append([fmap.to('cuda') for fmap in inner_list])\n",
    "\n",
    "    all_fobj_r_list = all_fobj_r_list_gpu\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"preparación de GPU completa.\")\n",
    "\n",
    "    print(\"Calculando mapas de puntuación de matching...\")\n",
    "    all_matching_score_maps, matched_maha_range_global = compute_matching_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-7, # Keep your refined regularization value here\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        pixel_batch_size=4096\n",
    "    )\n",
    "    print(f\"Total de mapas de matching válidos: {len(all_matching_score_maps)}\")\n",
    "\n",
    "\n",
    "    print(\"Calculando mapas de puntuación de unmatched...\")\n",
    "    all_unmatched_score_maps = compute_unmatched_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj=all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-7, # Keep your refined regularization value here\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        pixel_batch_size=4096\n",
    "    )\n",
    "    print(f\"Total de mapas de unmatched válidos: {len(all_unmatched_score_maps)}\")\n",
    "\n",
    "    image_original = Image.open(query_image_path)\n",
    "    H, W = image_original.size\n",
    "\n",
    "    print(\"Construyendo mapa agregado de matching...\")\n",
    "    global_matched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_matching_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Matched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_matched_anomaly_raw\")\n",
    "\n",
    "    print(\"Construyendo mapa agregado de unmatched...\")\n",
    "    global_unmatched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_unmatched_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Unmatched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_unmatched_anomaly_raw\")\n",
    "\n",
    "    combined_individual_score_maps = []\n",
    "    num_queries = len(fobj_q)\n",
    "    for i in range(num_queries):\n",
    "        # Retrieve maps from the potentially filtered lists\n",
    "        # Note: The order/count in all_matching_score_maps and all_unmatched_score_maps\n",
    "        # might not perfectly match query_idx if maps were discarded.\n",
    "        # To correctly combine, you might need a more robust way to associate.\n",
    "        # For now, let's assume they are still ordered by query_idx if not discarded.\n",
    "        # This part might need refinement if map discarding leads to mismatch.\n",
    "        \n",
    "        # Let's filter here again based on the original fobj_q indices to be safe\n",
    "        # This is a placeholder for more robust association if needed.\n",
    "        matched_map_for_query = None\n",
    "        if i < len(all_matching_score_maps): # Simple check assuming order\n",
    "            matched_map_for_query = all_matching_score_maps[i]\n",
    "            \n",
    "        unmatched_map_for_query = None\n",
    "        if i < len(all_unmatched_score_maps): # Simple check assuming order\n",
    "            unmatched_map_for_query = all_unmatched_score_maps[i]\n",
    "        \n",
    "        # Only combine if both maps are available and valid for this query_idx\n",
    "        if matched_map_for_query is not None and unmatched_map_for_query is not None and \\\n",
    "        not (torch.isnan(matched_map_for_query).any() or torch.isinf(matched_map_for_query).any()) and \\\n",
    "        not (torch.isnan(unmatched_map_for_query).any() or torch.isinf(unmatched_map_for_query).any()):\n",
    "            \n",
    "            combined_map_for_query_i = matched_map_for_query + unmatched_map_for_query\n",
    "            combined_individual_score_maps.append(combined_map_for_query_i)\n",
    "        else:\n",
    "            print(f\"INFO: Query Object {i} is partially or fully discarded for combined map due to missing/invalid individual maps.\")\n",
    "\n",
    "\n",
    "    print(f\"Number of valid combined individual score maps for aggregation: {len(combined_individual_score_maps)}\")\n",
    "    if combined_individual_score_maps:\n",
    "        all_max_values = [m.max().item() for m in combined_individual_score_maps]\n",
    "        print(f\"Max values across all combined_individual_score_maps: {all_max_values}\")\n",
    "\n",
    "    print(\"Construyendo mapa total de anomalías...\")\n",
    "    global_total_anomaly_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=combined_individual_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Total Anomaly Map (Sum of RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_total_anomaly_raw\")\n",
    "\n",
    "    print(\"Generando superposiciones de mapas de anomalías...\")\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_matched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_matched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_unmatched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_unmatched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_total_anomaly_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_total_anomaly_overlay_raw\")\n",
    "\n",
    "    score_map_filename = f\"maha_{base_image_name}.npy\"\n",
    "    score_map_save_path = os.path.join(MAHALANOBIS_SCORE_MAPS_DIR, score_map_filename)\n",
    "\n",
    "    score_map_to_save = global_total_anomaly_score_map.cpu().numpy()\n",
    "\n",
    "    np.save(score_map_save_path, score_map_to_save)\n",
    "    print(\"finalizado iteracion\")\n",
    "\n",
    "    # Assuming start_time_total and start_time_global are defined somewhere\n",
    "    # end_time_total = time.time()\n",
    "    # total_time = end_time_total - start_time_total\n",
    "    # print(f\"Tiempo total de ejecución iteracion: {total_time:.2f} segundos\")\n",
    "\n",
    "    # Check and report NaN/Inf in the final saved map\n",
    "    nan_count = np.isnan(score_map_to_save).sum()\n",
    "    inf_count = np.isinf(score_map_to_save).sum()\n",
    "\n",
    "    if nan_count > 0 or inf_count > 0:\n",
    "        print(f\"\\n--- REPORTE FINAL DE INCONSISTENCIAS ---\")\n",
    "        print(f\"ATENCIÓN: El mapa de Mahalanobis final guardado '{score_map_save_path}' contiene:\")\n",
    "        print(f\"  - {nan_count} valores NaN (Not a Number)\")\n",
    "        print(f\"  - {inf_count} valores Inf (Infinito)\")\n",
    "        print(f\"A pesar de los descartes, si estos valores aparecen aquí, significa que la agregación o una etapa posterior pudo haberlos reintroducido o que un mapa descartado era la única fuente.\")\n",
    "        print(f\"Este mapa final fue limpiado para asegurar que sea numéricamente manejable.\")\n",
    "    else:\n",
    "        print(f\"\\n--- REPORTE FINAL DE INCONSISTENCIAS ---\")\n",
    "        print(f\"No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '{score_map_save_path}'.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Top 10 valores del mapa global de anomalía ---\")\n",
    "    for query_image_path in image_paths:\n",
    "        base_image_name_with_ext = os.path.basename(query_image_path)\n",
    "        base_image_name = os.path.splitext(base_image_name_with_ext)[0]\n",
    "        score_map_filename = f\"maha_{base_image_name}.npy\"\n",
    "        score_map_path = os.path.join(MAHALANOBIS_SCORE_MAPS_DIR, score_map_filename)\n",
    "\n",
    "        try:\n",
    "            score_map = np.load(score_map_path)\n",
    "            top_10_values = np.sort(score_map.flatten())[-10:]\n",
    "            print(f\"Imagen: {base_image_name}\")\n",
    "            print(f\"Top 10 valores: {top_10_values}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: No se encontró el archivo de mapa de puntuación para la imagen '{base_image_name}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Ocurrió un problema al procesar la imagen '{base_image_name}'. Detalles: {e}\")\n",
    "\n",
    "\n",
    "print(\"finalizado\")\n",
    "# end_time_global = time.time()\n",
    "# total_global_time = end_time_global - start_time_global\n",
    "# print(f\"Tiempo total de ejecución global: {total_global_time:.2f} segundos\")\n",
    "\n",
    "# --- Imprimir los 10 valores más altos del mapa global de anomalía para cada imagen ---\n",
    "# --- NUEVA FUNCIÓN: Obtener y mostrar los top N valores más altos ---\n",
    "def get_top_n_values_from_maps(mahalanobis_maps_dict, map_file_ids_dict, n=10):\n",
    "    print(f\"\\n--- Top {n} valores más altos de Mahalanobis para cada mapa ---\")\n",
    "    for cls_name, maps_list in mahalanobis_maps_dict.items():\n",
    "        file_ids = map_file_ids_dict.get(cls_name, [])\n",
    "        if not maps_list:\n",
    "            print(f\"   No hay mapas para la clase '{cls_name}'.\")\n",
    "            continue\n",
    "        print(f\" Clase: '{cls_name}'\")\n",
    "        for i, score_map in enumerate(maps_list):\n",
    "            if score_map.size == 0:\n",
    "                print(f\"     Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'}: Vacío.\")\n",
    "                continue\n",
    "            \n",
    "            flat_scores = score_map.flatten()\n",
    "            # Sort in descending order and take the top N\n",
    "            top_n_values = np.sort(flat_scores)[::-1][:n]\n",
    "            print(f\"     Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'} (Top {n}): {[f'{val:.4f}' for val in top_n_values]}\")\n",
    "    print(\"--- Fin de la visualización de los top valores ---\")\n",
    "# Load the Mahalanobis score map for the current query image\n",
    "try:\n",
    "    score_map = np.load(score_map_save_path)\n",
    "    top_10_values = np.sort(score_map.flatten())[-10:]\n",
    "    print(f\"Imagen: {os.path.basename(query_image_path)}\")\n",
    "    print(f\"Top 10 valores: {top_10_values}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo de mapa de puntuación para la imagen '{os.path.basename(query_image_path)}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Ocurrió un problema al procesar la imagen '{os.path.basename(query_image_path)}'. Detalles: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta para guardar score maps: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps\n",
      "Cargando datos del coreset...\n",
      "Coreset cargado. Dimensión: torch.Size([8192, 384])\n",
      "NearestNeighbors finder inicializado.\n",
      "Cargando modelo DINOv2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo DINOv2 cargado.\n",
      "Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\n",
      "Modelo SAM2 cargado.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/000.png ---\n",
      "Ground Truth Mask Path para 000: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/000_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2738 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97603, IOU=0.9718933701515198, Stability Score=0.9584090709686279\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/000/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 158.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97599, IOU=0.959449291229248, Stability Score=0.9547622203826904\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/000/processed_masks/similar_mask_overlay_158_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 179.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98368, IOU=0.9463170766830444, Stability Score=0.9554387331008911\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/000/processed_masks/similar_mask_overlay_179_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 293.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=96466, IOU=0.9746192097663879, Stability Score=0.9617436528205872\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/000/processed_masks/similar_mask_overlay_293_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.7047 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.094159126281738\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1521834284067154\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9855, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19050.6504,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9802, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18078.5195,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9789, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17840.2129,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6053]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6053, 0.3947],\n",
      "        [0.3947, 0.6053]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6053, 0.3947, 1.0000],\n",
      "        [0.3947, 0.6053, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6053 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3947\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5990, 0.4010],\n",
      "        [0.4010, 0.5990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5990, 0.4010, 1.0000],\n",
      "        [0.4010, 0.5990, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5990 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4010\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5974]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5974, 0.4026],\n",
      "        [0.4026, 0.5974]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5974, 0.4026, 1.0000],\n",
      "        [0.4026, 0.5974, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5974 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4026\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [213.720458984375]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_000.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '001'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '002'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '003'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/001.png ---\n",
      "Ground Truth Mask Path para 001: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/001_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3273 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98025, IOU=0.9172194004058838, Stability Score=0.9638808965682983\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/001/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 300.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97634, IOU=0.9180427193641663, Stability Score=0.9615628719329834\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/001/processed_masks/similar_mask_overlay_300_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 122.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97387, IOU=0.8748564124107361, Stability Score=0.9601325988769531\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/001/processed_masks/similar_mask_overlay_122_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 075.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97185, IOU=0.9478815793991089, Stability Score=0.9571300148963928\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/001/processed_masks/similar_mask_overlay_075_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.8503 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.7128400802612305\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.14245106279850006\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9764, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17393.1895,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9783, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17729.2715,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9681, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16004.7861,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5943]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5943, 0.4057],\n",
      "        [0.4057, 0.5943]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5943, 0.4057, 1.0000],\n",
      "        [0.4057, 0.5943, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5943 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4057\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5966]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5966, 0.4034],\n",
      "        [0.4034, 0.5966]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5966, 0.4034, 1.0000],\n",
      "        [0.4034, 0.5966, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5966 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4034\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5843]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5843, 0.4157],\n",
      "        [0.4157, 0.5843]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5843, 0.4157, 1.0000],\n",
      "        [0.4157, 0.5843, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5843 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4157\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [231.5658416748047]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_001.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '002'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '003'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/002.png ---\n",
      "Ground Truth Mask Path para 002: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/002_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.4247 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=100041, IOU=0.9792324900627136, Stability Score=0.958497166633606\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/002/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 183.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99731, IOU=0.9248114824295044, Stability Score=0.9611045718193054\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/002/processed_masks/similar_mask_overlay_183_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 262.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99530, IOU=0.9808626174926758, Stability Score=0.9587550759315491\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/002/processed_masks/similar_mask_overlay_262_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 082.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99755, IOU=0.9763985276222229, Stability Score=0.9529395699501038\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/002/processed_masks/similar_mask_overlay_082_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.6845 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.383665561676025\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.16543430089950562\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9839, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18759.5195,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9786, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17785.6328,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9814, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18287.9766,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6034]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6034, 0.3966],\n",
      "        [0.3966, 0.6034]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6034, 0.3966, 1.0000],\n",
      "        [0.3966, 0.6034, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6034 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3966\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5970]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5970, 0.4030],\n",
      "        [0.4030, 0.5970]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5970, 0.4030, 1.0000],\n",
      "        [0.4030, 0.5970, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5970 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4030\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6004]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6004, 0.3996],\n",
      "        [0.3996, 0.6004]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6004, 0.3996, 1.0000],\n",
      "        [0.3996, 0.6004, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6004 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3996\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [227.80923461914062]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_002.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '003'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/003.png ---\n",
      "Ground Truth Mask Path para 003: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/003_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2284 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97252, IOU=0.950711727142334, Stability Score=0.9604742527008057\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/003/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 289.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99499, IOU=0.9024356007575989, Stability Score=0.9536243081092834\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/003/processed_masks/similar_mask_overlay_289_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 136.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99438, IOU=0.9644386172294617, Stability Score=0.9671921730041504\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/003/processed_masks/similar_mask_overlay_136_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 018.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99272, IOU=0.9506376385688782, Stability Score=0.9637121558189392\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/003/processed_masks/similar_mask_overlay_018_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 11.3194 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.1302056312561035\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.14859344065189362\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9846, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18887.0996,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9842, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18798.7207,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9841, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18783.4355,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6042]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6042, 0.3958],\n",
      "        [0.3958, 0.6042]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6042, 0.3958, 1.0000],\n",
      "        [0.3958, 0.6042, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6042 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3958\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6037]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6037, 0.3963],\n",
      "        [0.3963, 0.6037]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6037, 0.3963, 1.0000],\n",
      "        [0.3963, 0.6037, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6037 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3963\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6036]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6036, 0.3964],\n",
      "        [0.3964, 0.6036]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6036, 0.3964, 1.0000],\n",
      "        [0.3964, 0.6036, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6036 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3964\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [237.5730743408203]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_003.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '004'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/004.png ---\n",
      "Ground Truth Mask Path para 004: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/004_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.5668 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98548, IOU=0.9650204181671143, Stability Score=0.9556167721748352\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/004/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 134.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98987, IOU=0.9696258902549744, Stability Score=0.9599682688713074\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/004/processed_masks/similar_mask_overlay_134_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 109.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98732, IOU=0.9586172103881836, Stability Score=0.9591216444969177\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/004/processed_masks/similar_mask_overlay_109_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 162.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98054, IOU=0.9581800699234009, Stability Score=0.9540802836418152\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/004/processed_masks/similar_mask_overlay_162_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.5996 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.105721950531006\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.14341267943382263\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9802, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18066.1113,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9754, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17226.6074,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9843, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18830.7871,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5989, 0.4011],\n",
      "        [0.4011, 0.5989]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5989, 0.4011, 1.0000],\n",
      "        [0.4011, 0.5989, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5989 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4011\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5932]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5932, 0.4068],\n",
      "        [0.4068, 0.5932]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5932, 0.4068, 1.0000],\n",
      "        [0.4068, 0.5932, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5932 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4068\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6039]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6039, 0.3961],\n",
      "        [0.3961, 0.6039]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6039, 0.3961, 1.0000],\n",
      "        [0.3961, 0.6039, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6039 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3961\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [235.81512451171875]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_004.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '005'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/005.png ---\n",
      "Ground Truth Mask Path para 005: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/005_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.5092 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98077, IOU=0.9744378328323364, Stability Score=0.9621762633323669\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/005/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 161.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99047, IOU=0.9806923270225525, Stability Score=0.9658403396606445\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/005/processed_masks/similar_mask_overlay_161_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 279.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99237, IOU=0.964404821395874, Stability Score=0.9606108069419861\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/005/processed_masks/similar_mask_overlay_279_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 060.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98814, IOU=0.9694907665252686, Stability Score=0.9645093679428101\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/005/processed_masks/similar_mask_overlay_060_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.0106 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.691284656524658\n",
      "Mínimo de fobj_q_pooled: 0.0\n",
      "Máximo de d_M_q: 0.14034487307071686\n",
      "Mínimo de d_M_q: 0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9762, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17368.8066,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9708, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16450.4473,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9734, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16876.0879,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5942]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5942, 0.4058],\n",
      "        [0.4058, 0.5942]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5942, 0.4058, 1.0000],\n",
      "        [0.4058, 0.5942, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5942 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4058\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5876]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5876, 0.4124],\n",
      "        [0.4124, 0.5876]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5876, 0.4124, 1.0000],\n",
      "        [0.4124, 0.5876, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5876 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4124\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5907]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5907, 0.4093],\n",
      "        [0.4093, 0.5907]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5907, 0.4093, 1.0000],\n",
      "        [0.4093, 0.5907, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5907 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4093\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [222.7283172607422]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_005.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '006'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/006.png ---\n",
      "Ground Truth Mask Path para 006: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/006_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3794 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98363, IOU=0.9752871990203857, Stability Score=0.9642282128334045\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/006/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 161.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99047, IOU=0.9806923270225525, Stability Score=0.9658403396606445\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/006/processed_masks/similar_mask_overlay_161_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 108.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98505, IOU=0.9766190648078918, Stability Score=0.964866042137146\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/006/processed_masks/similar_mask_overlay_108_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 060.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98814, IOU=0.9694907665252686, Stability Score=0.9645093679428101\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/006/processed_masks/similar_mask_overlay_060_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.9287 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.823636770248413\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.15099522471427917\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9778, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17639.5664,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9790, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17857.8477,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9832, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18623.6875,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5960]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5960, 0.4040],\n",
      "        [0.4040, 0.5960]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5960, 0.4040, 1.0000],\n",
      "        [0.4040, 0.5960, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5960 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4040\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5975]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5975, 0.4025],\n",
      "        [0.4025, 0.5975]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5975, 0.4025, 1.0000],\n",
      "        [0.4025, 0.5975, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5975 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4025\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6025]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6025, 0.3975],\n",
      "        [0.3975, 0.6025]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6025, 0.3975, 1.0000],\n",
      "        [0.3975, 0.6025, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6025 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3975\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [217.89276123046875]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_006.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '007'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/007.png ---\n",
      "Ground Truth Mask Path para 007: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/007_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3244 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98248, IOU=0.9801051020622253, Stability Score=0.9655320644378662\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/007/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 280.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98036, IOU=0.9353901743888855, Stability Score=0.9589677453041077\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/007/processed_masks/similar_mask_overlay_280_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 294.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98419, IOU=0.9676449298858643, Stability Score=0.965084433555603\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/007/processed_masks/similar_mask_overlay_294_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 132.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99294, IOU=0.9664217233657837, Stability Score=0.9668140411376953\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/007/processed_masks/similar_mask_overlay_132_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 11.0594 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.025334358215332\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1437903791666031\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9788, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17820.7090,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9729, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16795.1523,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9729, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[16794.1113,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5973]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5973, 0.4027],\n",
      "        [0.4027, 0.5973]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5973, 0.4027, 1.0000],\n",
      "        [0.4027, 0.5973, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5973 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4027\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5901]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5901, 0.4099],\n",
      "        [0.4099, 0.5901]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5901, 0.4099, 1.0000],\n",
      "        [0.4099, 0.5901, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5901 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4099\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5901]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5901, 0.4099],\n",
      "        [0.4099, 0.5901]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5901, 0.4099, 1.0000],\n",
      "        [0.4099, 0.5901, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5901 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4099\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [232.7973175048828]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_007.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '008'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/008.png ---\n",
      "Ground Truth Mask Path para 008: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/008_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3900 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97901, IOU=0.961593508720398, Stability Score=0.9615404009819031\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/008/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 048.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98834, IOU=0.9607238173484802, Stability Score=0.9599364399909973\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/008/processed_masks/similar_mask_overlay_048_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 014.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98462, IOU=0.9092371463775635, Stability Score=0.960098922252655\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/008/processed_masks/similar_mask_overlay_014_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 296.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98229, IOU=0.9672300219535828, Stability Score=0.9617630839347839\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/008/processed_masks/similar_mask_overlay_296_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.0339 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.5206971168518066\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1340639740228653\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9798, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17991.3184,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9803, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18082.3652,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9743, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17042.6777,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5984]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5984, 0.4016],\n",
      "        [0.4016, 0.5984]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5984, 0.4016, 1.0000],\n",
      "        [0.4016, 0.5984, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5984 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4016\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5990, 0.4010],\n",
      "        [0.4010, 0.5990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5990, 0.4010, 1.0000],\n",
      "        [0.4010, 0.5990, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5990 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4010\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5919]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5919, 0.4081],\n",
      "        [0.4081, 0.5919]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5919, 0.4081, 1.0000],\n",
      "        [0.4081, 0.5919, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5919 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4081\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [226.5948028564453]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_008.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '009'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/009.png ---\n",
      "Ground Truth Mask Path para 009: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/009_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.4113 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98974, IOU=0.967979371547699, Stability Score=0.9607683420181274\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/009/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 134.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98987, IOU=0.9696258902549744, Stability Score=0.9599682688713074\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/009/processed_masks/similar_mask_overlay_134_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 162.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98054, IOU=0.9581800699234009, Stability Score=0.9540802836418152\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/009/processed_masks/similar_mask_overlay_162_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 109.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98732, IOU=0.9586172103881836, Stability Score=0.9591216444969177\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/009/processed_masks/similar_mask_overlay_109_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.0853 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.099188804626465\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.15063080191612244\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9804, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18099.0645,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9852, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19004.7051,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9806, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18136.2305,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5991]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5991, 0.4009],\n",
      "        [0.4009, 0.5991]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5991, 0.4009, 1.0000],\n",
      "        [0.4009, 0.5991, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5991 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4009\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6050]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6050, 0.3950],\n",
      "        [0.3950, 0.6050]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6050, 0.3950, 1.0000],\n",
      "        [0.3950, 0.6050, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6050 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3950\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5994]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5994, 0.4006],\n",
      "        [0.4006, 0.5994]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5994, 0.4006, 1.0000],\n",
      "        [0.4006, 0.5994, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5994 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4006\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [220.68247985839844]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_009.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '010'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/010.png ---\n",
      "Ground Truth Mask Path para 010: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/010_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3114 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98040, IOU=0.9166454076766968, Stability Score=0.9630056619644165\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/010/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 015.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98450, IOU=0.9397732615470886, Stability Score=0.9668242931365967\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/010/processed_masks/similar_mask_overlay_015_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 105.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97565, IOU=0.9657941460609436, Stability Score=0.9635220170021057\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/010/processed_masks/similar_mask_overlay_105_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 092.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97739, IOU=0.8843136429786682, Stability Score=0.9609926342964172\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/010/processed_masks/similar_mask_overlay_092_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.7388 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.350160837173462\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.13372685015201569\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9785, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17762.8652,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9798, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17996.9805,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9742, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17010.3477,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5969]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5969, 0.4031],\n",
      "        [0.4031, 0.5969]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5969, 0.4031, 1.0000],\n",
      "        [0.4031, 0.5969, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5969 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4031\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5984]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5984, 0.4016],\n",
      "        [0.4016, 0.5984]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5984, 0.4016, 1.0000],\n",
      "        [0.4016, 0.5984, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5984 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4016\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5916]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5916, 0.4084],\n",
      "        [0.4084, 0.5916]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5916, 0.4084, 1.0000],\n",
      "        [0.4084, 0.5916, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5916 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4084\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [213.79302978515625]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_010.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '011'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/011.png ---\n",
      "Ground Truth Mask Path para 011: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/011_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2331 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98058, IOU=0.9626822471618652, Stability Score=0.9692723751068115\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/011/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 291.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99032, IOU=0.9695636034011841, Stability Score=0.9666070342063904\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/011/processed_masks/similar_mask_overlay_291_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 206.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98603, IOU=0.9657735824584961, Stability Score=0.9653190970420837\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/011/processed_masks/similar_mask_overlay_206_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 192.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99072, IOU=0.9732056260108948, Stability Score=0.9673454165458679\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/011/processed_masks/similar_mask_overlay_192_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.5781 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.8519253730773926\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.14601527154445648\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9859, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19127.1465,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9770, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17500.3750,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9776, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17599.9277,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6057]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6057, 0.3943],\n",
      "        [0.3943, 0.6057]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6057, 0.3943, 1.0000],\n",
      "        [0.3943, 0.6057, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6057 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3943\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5951]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5951, 0.4049],\n",
      "        [0.4049, 0.5951]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5951, 0.4049, 1.0000],\n",
      "        [0.4049, 0.5951, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5951 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4049\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5958]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5958, 0.4042],\n",
      "        [0.4042, 0.5958]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5958, 0.4042, 1.0000],\n",
      "        [0.4042, 0.5958, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5958 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4042\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [228.77972412109375]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_011.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '012'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/012.png ---\n",
      "Ground Truth Mask Path para 012: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/012_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2879 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=99401, IOU=0.9584919214248657, Stability Score=0.9583966732025146\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/012/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 238.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99056, IOU=0.9725109338760376, Stability Score=0.9536551833152771\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/012/processed_masks/similar_mask_overlay_238_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 104.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98911, IOU=0.9756824970245361, Stability Score=0.9586544036865234\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/012/processed_masks/similar_mask_overlay_104_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 221.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98597, IOU=0.9625661373138428, Stability Score=0.9497363567352295\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/012/processed_masks/similar_mask_overlay_221_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.8163 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.633913040161133\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.13316354155540466\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9868, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19295.6465,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9881, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19548.0430,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9829, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18572.7988,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6068]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6068, 0.3932],\n",
      "        [0.3932, 0.6068]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6068, 0.3932, 1.0000],\n",
      "        [0.3932, 0.6068, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6068 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3932\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6083]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6083, 0.3917],\n",
      "        [0.3917, 0.6083]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6083, 0.3917, 1.0000],\n",
      "        [0.3917, 0.6083, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6083 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3917\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6022]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6022, 0.3978],\n",
      "        [0.3978, 0.6022]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6022, 0.3978, 1.0000],\n",
      "        [0.3978, 0.6022, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6022 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3978\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [229.9615478515625]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_012.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '013'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/013.png ---\n",
      "Ground Truth Mask Path para 013: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/013_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.4950 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=99458, IOU=0.9260327219963074, Stability Score=0.9606935381889343\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/013/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 249.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 0\n",
      "Máscaras procesadas para vecino 1: 0.\n",
      "--- Procesando vecino 2: 071.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 0\n",
      "Máscaras procesadas para vecino 2: 0.\n",
      "--- Procesando vecino 3: 131.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 0\n",
      "Máscaras procesadas para vecino 3: 0.\n",
      "Tiempo total de ejecución de SAM: 5.6209 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([0, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([0, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([0, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Advertencia: fobj_r_current tiene dimensión C=0. Saltando a la siguiente iteración.\n",
      "Advertencia: fobj_r_current tiene dimensión C=0. Saltando a la siguiente iteración.\n",
      "Advertencia: fobj_r_current tiene dimensión C=0. Saltando a la siguiente iteración.\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.105186462402344\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.14440324902534485\n",
      "Mínimo de d_M_q: -0.0\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([], device='cuda:0', size=(1, 0))\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[27398.7305],\n",
      "        [16206.1680]], device='cuda:0')\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[27398.7305, 27398.7305],\n",
      "        [16206.1680, 16206.1680],\n",
      "        [43604.8984, 43604.8984]], device='cuda:0')\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: -inf en el índice -1\n",
      "     Probabilidad en el 'Trash Bin': 27398.7305\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto -1\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([], device='cuda:0', size=(1, 0))\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[ 28.4286],\n",
      "        [416.0000]], device='cuda:0')\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[ 28.4286,  28.4286],\n",
      "        [416.0000, 416.0000],\n",
      "        [444.4286, 444.4286]], device='cuda:0')\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: -inf en el índice -1\n",
      "     Probabilidad en el 'Trash Bin': 28.4286\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto -1\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([], device='cuda:0', size=(1, 0))\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.],\n",
      "        [0.]], device='cuda:0')\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: -inf en el índice -1\n",
      "     Probabilidad en el 'Trash Bin': 0.0000\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto -1\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [0.0]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_013.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '014'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/014.png ---\n",
      "Ground Truth Mask Path para 014: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/014_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2123 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98815, IOU=0.974175751209259, Stability Score=0.9531760811805725\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/014/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 084.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99605, IOU=0.9732992053031921, Stability Score=0.9530330896377563\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/014/processed_masks/similar_mask_overlay_084_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 151.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99528, IOU=0.9773388504981995, Stability Score=0.9446479082107544\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/014/processed_masks/similar_mask_overlay_151_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 282.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=102343, IOU=0.9767534732818604, Stability Score=0.9403704404830933\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/014/processed_masks/similar_mask_overlay_282_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.6609 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.163289546966553\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1481681615114212\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9769, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17485.4941,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9767, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17453.5059,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9791, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17864.3027,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5950]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5950, 0.4050],\n",
      "        [0.4050, 0.5950]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5950, 0.4050, 1.0000],\n",
      "        [0.4050, 0.5950, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5950 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4050\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5948]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5948, 0.4052],\n",
      "        [0.4052, 0.5948]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5948, 0.4052, 1.0000],\n",
      "        [0.4052, 0.5948, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5948 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4052\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5976]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5976, 0.4024],\n",
      "        [0.4024, 0.5976]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5976, 0.4024, 1.0000],\n",
      "        [0.4024, 0.5976, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5976 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4024\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [239.3232879638672]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_014.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '015'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/015.png ---\n",
      "Ground Truth Mask Path para 015: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/015_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.4339 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=99730, IOU=0.9775761365890503, Stability Score=0.9672108292579651\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/015/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 291.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99032, IOU=0.9695636034011841, Stability Score=0.9666070342063904\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/015/processed_masks/similar_mask_overlay_291_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 206.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98603, IOU=0.9657735824584961, Stability Score=0.9653190970420837\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/015/processed_masks/similar_mask_overlay_206_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 192.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99072, IOU=0.9732056260108948, Stability Score=0.9673454165458679\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/015/processed_masks/similar_mask_overlay_192_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.3299 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.5914275646209717\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.13344739377498627\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9856, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19070.4629,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9799, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18018.4297,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9788, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17817.2578,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6054]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6054, 0.3946],\n",
      "        [0.3946, 0.6054]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6054, 0.3946, 1.0000],\n",
      "        [0.3946, 0.6054, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6054 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3946\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5986]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5986, 0.4014],\n",
      "        [0.4014, 0.5986]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5986, 0.4014, 1.0000],\n",
      "        [0.4014, 0.5986, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5986 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4014\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5972, 0.4028],\n",
      "        [0.4028, 0.5972]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5972, 0.4028, 1.0000],\n",
      "        [0.4028, 0.5972, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5972 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4028\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [223.673583984375]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_015.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '016'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/016.png ---\n",
      "Ground Truth Mask Path para 016: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/016_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3977 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97533, IOU=0.9541965126991272, Stability Score=0.9581828117370605\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/016/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 171.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98062, IOU=0.9662578105926514, Stability Score=0.9541873335838318\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/016/processed_masks/similar_mask_overlay_171_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 122.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97387, IOU=0.8748564124107361, Stability Score=0.9601325988769531\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/016/processed_masks/similar_mask_overlay_122_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 300.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97634, IOU=0.9180427193641663, Stability Score=0.9615628719329834\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/016/processed_masks/similar_mask_overlay_300_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.0880 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.4049506187438965\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.15495909750461578\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9865, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19253.7539,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9833, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18637.7422,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9859, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19125.0664,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6065]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6065, 0.3935],\n",
      "        [0.3935, 0.6065]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6065, 0.3935, 1.0000],\n",
      "        [0.3935, 0.6065, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6065 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3935\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6026]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6026, 0.3974],\n",
      "        [0.3974, 0.6026]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6026, 0.3974, 1.0000],\n",
      "        [0.3974, 0.6026, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6026 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3974\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6057]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6057, 0.3943],\n",
      "        [0.3943, 0.6057]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6057, 0.3943, 1.0000],\n",
      "        [0.3943, 0.6057, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6057 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3943\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [248.32901000976562]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_016.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "Imagen: 016\n",
      "Top 10 valores: [85.75234  85.94066  85.94165  85.97201  86.002525 86.08104  86.145744\n",
      " 86.238014 86.35417  86.35594 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '017'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/017.png ---\n",
      "Ground Truth Mask Path para 017: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/017_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2699 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=96801, IOU=0.9341444969177246, Stability Score=0.9617738127708435\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/017/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 090.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=96403, IOU=0.9571091532707214, Stability Score=0.9629988074302673\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/017/processed_masks/similar_mask_overlay_090_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 158.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97599, IOU=0.959449291229248, Stability Score=0.9547622203826904\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/017/processed_masks/similar_mask_overlay_158_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 199.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=96549, IOU=0.9335776567459106, Stability Score=0.9603968262672424\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/017/processed_masks/similar_mask_overlay_199_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.3690 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.300967216491699\n",
      "Mínimo de fobj_q_pooled: 0.0\n",
      "Máximo de d_M_q: 0.1567244529724121\n",
      "Mínimo de d_M_q: 0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9821, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18410.7188,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9815, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18310.0547,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9784, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17742.9062,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6012]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6012, 0.3988],\n",
      "        [0.3988, 0.6012]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6012, 0.3988, 1.0000],\n",
      "        [0.3988, 0.6012, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6012 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3988\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6005]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6005, 0.3995],\n",
      "        [0.3995, 0.6005]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6005, 0.3995, 1.0000],\n",
      "        [0.3995, 0.6005, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6005 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3995\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5967]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5967, 0.4033],\n",
      "        [0.4033, 0.5967]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5967, 0.4033, 1.0000],\n",
      "        [0.4033, 0.5967, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5967 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4033\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [238.5574188232422]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_017.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "Imagen: 016\n",
      "Top 10 valores: [85.75234  85.94066  85.94165  85.97201  86.002525 86.08104  86.145744\n",
      " 86.238014 86.35417  86.35594 ]\n",
      "Imagen: 017\n",
      "Top 10 valores: [87.49778  87.501595 87.573326 87.57901  87.60413  87.66544  87.67229\n",
      " 87.693085 87.7156   87.73084 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '018'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/018.png ---\n",
      "Ground Truth Mask Path para 018: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/018_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3488 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98412, IOU=0.9669539928436279, Stability Score=0.9658902287483215\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/018/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 166.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98344, IOU=0.9651788473129272, Stability Score=0.9648628234863281\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/018/processed_masks/similar_mask_overlay_166_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 276.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98863, IOU=0.9703538417816162, Stability Score=0.9597679376602173\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/018/processed_masks/similar_mask_overlay_276_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 287.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99849, IOU=0.9780097603797913, Stability Score=0.9443409442901611\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/018/processed_masks/similar_mask_overlay_287_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.5819 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.022452354431152\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.14759092032909393\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9804, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18106.1777,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9757, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17276.8535,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9819, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18371.1504,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5992]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5992, 0.4008],\n",
      "        [0.4008, 0.5992]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5992, 0.4008, 1.0000],\n",
      "        [0.4008, 0.5992, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5992 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4008\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5935]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5935, 0.4065],\n",
      "        [0.4065, 0.5935]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5935, 0.4065, 1.0000],\n",
      "        [0.4065, 0.5935, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5935 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4065\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6009]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6009, 0.3991],\n",
      "        [0.3991, 0.6009]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6009, 0.3991, 1.0000],\n",
      "        [0.3991, 0.6009, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6009 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3991\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [229.71820068359375]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_018.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "Imagen: 016\n",
      "Top 10 valores: [85.75234  85.94066  85.94165  85.97201  86.002525 86.08104  86.145744\n",
      " 86.238014 86.35417  86.35594 ]\n",
      "Imagen: 017\n",
      "Top 10 valores: [87.49778  87.501595 87.573326 87.57901  87.60413  87.66544  87.67229\n",
      " 87.693085 87.7156   87.73084 ]\n",
      "Imagen: 018\n",
      "Top 10 valores: [134.70358 134.78719 134.94608 134.9841  135.00766 135.06992 135.07718\n",
      " 135.1559  135.18266 135.28987]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '019'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/019.png ---\n",
      "Ground Truth Mask Path para 019: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/019_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.3835 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98417, IOU=0.9753009080886841, Stability Score=0.9688544869422913\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/019/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 268.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98416, IOU=0.9636033773422241, Stability Score=0.966821014881134\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/019/processed_masks/similar_mask_overlay_268_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 024.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98723, IOU=0.9457679390907288, Stability Score=0.9608370065689087\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/019/processed_masks/similar_mask_overlay_024_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 273.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98519, IOU=0.9059591293334961, Stability Score=0.9625130891799927\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/019/processed_masks/similar_mask_overlay_273_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.8734 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.046566009521484\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1484089493751526\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9860, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19157.2129,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9852, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19000.4453,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9807, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18164.3066,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6059]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6059, 0.3941],\n",
      "        [0.3941, 0.6059]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6059, 0.3941, 1.0000],\n",
      "        [0.3941, 0.6059, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6059 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3941\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6049]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6049, 0.3951],\n",
      "        [0.3951, 0.6049]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6049, 0.3951, 1.0000],\n",
      "        [0.3951, 0.6049, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6049 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3951\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5996, 0.4004],\n",
      "        [0.4004, 0.5996]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5996, 0.4004, 1.0000],\n",
      "        [0.4004, 0.5996, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5996 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4004\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [228.68194580078125]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_019.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "Imagen: 016\n",
      "Top 10 valores: [85.75234  85.94066  85.94165  85.97201  86.002525 86.08104  86.145744\n",
      " 86.238014 86.35417  86.35594 ]\n",
      "Imagen: 017\n",
      "Top 10 valores: [87.49778  87.501595 87.573326 87.57901  87.60413  87.66544  87.67229\n",
      " 87.693085 87.7156   87.73084 ]\n",
      "Imagen: 018\n",
      "Top 10 valores: [134.70358 134.78719 134.94608 134.9841  135.00766 135.06992 135.07718\n",
      " 135.1559  135.18266 135.28987]\n",
      "Imagen: 019\n",
      "Top 10 valores: [118.87491  119.14442  119.17855  119.28131  119.31187  119.459236\n",
      " 119.46338  119.54418  119.576004 119.79329 ]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '020'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/020.png ---\n",
      "Ground Truth Mask Path para 020: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/020_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2134 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=98983, IOU=0.9744641184806824, Stability Score=0.9636695981025696\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/020/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 290.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=100359, IOU=0.9730374217033386, Stability Score=0.9626097679138184\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/020/processed_masks/similar_mask_overlay_290_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 028.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99918, IOU=0.974304735660553, Stability Score=0.961584210395813\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/020/processed_masks/similar_mask_overlay_028_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 274.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=101271, IOU=0.9418469667434692, Stability Score=0.9494903683662415\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/020/processed_masks/similar_mask_overlay_274_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.7657 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.552464485168457\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.12998995184898376\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9793, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17910.7559,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9856, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19075.0840,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9830, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18587.9863,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5979, 0.4021],\n",
      "        [0.4021, 0.5979]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5979, 0.4021, 1.0000],\n",
      "        [0.4021, 0.5979, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5979 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4021\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6054]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6054, 0.3946],\n",
      "        [0.3946, 0.6054]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6054, 0.3946, 1.0000],\n",
      "        [0.3946, 0.6054, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6054 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3946\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6023]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6023, 0.3977],\n",
      "        [0.3977, 0.6023]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6023, 0.3977, 1.0000],\n",
      "        [0.3977, 0.6023, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6023 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3977\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [222.41839599609375]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_020.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "Imagen: 016\n",
      "Top 10 valores: [85.75234  85.94066  85.94165  85.97201  86.002525 86.08104  86.145744\n",
      " 86.238014 86.35417  86.35594 ]\n",
      "Imagen: 017\n",
      "Top 10 valores: [87.49778  87.501595 87.573326 87.57901  87.60413  87.66544  87.67229\n",
      " 87.693085 87.7156   87.73084 ]\n",
      "Imagen: 018\n",
      "Top 10 valores: [134.70358 134.78719 134.94608 134.9841  135.00766 135.06992 135.07718\n",
      " 135.1559  135.18266 135.28987]\n",
      "Imagen: 019\n",
      "Top 10 valores: [118.87491  119.14442  119.17855  119.28131  119.31187  119.459236\n",
      " 119.46338  119.54418  119.576004 119.79329 ]\n",
      "Imagen: 020\n",
      "Top 10 valores: [82.43337  82.49297  82.51744  82.60892  82.71135  82.78452  82.81391\n",
      " 82.81662  82.94285  82.974045]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '021'.\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/021.png ---\n",
      "Ground Truth Mask Path para 021: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/021_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.4112 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97020, IOU=0.9813645482063293, Stability Score=0.9661896824836731\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/021/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 279.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99237, IOU=0.964404821395874, Stability Score=0.9606108069419861\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/021/processed_masks/similar_mask_overlay_279_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 253.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98559, IOU=0.9149934649467468, Stability Score=0.9548816084861755\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/021/processed_masks/similar_mask_overlay_253_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 225.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=98543, IOU=0.9538240432739258, Stability Score=0.9625113606452942\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/021/processed_masks/similar_mask_overlay_225_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 10.0121 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 3.523416042327881\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.13120539486408234\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9866, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19257.0234,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9855, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[19062.5527,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9824, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18464.0312,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.6065]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.6065, 0.3935],\n",
      "        [0.3935, 0.6065]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6065, 0.3935, 1.0000],\n",
      "        [0.3935, 0.6065, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6065 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3935\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.6053]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.6053, 0.3947],\n",
      "        [0.3947, 0.6053]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6053, 0.3947, 1.0000],\n",
      "        [0.3947, 0.6053, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6053 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3947\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.6015]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.6015, 0.3985],\n",
      "        [0.3985, 0.6015]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.6015, 0.3985, 1.0000],\n",
      "        [0.3985, 0.6015, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.6015 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.3985\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [231.33265686035156]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_021.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "Imagen: 016\n",
      "Top 10 valores: [85.75234  85.94066  85.94165  85.97201  86.002525 86.08104  86.145744\n",
      " 86.238014 86.35417  86.35594 ]\n",
      "Imagen: 017\n",
      "Top 10 valores: [87.49778  87.501595 87.573326 87.57901  87.60413  87.66544  87.67229\n",
      " 87.693085 87.7156   87.73084 ]\n",
      "Imagen: 018\n",
      "Top 10 valores: [134.70358 134.78719 134.94608 134.9841  135.00766 135.06992 135.07718\n",
      " 135.1559  135.18266 135.28987]\n",
      "Imagen: 019\n",
      "Top 10 valores: [118.87491  119.14442  119.17855  119.28131  119.31187  119.459236\n",
      " 119.46338  119.54418  119.576004 119.79329 ]\n",
      "Imagen: 020\n",
      "Top 10 valores: [82.43337  82.49297  82.51744  82.60892  82.71135  82.78452  82.81391\n",
      " 82.81662  82.94285  82.974045]\n",
      "Imagen: 021\n",
      "Top 10 valores: [154.40126 154.46631 154.5396  154.57397 154.6122  154.64664 154.71\n",
      " 154.8721  154.92184 154.93524]\n",
      "ERROR: No se encontró el archivo de mapa de puntuación para la imagen '022'.\n",
      "\n",
      "--- Procesando imagen: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side/022.png ---\n",
      "Ground Truth Mask Path para 022: /home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/ground_truth/thread_side/022_mask.png\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "dimension mapa query torch.Size([1, 384, 16, 16])\n",
      "dimension query flatten (98304,)\n",
      "dimension query flatten (320, 98304)\n",
      "dimensiones desde BANCO STAGE 1 stage torch.Size([320, 98304])\n",
      "Tiempo para calcular distancias KNN: 0.2189 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "Mascara 1: Area=97215, IOU=0.9544018507003784, Stability Score=0.9595416784286499\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/022/processed_masks/query_mask_1.png\n",
      "Número de máscaras generadas DESPUÉS de filtrar (área >= 75000): 1\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 136.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99438, IOU=0.9644386172294617, Stability Score=0.9671921730041504\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/022/processed_masks/similar_mask_overlay_136_mask_1.png\n",
      "Máscaras procesadas para vecino 1: 1.\n",
      "--- Procesando vecino 2: 289.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=99499, IOU=0.9024356007575989, Stability Score=0.9536243081092834\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/022/processed_masks/similar_mask_overlay_289_mask_1.png\n",
      "Máscaras procesadas para vecino 2: 1.\n",
      "--- Procesando vecino 3: 237.png ---\n",
      "Número de máscaras generadas y filtradas (área >= 75000): 1\n",
      "Mascara 1: Area=97817, IOU=0.9007501602172852, Stability Score=0.9531493782997131\n",
      "Máscara 1 sobrepuesta guardada en: /home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/022/processed_masks/similar_mask_overlay_237_mask_1.png\n",
      "Máscaras procesadas para vecino 3: 1.\n",
      "Tiempo total de ejecución de SAM: 9.9956 segundos.\n",
      "\n",
      "Análisis de SAM para una sola imagen completado.\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([1, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([1, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "Shape de fobj_q_pooled: torch.Size([1, 384])\n",
      "Máximo de fobj_q_pooled: 4.0177998542785645\n",
      "Mínimo de fobj_q_pooled: -0.0\n",
      "Máximo de d_M_q: 0.1428389996290207\n",
      "Mínimo de d_M_q: -0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9807, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18168.8457,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9792, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[17896.3613,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9802, 0.9000],\n",
      "        [0.9000, 0.9000]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[18074.1406,  8103.0840],\n",
      "        [ 8103.0840,  8103.0840]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.5996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[0.5996, 0.4004],\n",
      "        [0.4004, 0.5996]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5996, 0.4004, 1.0000],\n",
      "        [0.4004, 0.5996, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5996 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4004\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.5978]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[0.5978, 0.4022],\n",
      "        [0.4022, 0.5978]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5978, 0.4022, 1.0000],\n",
      "        [0.4022, 0.5978, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5978 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4022\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.5990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[0.5990, 0.4010],\n",
      "        [0.4010, 0.5990]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[0.5990, 0.4010, 1.0000],\n",
      "        [0.4010, 0.5990, 1.0000],\n",
      "        [1.0000, 1.0000, 2.0000]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.5990 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.4010\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 0), (1, 0), (2, 0)]\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\n",
      "--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\n",
      "pre1: Moviendo feature objects de query a GPU...\n",
      "pre2: Moviendo feature objects de referencia a GPU...\n",
      "preparación de GPU completa.\n",
      "Calculando mapas de puntuación de matching...\n",
      "Total de mapas de matching válidos: 1\n",
      "Calculando mapas de puntuación de unmatched...\n",
      "Total de mapas de unmatched válidos: 1\n",
      "Construyendo mapa agregado de matching...\n",
      "Construyendo mapa agregado de unmatched...\n",
      "Number of valid combined individual score maps for aggregation: 1\n",
      "Max values across all combined_individual_score_maps: [243.00685119628906]\n",
      "Construyendo mapa total de anomalías...\n",
      "Generando superposiciones de mapas de anomalías...\n",
      "finalizado iteracion\n",
      "\n",
      "--- REPORTE FINAL DE INCONSISTENCIAS ---\n",
      "No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10/mahalanobis_score_maps/maha_022.npy'.\n",
      "\n",
      "--- Top 10 valores del mapa global de anomalía ---\n",
      "Imagen: 000\n",
      "Top 10 valores: [71.92222  71.94309  71.972145 71.98162  72.08009  72.10664  72.18734\n",
      " 72.22033  72.24238  72.26724 ]\n",
      "Imagen: 001\n",
      "Top 10 valores: [84.35999 84.37674 84.39465 84.45178 84.46443 84.47631 84.49297 84.49506\n",
      " 84.55742 84.59333]\n",
      "Imagen: 002\n",
      "Top 10 valores: [136.6544  136.7178  136.7314  136.74815 136.77986 136.96625 137.02339\n",
      " 137.14641 137.16649 137.23119]\n",
      "Imagen: 003\n",
      "Top 10 valores: [111.416115 111.543    111.690384 111.79794  111.81312  111.84076\n",
      " 111.85525  111.98976  112.09483  112.17711 ]\n",
      "Imagen: 004\n",
      "Top 10 valores: [67.61989  67.62355  67.638    67.6491   67.65798  67.72995  67.731766\n",
      " 67.76658  67.77513  67.8011  ]\n",
      "Imagen: 005\n",
      "Top 10 valores: [124.63553  124.636635 124.641    124.64118  124.648994 124.65035\n",
      " 124.651726 124.65795  124.664375 124.66849 ]\n",
      "Imagen: 006\n",
      "Top 10 valores: [124.488884 124.49227  124.674255 124.75033  124.772606 124.809105\n",
      " 124.842125 124.940956 124.94769  125.050606]\n",
      "Imagen: 007\n",
      "Top 10 valores: [113.28842 113.295   113.33288 113.42065 113.43022 113.50001 113.50135\n",
      " 113.59449 113.67935 113.71025]\n",
      "Imagen: 008\n",
      "Top 10 valores: [89.3743  89.50829 89.52021 89.63897 89.8305  89.85183 89.87909 89.95047\n",
      " 90.0907  90.1403 ]\n",
      "Imagen: 009\n",
      "Top 10 valores: [73.093185 73.11029  73.11115  73.12919  73.15204  73.15493  73.15943\n",
      " 73.16547  73.17056  73.17616 ]\n",
      "Imagen: 010\n",
      "Top 10 valores: [144.80336 144.82024 144.8392  144.95236 145.0223  145.05563 145.09195\n",
      " 145.14825 145.24445 145.2884 ]\n",
      "Imagen: 011\n",
      "Top 10 valores: [79.96075  80.184204 80.22943  80.25736  80.30752  80.40676  80.40735\n",
      " 80.45219  80.49062  80.63443 ]\n",
      "Imagen: 012\n",
      "Top 10 valores: [57.041985 57.133526 57.155857 57.197796 57.201923 57.276108 57.29512\n",
      " 57.30199  57.35843  57.44407 ]\n",
      "Imagen: 013\n",
      "Top 10 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Imagen: 014\n",
      "Top 10 valores: [110.02534  110.02562  110.03257  110.03331  110.03636  110.04289\n",
      " 110.04447  110.045265 110.047615 110.05199 ]\n",
      "Imagen: 015\n",
      "Top 10 valores: [98.76941  98.76969  98.89006  98.97759  99.01311  99.09437  99.15589\n",
      " 99.190475 99.38271  99.419014]\n",
      "Imagen: 016\n",
      "Top 10 valores: [85.75234  85.94066  85.94165  85.97201  86.002525 86.08104  86.145744\n",
      " 86.238014 86.35417  86.35594 ]\n",
      "Imagen: 017\n",
      "Top 10 valores: [87.49778  87.501595 87.573326 87.57901  87.60413  87.66544  87.67229\n",
      " 87.693085 87.7156   87.73084 ]\n",
      "Imagen: 018\n",
      "Top 10 valores: [134.70358 134.78719 134.94608 134.9841  135.00766 135.06992 135.07718\n",
      " 135.1559  135.18266 135.28987]\n",
      "Imagen: 019\n",
      "Top 10 valores: [118.87491  119.14442  119.17855  119.28131  119.31187  119.459236\n",
      " 119.46338  119.54418  119.576004 119.79329 ]\n",
      "Imagen: 020\n",
      "Top 10 valores: [82.43337  82.49297  82.51744  82.60892  82.71135  82.78452  82.81391\n",
      " 82.81662  82.94285  82.974045]\n",
      "Imagen: 021\n",
      "Top 10 valores: [154.40126 154.46631 154.5396  154.57397 154.6122  154.64664 154.71\n",
      " 154.8721  154.92184 154.93524]\n",
      "Imagen: 022\n",
      "Top 10 valores: [151.13345 151.1467  151.18181 151.2535  151.60458 151.634   151.64041\n",
      " 151.70277 151.7888  151.8323 ]\n",
      "finalizado\n",
      "Imagen: 022.png\n",
      "Top 10 valores: [151.13345 151.1467  151.18181 151.2535  151.60458 151.634   151.64041\n",
      " 151.70277 151.7888  151.8323 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# FeatUp utilities\n",
    "from featup.util import norm, unnorm\n",
    "from featup.plotting import plot_feats\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Anomaly region detection and visualization\n",
    "from skimage import measure\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# SAM2 imports\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import cv2\n",
    "\n",
    "# PCA for manual visualization\n",
    "from sklearn.decomposition import PCA\n",
    "# --- Enable loading of truncated images ---\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # Add this at the very top for global effect\n",
    "\n",
    "# --- Configuración ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224  # DINOv2 input size\n",
    "BACKBONE_PATCH_SIZE = 14  # DINOv2 ViT-S/14 patch size\n",
    "use_norm = True\n",
    "\n",
    "H_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "W_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "\n",
    "# Directorios\n",
    "TRAIN_GOOD_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/train/good'\n",
    "directorio_coreset = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/train/good/archivos_coreset'\n",
    "#PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/plots_final_eval/cut'\n",
    "# --- Imagen de Consulta ---\n",
    "BASE_PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/graficas_evaluacion_screw/thread_side_gausG10'  # Base dirlectory for saving plots\n",
    "\n",
    "# Directory containing the test images \n",
    "TEST_IMAGES_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/screw/test/thread_side'\n",
    "\n",
    "# Create parent plot directory if it doesn't exist\n",
    "os.makedirs(BASE_PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "# --- NUEVA CARPETA PARA LOS MAPAS DE ANOMALÍAS ---\n",
    "MAHALANOBIS_SCORE_MAPS_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, 'mahalanobis_score_maps')\n",
    "os.makedirs(MAHALANOBIS_SCORE_MAPS_DIR, exist_ok=True)\n",
    "print(f\"Carpeta para guardar score maps: {MAHALANOBIS_SCORE_MAPS_DIR}\")\n",
    "\n",
    "# Coreset file paths\n",
    "core_bank_filenames_file = os.path.join(directorio_coreset, 'core_bank_filenames.pt')\n",
    "coreset_relevant_flat_features_bank_file = os.path.join(directorio_coreset, 'coreset_relevant_flat_features_bank.pt')\n",
    "template_features_bank_coreset_file = os.path.join(directorio_coreset, 'template_features_bank_coreset.pt')\n",
    "\n",
    "# --- Cargar Datos del Coreset ---\n",
    "print(\"Cargando datos del coreset...\")\n",
    "try:\n",
    "    coreset_relevant_filenames = torch.load(core_bank_filenames_file)\n",
    "    coreset_relevant_flat_features_bank = torch.load(coreset_relevant_flat_features_bank_file).to(device)\n",
    "    coreset_features = torch.load(template_features_bank_coreset_file).to(device)\n",
    "    print(f\"Coreset cargado. Dimensión: {coreset_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar archivos del coreset: {e}. Asegúrate de que la Etapa 1 se ejecutó.\")\n",
    "    exit()\n",
    "\n",
    "# Mover coreset a CPU para sklearn's NearestNeighbors\n",
    "coreset_features_cpu = coreset_features.cpu().numpy()\n",
    "# se calcula la distancia coseno == 1 - similitud coseno [0,1] 0 identico, 1 completamente diferente\n",
    "nn_finder = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='cosine').fit(coreset_features_cpu)\n",
    "print(\"NearestNeighbors finder inicializado.\")\n",
    "\n",
    "# --- Cargar Modelo DINOv2 ---\n",
    "print(\"Cargando modelo DINOv2...\")\n",
    "featup_local_path = \"/home/imercatoma/FeatUp\"\n",
    "upsampler = torch.hub.load(featup_local_path, 'dinov2', use_norm=use_norm, source='local').to(device)\n",
    "\n",
    "dinov2_model = upsampler.model\n",
    "dinov2_model.eval()\n",
    "print(\"Modelo DINOv2 cargado.\")\n",
    "\n",
    "# --- Transformación de Imagen ---\n",
    "transform = T.Compose([\n",
    "    T.Resize(input_size),\n",
    "    T.CenterCrop((input_size, input_size)),\n",
    "    T.ToTensor(),\n",
    "    norm\n",
    "])\n",
    "\n",
    "# --- Carga del Modelo SAM2 ---\n",
    "print(f\"Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\")\n",
    "checkpoint = \"/home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt\"\n",
    "model_cfg_name = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_model = build_sam2(model_cfg_name, checkpoint, device=device, apply_postprocessing=True)\n",
    "sam2_model.eval()\n",
    "print(\"Modelo SAM2 cargado.\")\n",
    "\n",
    "#### fin de carga de modelos\n",
    "\n",
    "# --- CONFIGURACIÓN PARA EL GUARDADO DE EXCEL ---\n",
    "EXCEL_OUTPUT_PATH = 'resultados_evaluacion_anomalias.xlsx'\n",
    "all_evaluation_results = [] # This list will accumulate results from all processed images\n",
    "\n",
    "# Opción 2: Procesar solo las primeras 10 imágenes (descomentar si prefieres esta opción)\n",
    "image_paths = glob.glob(os.path.join(TEST_IMAGES_DIR, '*.png'))\n",
    "image_paths.sort()\n",
    "\n",
    "######\n",
    "start_time_global = time.time()\n",
    "# --- Bucle para procesar cada imagen ---\n",
    "for query_image_path in image_paths:\n",
    "    start_time_total = time.time()\n",
    "    print(f\"\\n--- Procesando imagen: {query_image_path} ---\")\n",
    "\n",
    "    # Extraer el nombre base de la imagen (ej: '006.png')\n",
    "    base_image_name_with_ext = os.path.basename(query_image_path)\n",
    "    base_image_name = os.path.splitext(base_image_name_with_ext)[0] # '006'\n",
    "\n",
    "    # Construir la ruta de la máscara Ground Truth para la imagen actual\n",
    "    gt_mask_path = query_image_path.replace('test', 'ground_truth').replace('.png', '_mask.png')\n",
    "    print(f\"Ground Truth Mask Path para {base_image_name}: {gt_mask_path}\")\n",
    "\n",
    "    # --- Directorios de guardado específicos para esta imagen ---\n",
    "    PLOT_SAVE_ROOT_DIR = os.path.join(BASE_PLOT_SAVE_ROOT_DIR, base_image_name)\n",
    "    os.makedirs(PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "    HEATMAPS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'individual_heatmaps')\n",
    "    os.makedirs(HEATMAPS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    ANOMALY_REGIONS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'detected_anomaly_regions')\n",
    "    os.makedirs(ANOMALY_REGIONS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    FEATUP_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'featup_feature_plots')\n",
    "    os.makedirs(FEATUP_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "    # --- Cargar la imagen de consulta CON ERROR HANDLING ---\n",
    "    query_img_pil = None # Initialize to None\n",
    "    try:\n",
    "        query_img_pil = Image.open(query_image_path).convert(\"RGB\")\n",
    "        W, H = query_img_pil.size # Get dimensions for consistent resizing\n",
    "    except OSError as e:\n",
    "        print(f\"ERROR: No se pudo cargar o procesar la imagen de consulta '{query_image_path}'. Error: {e}\")\n",
    "        print(\"Saltando a la siguiente imagen...\")\n",
    "        continue # Skip to the next image in the loop\n",
    "\n",
    "    # If query_img_pil is still None, it means an error occurred, so skip\n",
    "    if query_img_pil is None:\n",
    "        continue\n",
    "\n",
    "    # Definir el tamaño objetivo para las máscaras de evaluación (el mismo que el mapa de anomalías)\n",
    "    TARGET_EVAL_SIZE = (W, H)\n",
    "\n",
    "    #############----------- PROCESO   -----###############\n",
    "    \n",
    "    input_tensor = transform(query_img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_lr = dinov2_model(input_tensor)\n",
    "\n",
    "    query_lr_features = features_lr\n",
    "\n",
    "    # --- Función para buscar imágenes similares usando KNN ---\n",
    "    def buscar_imagenes_similares_knn(query_feature_map, pre_flattened_features_bank, k=3, nombres_archivos=None):\n",
    "        query_feat_flatten = query_feature_map.flatten().cpu().numpy()#dimension mapa desde banco torch.Size([1, 384, 16, 16])\n",
    "        print(f\"dimension mapa query\", query_feature_map.shape)\n",
    "        print(f\"dimension query flatten\", query_feat_flatten.shape)#dimension query flatten (98304,)\n",
    "        features_bank_for_knn = pre_flattened_features_bank.cpu().numpy() if isinstance(pre_flattened_features_bank, torch.Tensor) else pre_flattened_features_bank\n",
    "        print(f\"dimension query flatten\", features_bank_for_knn.shape)#dimension query flatten (213, 98304)\n",
    "        print(f\"dimensiones desde BANCO STAGE 1 stage\", pre_flattened_features_bank.shape)#dimensiones desde BANCO STAGE 1 stage torch.Size([213, 98304])\n",
    "        \n",
    "        \n",
    "        start_time_knn_dist = time.time()\n",
    "        distances = euclidean_distances([query_feat_flatten], features_bank_for_knn)\n",
    "        nearest_indices = np.argsort(distances[0])[:k]\n",
    "        end_time_knn_dist = time.time()\n",
    "        print(f\"Tiempo para calcular distancias KNN: {end_time_knn_dist - start_time_knn_dist:.4f} segundos\")\n",
    "\n",
    "        imagenes_similares = []\n",
    "        rutas_imagenes_similares = []\n",
    "        if nombres_archivos:\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(nombres_archivos[idx])\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, nombres_archivos[idx]))\n",
    "        else: # Fallback if no filenames provided (less common for this use case)\n",
    "            for idx in nearest_indices:\n",
    "                imagenes_similares.append(f\"Imagen_Banco_{idx:03d}.png\")\n",
    "                rutas_imagenes_similares.append(os.path.join(TRAIN_GOOD_DIR, f\"Imagen_Banco_{idx:03d}.png\"))\n",
    "        return imagenes_similares, rutas_imagenes_similares, end_time_knn_dist\n",
    "\n",
    "    # --- Búsqueda KNN ---\n",
    "    print(\"\\nBuscando imágenes similares usando el banco pre-aplanado del Coreset...\")\n",
    "    imagenes_similares, rutas_imagenes_similares, time_knn_dist = buscar_imagenes_similares_knn(\n",
    "        query_lr_features, coreset_relevant_flat_features_bank, nombres_archivos=coreset_relevant_filenames\n",
    "    )\n",
    "\n",
    "    # --- Aplicar FeatUp para obtener características de alta resolución ---\n",
    "    def apply_featup_hr(image_path, featup_upsampler, image_transform, device):\n",
    "        image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = image_transform(image_pil).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            lr_feats = featup_upsampler.model(image_tensor)\n",
    "            hr_feats = featup_upsampler(image_tensor)\n",
    "        return lr_feats.cpu(), hr_feats.cpu()\n",
    "\n",
    "    # Características de la imagen de consulta\n",
    "    input_query_tensor_original = transform(Image.open(query_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    query_lr_feats_featup, query_hr_feats = apply_featup_hr(query_image_path, upsampler, transform, device)\n",
    "\n",
    "    # Características de las imágenes similares\n",
    "    similar_hr_feats_list = []\n",
    "    for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "        input_similar_tensor_original = transform(Image.open(similar_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "        similar_lr_feats, similar_hr_feats = apply_featup_hr(similar_image_path, upsampler, transform, device)\n",
    "        similar_hr_feats_list.append(similar_hr_feats)\n",
    "\n",
    "    ################################\n",
    "    ### Aplicando Máscaras SAM query y similares\n",
    "\n",
    "    def show_mask(mask, ax, random_color=False, borders=True):\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image_alpha = np.zeros((h, w, 4), dtype=np.float32)\n",
    "        mask_image_alpha[mask > 0] = color\n",
    "        if borders:\n",
    "            mask_uint8 = mask.astype(np.uint8) * 255\n",
    "            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contour_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=2)\n",
    "            contour_mask = (contour_image.astype(np.float32) / 255.0).sum(axis=-1) > 0\n",
    "            mask_image_alpha[contour_mask > 0, :3] = 1.0\n",
    "            mask_image_alpha[contour_mask > 0, 3] = 0.5\n",
    "        ax.imshow(mask_image_alpha)\n",
    "\n",
    "    def process_masks_with_hierarchy(image, masks, output_dir, filename_prefix, overlap_threshold=0.8):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        final_processed_masks_data = [] \n",
    "        original_mask_segments_for_comparison = [mask_data[\"segmentation\"] for mask_data in masks]\n",
    "\n",
    "        print(f\"Procesando jerárquicamente {len(masks)} máscaras...\")\n",
    "\n",
    "        for i, mask_data_a_original in enumerate(masks): \n",
    "            mask_data_a_processed = mask_data_a_original.copy() \n",
    "            mask_a_current_processing = np.copy(mask_data_a_original[\"segmentation\"]) \n",
    "\n",
    "            is_completely_internal_to_another = False \n",
    "            potential_holes_for_mask_a = [] \n",
    "\n",
    "            for j, mask_data_b_comparison in enumerate(masks): \n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                mask_b = original_mask_segments_for_comparison[j] \n",
    "\n",
    "                if np.sum(mask_a_current_processing) > 0 and np.all(np.logical_and(mask_a_current_processing, mask_b) == mask_a_current_processing):\n",
    "                    is_completely_internal_to_another = True\n",
    "                    break \n",
    "\n",
    "                intersection_ab = np.logical_and(mask_b, mask_a_current_processing)\n",
    "                area_b = np.sum(mask_b)\n",
    "                area_intersection_ab = np.sum(intersection_ab)\n",
    "\n",
    "                if area_b > 0 and (np.all(intersection_ab == mask_b) or \\\n",
    "                                (area_intersection_ab / area_b > overlap_threshold and area_intersection_ab > 0)):\n",
    "                    if np.sum(mask_b) < np.sum(mask_a_current_processing) * 0.9: \n",
    "                        potential_holes_for_mask_a.append(mask_b)\n",
    "\n",
    "            if is_completely_internal_to_another:\n",
    "                display_title = f'Máscara {i + 1} (Interna - Sin cambios significativos)'\n",
    "            else:\n",
    "                hollowed = False\n",
    "                for hole_mask in potential_holes_for_mask_a:\n",
    "                    mask_a_current_processing = np.logical_and(mask_a_current_processing, np.logical_not(hole_mask))\n",
    "                    hollowed = True\n",
    "                \n",
    "                mask_data_a_processed[\"segmentation\"] = mask_a_current_processing \n",
    "                if hollowed:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Hueca)'\n",
    "                else:\n",
    "                    display_title = f'Máscara {i + 1} (Externa - Sin huecos significativos)'\n",
    "\n",
    "            final_processed_masks_data.append(mask_data_a_processed) \n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(image) \n",
    "            show_mask(mask_data_a_processed[\"segmentation\"], plt.gca(), random_color=True) \n",
    "            plt.axis('off')\n",
    "            plt.title(display_title)\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{filename_prefix}_processed_mask_{i + 1}.png\")\n",
    "            plt.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Máscara procesada {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "        print(\"Procesamiento jerárquico de máscaras completado.\")\n",
    "        return final_processed_masks_data \n",
    "\n",
    "    def apply_morphological_closing(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            return masks_list\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando cierre morfológico con kernel {kernel_size}x{kernel_size}...\")\n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_smoothed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_CLOSE, kernel)\n",
    "            mask_data['segmentation'] = (mask_smoothed_np > 0).astype(bool)\n",
    "        print(\"Suavizado de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    def apply_morphological_opening(masks_list, kernel_size=5):\n",
    "        if not masks_list:\n",
    "            print(\"La lista de máscaras está vacía, no se aplica la apertura morfológica.\")\n",
    "            return masks_list\n",
    "        \n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"Aplicando apertura morfológica con kernel {kernel_size}x{kernel_size}...\")\n",
    "        \n",
    "        for mask_data in masks_list:\n",
    "            mask_boolean = mask_data['segmentation']\n",
    "            if mask_boolean.dtype != bool:\n",
    "                mask_boolean = mask_boolean.astype(bool)\n",
    "\n",
    "            mask_np_255 = (mask_boolean * 255).astype(np.uint8)\n",
    "            mask_processed_np = cv2.morphologyEx(mask_np_255, cv2.MORPH_OPEN, kernel)\n",
    "            mask_data['segmentation'] = (mask_processed_np > 0).astype(bool)\n",
    "            \n",
    "        print(\"Suavizado (apertura) de máscaras completado.\")\n",
    "        return masks_list\n",
    "\n",
    "    try:\n",
    "        image_for_sam_np = np.array(Image.open(query_image_path).convert(\"RGB\"))\n",
    "        print(f\"Dimensiones imagen SAM: {image_for_sam_np.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando imagen para SAM: {e}. Saltando SAM.\")\n",
    "        sam2_model = None\n",
    "        \n",
    "    PROCESSED_MASKS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"processed_masks\")\n",
    "\n",
    "    if sam2_model is not None:\n",
    "        points_grid_density = 16\n",
    "        min_mask_area_pixels = 3000\n",
    "\n",
    "        mask_generator_query = SAM2AutomaticMaskGenerator(\n",
    "            model=sam2_model,\n",
    "            points_per_side=points_grid_density,\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.85,\n",
    "            stability_score_thresh=0.8,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=min_mask_area_pixels,\n",
    "        )\n",
    "        \n",
    "        masks_data_query_image = mask_generator_query.generate(image_for_sam_np)\n",
    "\n",
    "\n",
    "        min_area_threshold = 75000#100000 # Define tu umbral de área mínima\n",
    "        max_area_threshold = 120000\n",
    "        filtered_masks_data = []\n",
    "        for mask_data in masks_data_query_image:\n",
    "            mask_area = mask_data['area']  # El diccionario 'mask_data' ya contiene el área\n",
    "            if min_area_threshold <= mask_area <= max_area_threshold:\n",
    "                filtered_masks_data.append(mask_data)\n",
    "\n",
    "        masks_data_query_image = filtered_masks_data # Actualiza tu lista de máscaras\n",
    "        print(f\"Número de máscaras generadas DESPUÉS de filtrar (área >= {min_area_threshold}): {len(masks_data_query_image)}\")\n",
    "        for i, mask_data in enumerate(masks_data_query_image):\n",
    "            area = mask_data['area']\n",
    "            iou = mask_data.get('predicted_iou', 'N/A')  # Usar 'N/A' si no está disponible\n",
    "            stability_score = mask_data.get('stability_score', 'N/A')  # Usar 'N/A' si no está disponible\n",
    "            print(f\"Mascara {i + 1}: Area={area}, IOU={iou}, Stability Score={stability_score}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        def plot_individual_masks(masks_data, output_dir, filename_prefix=\"query_mask\", image_path=None):\n",
    "\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            if image_path:\n",
    "                try:\n",
    "                    image_original = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_np = np.array(image_original)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"No image path provided for overlay. Skipping.\")\n",
    "                return\n",
    "            \n",
    "            for i, mask_data in enumerate(masks_data):\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                mask_np = mask_data[\"segmentation\"]\n",
    "                plt.imshow(image_np)\n",
    "                show_mask(mask_np, plt.gca(), random_color=True)\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"Máscara {i + 1} - Área: {mask_data['area']}, IoU: {mask_data.get('predicted_iou', 'N/A')}\")\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"{filename_prefix}_{i + 1}.png\")\n",
    "                plt.savefig(output_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(f\"Máscara {i + 1} sobrepuesta guardada en: {output_path}\")\n",
    "\n",
    "        # Call the function to visualize and save the masks\n",
    "        plot_individual_masks(masks_data_query_image, PROCESSED_MASKS_DIR, filename_prefix=\"query_mask\", image_path=query_image_path)\n",
    "        \n",
    "        print(f\"Número de máscaras generadas DESPUÉS de filtrar (área >= {min_area_threshold}): {len(masks_data_query_image)}\")   \n",
    "        \n",
    "        mask_generator_similar = SAM2AutomaticMaskGenerator( \n",
    "            model=sam2_model,\n",
    "            points_per_side=16,#25\n",
    "            points_per_batch=128,\n",
    "            pred_iou_thresh=0.85,\n",
    "            stability_score_thresh=0.8,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=3000,\n",
    "        )\n",
    "\n",
    "        print(\"\\nGenerando máscaras SAM para imágenes similares...\")\n",
    "        # --- Start of your main processing loop ---\n",
    "        start_time_sam = time.time()\n",
    "        similar_masks_raw_list=[]\n",
    "        \n",
    "        for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "                    \n",
    "            try:\n",
    "                image_np_similar_for_sam = np.array(Image.open(similar_image_path).convert('RGB'))\n",
    "                print(f\"--- Procesando vecino {j+1}: {os.path.basename(similar_image_path)} ---\")\n",
    "                \n",
    "                # 1. Generate ALL masks for the current similar image\n",
    "                all_generated_masks = mask_generator_similar.generate(image_np_similar_for_sam)\n",
    "                \n",
    "                # 2. Initialize a NEW list to store only the FILTERED masks\n",
    "                filtered_similar_masks_data = []\n",
    "\n",
    "                # 3. Iterate over the ALL_GENERATED_MASKS and add to the NEW list if they pass the filter\n",
    "                for mask_data in all_generated_masks: # <--- CRUCIAL CHANGE HERE!\n",
    "                    mask_area = mask_data['area']\n",
    "                    if min_area_threshold <= mask_area <= max_area_threshold:\n",
    "                        filtered_similar_masks_data.append(mask_data) # <--- Appending to a DIFFERENT list!\n",
    "\n",
    "                print(f\"Número de máscaras generadas y filtradas (área >= {min_area_threshold}): {len(filtered_similar_masks_data)}\")\n",
    "                for i, mask_data in enumerate(filtered_similar_masks_data): # <--- Iterate over the filtered list\n",
    "                    area = mask_data['area']\n",
    "                    iou = mask_data.get('predicted_iou', 'N/A')\n",
    "                    stability_score = mask_data.get('stability_score', 'N/A')\n",
    "                    print(f\"Mascara {i + 1}: Area={area}, IOU={iou}, Stability Score={stability_score}\")\n",
    "                    \n",
    "                similar_masks_raw_list.append(filtered_similar_masks_data) # <--- Append the filtered list\n",
    "                \n",
    "                # Visualize and save individual masks overlaid on the similar images\n",
    "                def plot_masks_overlay_on_images(masks_data, image_path, output_dir, filename_prefix=\"similar_mask_overlay\"):\n",
    "                    \"\"\"\n",
    "                    Function to overlay masks on the original similar images and save them as images.\n",
    "\n",
    "                    Args:\n",
    "                        masks_data (list): List of mask data dictionaries containing 'segmentation', 'area', and 'predicted_iou'.\n",
    "                        image_path (str): Path to the original similar image.\n",
    "                        output_dir (str): Directory to save the overlay images.\n",
    "                        filename_prefix (str): Prefix for the saved overlay filenames.\n",
    "                    \"\"\"\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    try:\n",
    "                        image_original = Image.open(image_path).convert(\"RGB\")\n",
    "                        image_np = np.array(image_original)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {image_path}: {e}\")\n",
    "                        return\n",
    "\n",
    "                    for i, mask_data in enumerate(masks_data):\n",
    "                        plt.figure(figsize=(8, 8))\n",
    "                        mask_np = mask_data[\"segmentation\"]\n",
    "                        plt.imshow(image_np)\n",
    "                        show_mask(mask_np, plt.gca(), random_color=True)\n",
    "                        plt.axis('off')\n",
    "                        \n",
    "                        # Handling N/A for formatting\n",
    "                        iou_val = mask_data.get('predicted_iou', 'N/A')\n",
    "                        stability_val = mask_data.get('stability_score', 'N/A')\n",
    "                        iou_str = f\"{iou_val:.4f}\" if isinstance(iou_val, (int, float)) else str(iou_val)\n",
    "\n",
    "                        plt.title(f\"Máscara {i + 1} - Área: {mask_data['area']}, IoU: {iou_str}, Stability: {stability_val}\")\n",
    "\n",
    "                        # Use a more unique filename to avoid overwrites across different similar images\n",
    "                        # Assumes 'j' (index of the similar image) is accessible from the outer scope\n",
    "                        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                        output_path = os.path.join(output_dir, f\"{filename_prefix}_{base_filename}_mask_{i + 1}.png\")\n",
    "                        \n",
    "                        plt.savefig(output_path, bbox_inches='tight')\n",
    "                        plt.close()\n",
    "                        print(f\"Máscara {i + 1} sobrepuesta guardada en: {output_path}\")\n",
    "\n",
    "                # Call the function to overlay and save the masks for the current similar image\n",
    "                # Pass the filtered list and ensure a unique filename prefix\n",
    "                plot_masks_overlay_on_images(filtered_similar_masks_data, similar_image_path, PROCESSED_MASKS_DIR, filename_prefix=\"similar_mask_overlay\")\n",
    "                \n",
    "                print(f\"Máscaras procesadas para vecino {j+1}: {len(filtered_similar_masks_data)}.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando imagen similar {os.path.basename(similar_image_path)} para SAM: {e}\")\n",
    "                # It's usually a good idea to 'continue' here so the loop doesn't stop for one error\n",
    "                continue \n",
    "\n",
    "        end_time_sam = time.time()\n",
    "        print(f\"Tiempo total de ejecución de SAM: {end_time_sam - start_time_sam:.4f} segundos.\")\n",
    "\n",
    "        print(\"\\nAnálisis de SAM para una sola imagen completado.\")\n",
    "    \n",
    "    # Llamar a la función para procesar las máscaras de la query\n",
    "    # processed_masks_query = process_masks_with_hierarchy(image_for_sam_np, masks_data_query_image, PROCESSED_MASKS_DIR, \"query\")\n",
    "    # masks_data_query_image = processed_masks_query\n",
    "    # print(\"Shape de masks_data_query_image:\", len(masks_data_query_image))\n",
    "\n",
    "    #####################\n",
    "\n",
    "    # --- Implementación del punto 3.4.3. Object Feature Map ---\n",
    "    def process_masks_to_object_feature_maps(raw_masks, hr_feature_map, target_h, target_w, sam_processed_image_shape):\n",
    "        if not raw_masks:\n",
    "            print(\"Advertencia: No se encontraron máscaras para procesar. Devolviendo tensores vacíos.\")\n",
    "            C_dim = hr_feature_map.shape[0] if hr_feature_map.ndim >= 3 else 0\n",
    "            return torch.empty(0, C_dim, target_h, target_w, device=hr_feature_map.device), \\\n",
    "                torch.empty(0, 1, target_h, target_w, device=hr_feature_map.device)\n",
    "\n",
    "        object_feature_maps_list = []\n",
    "        scaled_mask_append = []\n",
    "        C_dim = hr_feature_map.shape[0] \n",
    "\n",
    "        for mask_info in raw_masks:\n",
    "            mask_np = mask_info['segmentation'].astype(np.float32)\n",
    "            mask_tensor_original_res = torch.from_numpy(mask_np).unsqueeze(0).unsqueeze(0) #(1,1,H,W)\n",
    "            mask_tensor_original_res = mask_tensor_original_res.to(hr_feature_map.device)\n",
    "\n",
    "            scaled_mask = F.interpolate(mask_tensor_original_res,\n",
    "                                        size=(target_h, target_w),\n",
    "                                        mode='bilinear',\n",
    "                                        align_corners=False)\n",
    "            scaled_mask = (scaled_mask > 0.5).float()\n",
    "            scaled_mask_append.append(scaled_mask)\n",
    "            \n",
    "            if hr_feature_map.ndim == 3:\n",
    "                hr_feature_map_with_batch = hr_feature_map.unsqueeze(0) #(1,C,W,H)\n",
    "            else: \n",
    "                hr_feature_map_with_batch = hr_feature_map\n",
    "\n",
    "            object_feature_map_i = scaled_mask * hr_feature_map_with_batch\n",
    "            object_feature_maps_list.append(object_feature_map_i)\n",
    "\n",
    "        final_object_feature_maps = torch.cat(object_feature_maps_list, dim=0) \n",
    "        final_scaled_masks = torch.cat(scaled_mask_append, dim=0)\n",
    "        \n",
    "        return final_object_feature_maps, final_scaled_masks\n",
    "\n",
    "    # --- Visualización de Mapas de Características de Objeto ---\n",
    "    def visualize_object_feature_map(original_image_path, sam_mask_info, hr_feature_map_tensor,\n",
    "                                    object_feature_map_tensor, target_h, target_w,\n",
    "                                    plot_save_dir, plot_filename_prefix, mask_idx,\n",
    "                                    sam_processed_image_shape):\n",
    "        try:\n",
    "            original_img = Image.open(original_image_path).convert(\"RGB\")\n",
    "            sam_mask_np = sam_mask_info['segmentation']\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "            axes[0].imshow(original_img)\n",
    "            axes[0].set_title(f'Imagen Original\\n{os.path.basename(original_image_path)}')\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            mask_display = sam_mask_np \n",
    "            axes[1].imshow(original_img) \n",
    "            show_mask(mask_display, axes[1], random_color=False, borders=True) \n",
    "            axes[1].set_title(f'Máscara SAM {mask_idx}')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            if object_feature_map_tensor.numel() == 0:\n",
    "                axes[2].text(0.5, 0.5, \"No hay características de objeto\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                axes[2].set_title('Mapa de Características de Objeto (Vacío)')\n",
    "                axes[2].axis('off')\n",
    "            else:\n",
    "                ofm_cpu = object_feature_map_tensor.squeeze().cpu().numpy() \n",
    "                if ofm_cpu.ndim == 3: \n",
    "                    C, H, W = ofm_cpu.shape\n",
    "                    ofm_reshaped = ofm_cpu.transpose(1, 2, 0).reshape(-1, C) \n",
    "\n",
    "                    if C > 3: \n",
    "                        pca = PCA(n_components=3)\n",
    "                        ofm_pca = pca.fit_transform(ofm_reshaped)\n",
    "                        ofm_pca_normalized = (ofm_pca - ofm_pca.min()) / (ofm_pca.max() - ofm_pca.min() + 1e-8)\n",
    "                        ofm_display = ofm_pca_normalized.reshape(H, W, 3)\n",
    "                        axes[2].imshow(ofm_display)\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto (PCA)\\nMáscara {mask_idx}')\n",
    "                    else: \n",
    "                        if C == 1:\n",
    "                            ofm_display = ofm_cpu.squeeze()\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        elif C == 3:\n",
    "                            ofm_display = ofm_cpu.transpose(1, 2, 0) \n",
    "                            ofm_display_norm = (ofm_display - ofm_display.min()) / (ofm_display.max() - ofm_display.min() + 1e-8)\n",
    "                            axes[2].imshow(ofm_display_norm)\n",
    "                        else: \n",
    "                            ofm_display = ofm_cpu[0]\n",
    "                            axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                        axes[2].set_title(f'Mapa de Características de Objeto\\nMáscara {mask_idx}')\n",
    "                else: \n",
    "                    axes[2].text(0.5, 0.5, \"Formato de características de objeto inesperado\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                    axes[2].set_title('Mapa de Características de Objeto (Error)')\n",
    "\n",
    "                axes[2].axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{plot_filename_prefix}_mask_{mask_idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al visualizar el mapa de características de objeto para máscara {mask_idx} de {os.path.basename(original_image_path)}: {e}\")\n",
    "\n",
    "    # --- Aplicar el proceso a la imagen de consulta y a las imágenes de referencia ---\n",
    "\n",
    "    print(\"\\n--- Generando Mapas de Características de Objeto ---\")\n",
    "\n",
    "    TARGET_MASK_H = 8 * H_prime \n",
    "    TARGET_MASK_W = 8 * W_prime \n",
    "    print(f\"TARGET_MASK_H: {TARGET_MASK_H}\")\n",
    "    print(f\"TARGET_MASK_W: {TARGET_MASK_W}\")\n",
    "\n",
    "    fobj_q, scaled_masks_query = process_masks_to_object_feature_maps(\n",
    "        masks_data_query_image,\n",
    "        query_hr_feats.squeeze(0), \n",
    "        TARGET_MASK_H,\n",
    "        TARGET_MASK_W,\n",
    "        image_for_sam_np.shape \n",
    "    )\n",
    "\n",
    "    fobj_q = fobj_q.to(device)\n",
    "\n",
    "    print(f\"Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): {fobj_q.shape}\") \n",
    "\n",
    "    all_fobj_r_list = [] \n",
    "    for i, similar_hr_feats in enumerate(similar_hr_feats_list):\n",
    "        current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "        img_similar_pil = Image.open(rutas_imagenes_similares[i]).convert('RGB') \n",
    "        image_np_similar_for_sam_shape = np.array(img_similar_pil).shape\n",
    "\n",
    "        fobj_r_current, scaled_masks_similar = process_masks_to_object_feature_maps(\n",
    "            current_similar_masks_raw,\n",
    "            similar_hr_feats.squeeze(0), \n",
    "            TARGET_MASK_H,\n",
    "            TARGET_MASK_W,\n",
    "            image_np_similar_for_sam_shape \n",
    "        )\n",
    "        fobj_r_current = fobj_r_current.to(device)\n",
    "        \n",
    "        all_fobj_r_list.append(fobj_r_current)\n",
    "        print(f\"Dimensiones de fobj_r para vecino {i+1}: {fobj_r_current.shape}\") \n",
    "        print(\"\\nTipos de los elementos en all_fobj_r_list:\")\n",
    "        for idx, fobj_r in enumerate(all_fobj_r_list):\n",
    "            print(f\"Vecino {idx + 1}: Tipo de fobj_r:\", type(fobj_r))\n",
    "    print(\"\\nProceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\")\n",
    "\n",
    "\n",
    "    # -----------3.5.2 Object matching module-----------------\n",
    "    ## Matching\n",
    "    # --- Definición de la función show_anomalies_on_image ---\n",
    "    def show_anomalies_on_image(image_np, masks, anomalous_info, alpha=0.5, save_path=None):\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image_np)\n",
    "\n",
    "        for obj_id, similarity in anomalous_info: # Iterate through (id, similarity) tuples\n",
    "            # Extraer la máscara binaria real\n",
    "            mask = masks[obj_id]['segmentation']\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "\n",
    "            # Crear máscara en rojo\n",
    "            colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "            colored_mask[mask > 0] = [255, 0, 0]\n",
    "            plt.imshow(colored_mask, alpha=alpha)\n",
    "\n",
    "            # Calcular centroide para colocar el texto\n",
    "            ys, xs = np.where(mask > 0)\n",
    "            if len(xs) > 0 and len(ys) > 0:\n",
    "                cx = int(xs.mean())\n",
    "                cy = int(ys.mean())\n",
    "                \n",
    "                # Create text with index and percentage\n",
    "                text_label = f\"{obj_id} ({similarity*100:.2f}%)\"\n",
    "                plt.text(cx, cy, text_label, color='white', fontsize=10, fontweight='bold', ha='center', va='center',\n",
    "                        bbox=dict(facecolor='red', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "        plt.title(\"Objetos Anómalos en Rojo con Índice y Similitud\") # Updated title for clarity\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de anomalías guardado en: {save_path}\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    # --- Fin de la definición de la función show_anomalies_on_image ---\n",
    "    # --- Nuevas funciones de ploteo para la matriz P y P_augmented_full ---\n",
    "    def plot_assignment_matrix(P_matrix, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación P\"):\n",
    "\n",
    "        if isinstance(P_matrix, torch.Tensor):\n",
    "            #P_matrix = P_matrix.cpu().numpy()\n",
    "            P_matrix = P_matrix.detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(P_matrix.shape[1] * 0.8 + 2, P_matrix.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_matrix, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(reference_labels)), reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(query_labels)), query_labels)\n",
    "        plt.xlabel('Objetos de Referencia')\n",
    "        plt.ylabel('Objetos de Consulta')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_augmented_assignment_matrix(P_augmented_full, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación Aumentada (con Trash Bin)\"):\n",
    "\n",
    "        if isinstance(P_augmented_full, torch.Tensor):\n",
    "            #P_augmented_full = P_augmented_full.cpu().numpy()\n",
    "            P_augmented_full = P_augmented_full.detach().cpu().numpy()\n",
    "\n",
    "        # Añadir etiquetas para los trash bins\n",
    "        full_query_labels = [f\"Q_{i}\" for i in query_labels] + [\"Trash Bin (Q)\"]\n",
    "        full_reference_labels = [f\"R_{i}\" for i in reference_labels] + [\"Trash Bin (R)\"]\n",
    "\n",
    "        plt.figure(figsize=(P_augmented_full.shape[1] * 0.8 + 2, P_augmented_full.shape[0] * 0.8 + 2))\n",
    "        plt.imshow(P_augmented_full, cmap='viridis', origin='upper', aspect='auto')\n",
    "        plt.colorbar(label='Probabilidad de Asignación')\n",
    "        plt.xticks(np.arange(len(full_reference_labels)), full_reference_labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(np.arange(len(full_query_labels)), full_query_labels)\n",
    "        plt.xlabel('Objetos de Referencia y Trash Bin')\n",
    "        plt.ylabel('Objetos de Consulta y Trash Bin')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"✅ Plot de la matriz de asignación aumentada guardado en: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# --- Fin de las nuevas funciones de ploteo ---\n",
    "\n",
    "    ## Matching-continue---\n",
    "    ## Matching\n",
    "    start_time_sam_matching = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    def apply_global_max_pool(feat_map):\n",
    "        return F.adaptive_max_pool2d(feat_map, output_size=1).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    class SimpleObjectMatchingModule(nn.Module):\n",
    "        def __init__(self, sinkhorn_iterations=100, sinkhorn_epsilon=0.1, bin_score_value=0.5):\n",
    "            super(SimpleObjectMatchingModule, self).__init__()\n",
    "            self.sinkhorn_iterations = sinkhorn_iterations\n",
    "            self.sinkhorn_epsilon = sinkhorn_epsilon\n",
    "            self.z = nn.Parameter(torch.tensor(bin_score_value, dtype=torch.float32))\n",
    "\n",
    "        def forward(self, d_M_q, d_N_r):\n",
    "            M = d_M_q.shape[0]\n",
    "            N = d_N_r.shape[0]\n",
    "\n",
    "            if M == 0 or N == 0:\n",
    "                return torch.empty(M, N, device=d_M_q.device), \\\n",
    "                    torch.empty(M+1, N+1, device=d_M_q.device)\n",
    "\n",
    "            score_matrix = torch.mm(d_M_q, d_N_r.T)\n",
    "            #print(\"score_matrix (antes de Sinkhorn):\\n\", score_matrix)\n",
    "\n",
    "            S_augmented = torch.zeros((M + 1, N + 1), device=d_M_q.device, dtype=d_M_q.dtype)\n",
    "            S_augmented[:M, :N] = score_matrix\n",
    "            S_augmented[:M, N] = self.z\n",
    "            S_augmented[M, :N] = self.z\n",
    "            S_augmented[M, N] = self.z\n",
    "            print(\"S_augmented antes de Sinkhorn:\\n\", S_augmented)\n",
    "\n",
    "            K = torch.exp(S_augmented / self.sinkhorn_epsilon)\n",
    "            print(\"K (antes de Sinkhorn):\\n\", K)\n",
    "            \n",
    "\n",
    "            for i in range(self.sinkhorn_iterations):\n",
    "                K = K / K.sum(dim=1, keepdim=True)\n",
    "                K = K / K.sum(dim=0, keepdim=True)\n",
    "                #print(f\"Iteración {i+1}: K.shape = {K}\")\n",
    "\n",
    "            P_augmented_full = K\n",
    "            P = P_augmented_full[:M, :N]\n",
    "\n",
    "            return P, P_augmented_full\n",
    "\n",
    "    if fobj_q.shape[0] == 0:\n",
    "        print(\"Advertencia: fobj_q tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "        continue\n",
    "\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        if fobj_r_current.shape[0] == 0:\n",
    "            print(\"Advertencia: fobj_r_current tiene dimensión C=0. Saltando a la siguiente iteración.\")\n",
    "            continue\n",
    "    \n",
    "    fobj_q_pooled = apply_global_max_pool(fobj_q)\n",
    "    print(\"Shape de fobj_q_pooled:\", fobj_q_pooled.shape)\n",
    "    print(\"Máximo de fobj_q_pooled:\", torch.max(fobj_q_pooled).item())\n",
    "    print(\"Mínimo de fobj_q_pooled:\", torch.min(fobj_q_pooled).item())\n",
    "\n",
    "    all_fobj_r_pooled_list = []\n",
    "    for fobj_r_current in all_fobj_r_list:\n",
    "        pooled_r = apply_global_max_pool(fobj_r_current)\n",
    "        all_fobj_r_pooled_list.append(pooled_r)\n",
    "        \n",
    "    d_M_q = F.normalize(fobj_q_pooled, p=2, dim=1) #shape (M, C)\n",
    "    d_N_r_list = [F.normalize(fobj_r_pooled, p=2, dim=1) \n",
    "                                for fobj_r_pooled in all_fobj_r_pooled_list]\n",
    "    print(\"Máximo de d_M_q:\", torch.max(d_M_q).item())\n",
    "    print(\"Mínimo de d_M_q:\", torch.min(d_M_q).item())\n",
    "\n",
    "    object_matching_module = SimpleObjectMatchingModule(\n",
    "        sinkhorn_iterations=100,\n",
    "        sinkhorn_epsilon=0.1,\n",
    "        bin_score_value=0.9 #2.36\n",
    "    ).to(device)\n",
    "\n",
    "    P_matrices = []\n",
    "    P_augmented_full_matrices = []\n",
    "\n",
    "    for i, d_N_r_current_image in enumerate(d_N_r_list):\n",
    "        d_M_q_cuda = d_M_q.to(device)\n",
    "        d_N_r_current_image_cuda = d_N_r_current_image.to(device)\n",
    "\n",
    "        P_current, P_augmented_current = object_matching_module(d_M_q_cuda, d_N_r_current_image_cuda)\n",
    "        P_matrices.append(P_current)\n",
    "        P_augmented_full_matrices.append(P_augmented_current)\n",
    "\n",
    "\n",
    "    print(\"\\n--- Matrices P y P_augmented_full generadas ---\")\n",
    "    # --- NUEVOS DICCIONARIOS CONSOLIDADOS ---\n",
    "    # Almacenarán para cada query_idx, las referencias que le corresponden de TODOS los vecinos.\n",
    "    M = d_M_q.shape[0]\n",
    "    all_matched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)} # M es el número de objetos de consulta (Iq)\n",
    "    all_closest_unmatched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)}\n",
    "    # Imprimir shapes de los diccionarios consolidados\n",
    "    #//////\n",
    "    print(\"\\n--- Resultados Consolidados ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj:\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Objeto de Consulta {q_idx}: {closest_unmatches}\")\n",
    "    #/////////////////\n",
    "    # Procesar matrices P y P_augmented_full para obtener índices\n",
    "    for i, (P, P_augmented_full) in enumerate(zip(P_matrices, P_augmented_full_matrices)):\n",
    "        current_neighbor_key = f\"Vecino_{i+1}\"\n",
    "        N_current = P.shape[1] \n",
    "\n",
    "        print(f\"\\n--- Vecino {current_neighbor_key} ---\")\n",
    "        print(f\"Matriz P (MxN) para el vecino {current_neighbor_key}:\")\n",
    "        print(P)\n",
    "        print(f\"Matriz P_augmented_full (M+1 x N+1) para el vecino {current_neighbor_key}:\")\n",
    "        print(P_augmented_full)\n",
    "\n",
    "        # Imprimir sumas de filas y columnas de P_augmented_full\n",
    "        augmented_with_totals = torch.cat([\n",
    "            torch.cat([P_augmented_full, P_augmented_full.sum(dim=0, keepdim=True)], dim=0),\n",
    "            torch.cat([P_augmented_full.sum(dim=1, keepdim=True), P_augmented_full.sum().unsqueeze(0).unsqueeze(0)], dim=0)\n",
    "        ], dim=1)\n",
    "        print(f\"Matriz P_augmented_full con totales (M+2 x N+2):\\n{augmented_with_totals}\")\n",
    "\n",
    "        print(f\"\\n--- Decisiones de Emparejamiento para el Vecino {current_neighbor_key} ---\")\n",
    "        for obj_idx in range(P.shape[0]):\n",
    "            \n",
    "            # Obtener la probabilidad más alta dentro de P y su índice\n",
    "            if N_current > 0:\n",
    "                max_prob_P = P[obj_idx].max().item()\n",
    "                max_idx_P = P[obj_idx].argmax().item()\n",
    "            else:\n",
    "                max_prob_P = -float('inf')\n",
    "                max_idx_P = -1\n",
    "\n",
    "            trash_bin_prob = P_augmented_full[obj_idx, -1].item() \n",
    "\n",
    "            print(f\"   Objeto de Consulta {obj_idx}:\")\n",
    "            print(f\"     Probabilidad máxima en P: {max_prob_P:.4f} en el índice {max_idx_P}\")\n",
    "            print(f\"     Probabilidad en el 'Trash Bin': {trash_bin_prob:.4f}\")\n",
    "\n",
    "\n",
    "        # Decisión y almacenamiento en los diccionarios consolidados\n",
    "            if trash_bin_prob > max_prob_P:\n",
    "                # Desemparejado: ahora añadimos el 'primer máximo' a la lista de ese objeto de consulta\n",
    "                if max_idx_P != -1: # Solo añadir si hay un 'primer máximo' válido\n",
    "                    all_closest_unmatched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto {max_idx_P}\")\n",
    "            else:\n",
    "                # Emparejado: añadir el emparejamiento real a la lista de ese objeto de consulta\n",
    "                all_matched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "                print(f\"     Decisión: EMPAREJADO con objeto de imagen {max_idx_P}\")\n",
    "\n",
    "\n",
    "    # --- Resultados Finales Consolidados ---\n",
    "    print(\"\\n--- Resultados Finales Consolidados (Índices) ---\")\n",
    "    print(\"all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\")\n",
    "    for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {matches}\")\n",
    "\n",
    "    print(\"\\nall_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\")\n",
    "    for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "        print(f\"  Query {q_idx}: {closest_unmatches}\")\n",
    "\n",
    "\n",
    "    # --- AHORA SE NECESITAN ESTOS DICTIONARIOS PARA TU IMPLEMENTACIÓN DE MAHALANOBIS ---\n",
    "    # amm\n",
    "    print(\"--- FIN DE LÓGICA DE EMPAREJAMIENTO DE DEMOSTRACIÓN ---\")\n",
    "    # --- Utility Functions ---\n",
    "\n",
    "    def percentile_normalize(data_tensor, percentile_cap=99.0):\n",
    "        # This function is for visualization, so if it receives NaN/Inf, it should handle them\n",
    "        # gracefully rather than discarding, to still show what's valid.\n",
    "        if data_tensor.numel() == 0 or data_tensor.max() == data_tensor.min():\n",
    "            return torch.zeros_like(data_tensor)\n",
    "\n",
    "        data_np = data_tensor.cpu().numpy()\n",
    "        \n",
    "        # Clean NaN/Inf for percentile calculation to avoid errors in np.percentile\n",
    "        if np.isnan(data_np).any() or np.isinf(data_np).any():\n",
    "            data_np_cleaned = np.nan_to_num(data_np, nan=0.0, posinf=data_np[np.isfinite(data_np)].max() if np.isfinite(data_np).any() else 0.0, neginf=data_np[np.isfinite(data_np)].min() if np.isfinite(data_np).any() else 0.0)\n",
    "            # Using max/min of finite values for inf to keep scale, or 0 if no finite values.\n",
    "            print(f\"WARNING: NaN/Inf detected in data for percentile normalization. Cleaning for visualization.\")\n",
    "            data_np = data_np_cleaned\n",
    "\n",
    "        p_min = np.percentile(data_np, 1.0)\n",
    "        p_max = np.percentile(data_np, percentile_cap)\n",
    "\n",
    "        if p_max <= p_min + 1e-8:\n",
    "            return torch.zeros_like(data_tensor)\n",
    "\n",
    "        normalized_tensor = (data_tensor - p_min) / (p_max - p_min)\n",
    "        normalized_tensor = torch.clamp(normalized_tensor, 0.0, 1.0)\n",
    "        return normalized_tensor\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_mahalanobis_map_single(query_fmap, ref_fmaps, regularization=1e-5, pixel_batch_size=4096):\n",
    "        device = query_fmap.device\n",
    "        k = len(ref_fmaps)\n",
    "        C, H, W = query_fmap.shape\n",
    "\n",
    "        if k < 2:\n",
    "            # Returning a map of zeros, but you could also return None to indicate invalid\n",
    "            # For now, stick to zeros as it's cleaner for subsequent processing, and let\n",
    "            # the calling function decide to discard based on this or actual NaN/Inf later.\n",
    "            return torch.zeros(H, W, device=device, dtype=torch.float32)\n",
    "\n",
    "        query_fmap_float32 = query_fmap.to(torch.float32)\n",
    "        ref_fmaps_float32 = [fmap.to(torch.float32) for fmap in ref_fmaps]\n",
    "\n",
    "        ref_stack = torch.stack(ref_fmaps_float32, dim=0).permute(0, 2, 3, 1)\n",
    "        query_fmap_permuted = query_fmap_float32.permute(1, 2, 0)\n",
    "\n",
    "        N_pixels = H * W\n",
    "        ref_vectors_flat = ref_stack.reshape(k, N_pixels, C)\n",
    "        query_vectors_flat = query_fmap_permuted.reshape(N_pixels, C)\n",
    "\n",
    "        mu = ref_vectors_flat.mean(dim=0)\n",
    "        \n",
    "        maha_map_flat = torch.zeros(N_pixels, device=device, dtype=torch.float32)\n",
    "\n",
    "        for i in range(0, N_pixels, pixel_batch_size):\n",
    "            end_idx = min(i + pixel_batch_size, N_pixels)\n",
    "            current_pixel_batch_size = end_idx - i\n",
    "\n",
    "            mu_batch = mu[i:end_idx]\n",
    "            query_vectors_flat_batch = query_vectors_flat[i:end_idx]\n",
    "            \n",
    "            delta_batch = ref_vectors_flat[:, i:end_idx, :] - mu_batch.unsqueeze(0)\n",
    "            delta_reshaped_batch = delta_batch.permute(1, 0, 2)\n",
    "            cov_batch = (delta_reshaped_batch.transpose(-1, -2) @ delta_reshaped_batch) / (k - 1)\n",
    "            \n",
    "            cov_batch += regularization * torch.eye(C, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            try:\n",
    "                cov_inv_batch = torch.linalg.inv(cov_batch)\n",
    "            except RuntimeError:\n",
    "                # If inverse fails, these pixels are problematic, return a \"problem\" value\n",
    "                maha_map_flat[i:end_idx] = float('nan') # Mark as NaN\n",
    "                continue\n",
    "\n",
    "            diff_batch = query_vectors_flat_batch - mu_batch\n",
    "            maha_val_squared_batch = (diff_batch.unsqueeze(1) @ cov_inv_batch @ diff_batch.unsqueeze(2)).squeeze()\n",
    "            \n",
    "            maha_map_flat[i:end_idx] = torch.sqrt(torch.relu(maha_val_squared_batch))\n",
    "            \n",
    "            del mu_batch, query_vectors_flat_batch, delta_batch, delta_reshaped_batch, cov_batch, cov_inv_batch, diff_batch, maha_val_squared_batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        maha_map = maha_map_flat.reshape(H, W)\n",
    "        \n",
    "        # Crucial change: Don't clean here. Let the caller decide to discard.\n",
    "        # We only check if it contains NaN/Inf.\n",
    "        if torch.isnan(maha_map).any() or torch.isinf(maha_map).any():\n",
    "            print(f\"DEBUG: NaN/Inf detected in raw Mahalanobis map (shape {maha_map.shape}). This map will be marked for potential discard by caller.\")\n",
    "            # Return the map as is, with NaNs/Infs, so the caller can check it.\n",
    "        \n",
    "        return maha_map\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def compute_matching_score_map(\n",
    "        fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        matching_maha_maps = []\n",
    "        all_raw_maha_values = [] \n",
    "        \n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx]\n",
    "            device = query_fmap.device\n",
    "\n",
    "            matched_ref_fmaps_list = []\n",
    "            for neighbor_idx, ref_idx in all_matched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                matched_ref_fmaps_list.append(ref_fmap)\n",
    "                \n",
    "            if len(matched_ref_fmaps_list) >= 2:\n",
    "                maha_map_raw = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=matched_ref_fmaps_list,\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            else:\n",
    "                map_H, map_W = query_fmap.shape[1], query_fmap.shape[2]\n",
    "                maha_map_raw = torch.zeros((map_H, map_W), device=device) # Assign zero if less than two matches\n",
    "            \n",
    "            # Check here: If the map is invalid, do NOT add it to the list\n",
    "            if torch.isnan(maha_map_raw).any() or torch.isinf(maha_map_raw).any():\n",
    "                print(f\"WARNING: Discarding Matching Score Map for Query Object {query_idx} due to NaN/Inf values.\")\n",
    "                # Do not append this map\n",
    "            else:\n",
    "                all_raw_maha_values.append(maha_map_raw.flatten().cpu()) \n",
    "                matching_maha_maps.append(maha_map_raw.cpu())\n",
    "\n",
    "                if plot_save_dir:\n",
    "                    plt.figure(figsize=(6, 5))\n",
    "                    maha_map_for_plot = matching_maha_maps[-1] # This map is guaranteed to be clean\n",
    "                    plot_normalized_maha = percentile_normalize(maha_map_for_plot, percentile_cap=99.0)\n",
    "                    plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                    plt.title(f\"Matching Score Map (Percentile Normalized) - Obj {query_idx}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                    plt.tight_layout()\n",
    "                    save_path = os.path.join(plot_save_dir, f\"matching_score_percentile_norm_obj_{query_idx}.png\")\n",
    "                    plt.savefig(save_path)\n",
    "                    plt.close()\n",
    "\n",
    "        global_min_maha = 0.0\n",
    "        global_max_maha = 1.0\n",
    "\n",
    "        if all_raw_maha_values:\n",
    "            combined_raw_values = torch.cat(all_raw_maha_values)\n",
    "            global_min_maha = combined_raw_values.min().item()\n",
    "            global_max_maha = combined_raw_values.max().item()\n",
    "            if global_max_maha <= global_min_maha:\n",
    "                global_max_maha = global_min_maha + 1e-8 \n",
    "\n",
    "        return matching_maha_maps, (global_min_maha, global_max_maha)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_unmatched_score_map(\n",
    "        fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list,\n",
    "        regularization=1e-5,\n",
    "        plot_save_dir=None,\n",
    "        pixel_batch_size=4096\n",
    "        ):\n",
    "        \n",
    "        unmatched_maha_maps = []\n",
    "\n",
    "        for query_idx in range(len(fobj_q)):\n",
    "            query_fmap = fobj_q[query_idx] \n",
    "            device = query_fmap.device\n",
    "            map_H, map_W = query_fmap.shape[1], query_fmap.shape[2] \n",
    "\n",
    "            closest_ref_fmaps = []\n",
    "            for neighbor_idx, ref_idx in all_closest_unmatched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "                ref_fmap_closest = all_fobj_r_list[neighbor_idx][ref_idx].to(device)\n",
    "                closest_ref_fmaps.append(ref_fmap_closest)\n",
    "\n",
    "            if len(closest_ref_fmaps) < 2:\n",
    "                maha_map_to_return = torch.zeros((map_H, map_W), device=device)\n",
    "            else:\n",
    "                maha_map_to_return = compute_mahalanobis_map_single(\n",
    "                    query_fmap=query_fmap,\n",
    "                    ref_fmaps=closest_ref_fmaps,\n",
    "                    regularization=regularization,\n",
    "                    pixel_batch_size=pixel_batch_size\n",
    "                )\n",
    "            \n",
    "            # Check here: If the map is invalid, do NOT add it to the list\n",
    "            if torch.isnan(maha_map_to_return).any() or torch.isinf(maha_map_to_return).any():\n",
    "                print(f\"WARNING: Discarding Unmatched Score Map for Query Object {query_idx} due to NaN/Inf values.\")\n",
    "                # Do not append this map\n",
    "            else:\n",
    "                unmatched_maha_maps.append(maha_map_to_return.cpu())\n",
    "\n",
    "                if plot_save_dir:\n",
    "                    plt.figure(figsize=(6, 5))\n",
    "                    maha_map_for_plot = unmatched_maha_maps[-1] # This map is guaranteed to be clean\n",
    "                    plot_normalized_maha = percentile_normalize(maha_map_for_plot, percentile_cap=99.0)\n",
    "                    plt.imshow(plot_normalized_maha.numpy(), cmap=\"hot\")\n",
    "                    plt.title(f\"Unmatched Anomaly Map (Percentile Normalized) - Obj {query_idx}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.colorbar(label=\"Normalized Mahalanobis Distance (for display)\")\n",
    "                    plt.tight_layout()\n",
    "                    save_path = os.path.join(plot_save_dir, f\"unmatched_anomaly_percentile_norm_obj_{query_idx}.png\")\n",
    "                    plt.savefig(save_path)\n",
    "                    plt.close()\n",
    "\n",
    "        return unmatched_maha_maps\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def build_aggregated_score_map(individual_score_maps_list, final_size=(1024, 1024), title_prefix=\"Global Score Map\", plot_save_dir=None, filename_prefix=\"global_score_map\"):\n",
    "\n",
    "        H_out, W_out = final_size\n",
    "        aggregated_score_map = torch.zeros((H_out, W_out), device='cpu') \n",
    "\n",
    "        if not individual_score_maps_list:\n",
    "            print(f\"INFO: No valid individual score maps to aggregate for '{title_prefix}'. Returning empty map.\")\n",
    "            return aggregated_score_map\n",
    "        \n",
    "        for i, score_map in enumerate(individual_score_maps_list):\n",
    "            if torch.isnan(score_map).any() or torch.isinf(score_map).any():\n",
    "                print(f\"CRITICAL WARNING: NaN/Inf detectado en un mapa de puntuación individual {i} después de verificaciones. Saltando.\")\n",
    "                continue\n",
    "                \n",
    "            if score_map.dim() == 2:\n",
    "                score_map_tensor = score_map.unsqueeze(0).unsqueeze(0) \n",
    "            else:\n",
    "                print(f\"WARNING: El mapa de puntuación individual {i} tiene dimensiones inesperadas {score_map.dim()}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            score_resized = F.interpolate(\n",
    "                score_map_tensor.to('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "                size=(H_out, W_out),\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            ).squeeze().cpu()\n",
    "            \n",
    "            aggregated_score_map += score_resized\n",
    "            #aggregated_score_map = torch.max(aggregated_score_map, score_resized)\n",
    "        \n",
    "        # Aplicación del filtro Gaussiano con sigma = 10.0 (MUCHO más agresivo)\n",
    "        aggregated_score_map_for_blur = aggregated_score_map.unsqueeze(0)\n",
    "        \n",
    "        # Kernel size para sigma = 10.0: (6 * 10) + 1 = 61\n",
    "        gaussian_blur_kernel_size = 61 \n",
    "        \n",
    "        gaussian_blur = T.GaussianBlur(kernel_size=(gaussian_blur_kernel_size, gaussian_blur_kernel_size), sigma=(10.0, 10.0)) # Sigma 10.0\n",
    "        \n",
    "        aggregated_score_map_smoothed = gaussian_blur(aggregated_score_map_for_blur)\n",
    "        \n",
    "        aggregated_score_map = aggregated_score_map_smoothed.squeeze(0)\n",
    "\n",
    "        \n",
    "        # # Aplicación del filtro Gaussiano\n",
    "        # aggregated_score_map_for_blur = aggregated_score_map.unsqueeze(0)\n",
    "        \n",
    "        # gaussian_blur_kernel_size = 19 \n",
    "        \n",
    "        # gaussian_blur = T.GaussianBlur(kernel_size=(gaussian_blur_kernel_size, gaussian_blur_kernel_size), sigma=(3.0, 3.0))\n",
    "        \n",
    "        # aggregated_score_map_smoothed = gaussian_blur(aggregated_score_map_for_blur)\n",
    "        \n",
    "        # aggregated_score_map = aggregated_score_map_smoothed.squeeze(0)\n",
    "\n",
    "        # Verificación final y limpieza después de la agregación y el suavizado\n",
    "        if torch.isnan(aggregated_score_map).any() or torch.isinf(aggregated_score_map).any():\n",
    "            print(f\"ADVERTENCIA CRÍTICA: NaN/Inf detectado en el mapa de puntuación agregado '{title_prefix}' después de la agregación y suavizado. Limpiando para la salida.\")\n",
    "            aggregated_score_map = torch.nan_to_num(aggregated_score_map, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if plot_save_dir:\n",
    "            os.makedirs(plot_save_dir, exist_ok=True)\n",
    "            \n",
    "            plt.figure(figsize=(8, 7))\n",
    "            map_for_plot = aggregated_score_map \n",
    "            plot_normalized_map = percentile_normalize(map_for_plot, percentile_cap=99.0)\n",
    "\n",
    "            plt.imshow(plot_normalized_map.numpy(), cmap=\"hot\")\n",
    "            plt.title(title_prefix + \" (Normalizado por Percentil & Suavizado)\") \n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Puntuación Acumulada (Normalizada para visualización)\")\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_prefix}_percentile_norm_smoothed.png\") \n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "\n",
    "        return aggregated_score_map\n",
    "\n",
    "\n",
    "\n",
    "    def overlay_anomaly_map_on_image(image_rgb_path, anomaly_map, alpha=0.7, cmap='magma', plot_save_dir=None, filename_suffix=\"overlay\"):\n",
    "        try:\n",
    "            image_original_loaded = Image.open(image_rgb_path).convert(\"RGB\")\n",
    "            image_np = np.array(image_original_loaded)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Image not found at {image_rgb_path}. Cannot overlay anomaly map.\")\n",
    "            return\n",
    "\n",
    "        if isinstance(anomaly_map, torch.Tensor):\n",
    "            anomaly_np = anomaly_map.cpu().numpy()\n",
    "        else:\n",
    "            anomaly_np = anomaly_map\n",
    "\n",
    "        # Ensure anomaly_np is clean before sending to percentile_normalize for plotting\n",
    "        if np.isnan(anomaly_np).any() or np.isinf(anomaly_np).any():\n",
    "            print(f\"WARNING: NaN/Inf detected in anomaly map for overlay. Cleaning up for visualization.\")\n",
    "            anomaly_np = np.nan_to_num(anomaly_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        anomaly_norm = percentile_normalize(torch.from_numpy(anomaly_np), percentile_cap=99.0).numpy()\n",
    "\n",
    "        if anomaly_norm.shape[:2] != image_np.shape[:2]:\n",
    "            anomaly_norm = np.array(Image.fromarray(anomaly_norm).resize(\n",
    "                (image_np.shape[1], image_np.shape[0]), resample=Image.BILINEAR\n",
    "            ))\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(image_np)\n",
    "        plt.imshow(anomaly_norm, cmap=cmap, alpha=alpha)\n",
    "        plt.title(\"Anomaly Heatmap Overlay (Percentile Normalized)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if plot_save_dir:\n",
    "            save_path = os.path.join(plot_save_dir, f\"{filename_suffix}_percentile_norm.png\")\n",
    "            plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "    # --- Main script execution ---\n",
    "    # (Variables like PLOT_SAVE_ROOT_DIR, MAHALANOBIS_SCORE_MAPS_DIR,\n",
    "    # query_image_path, base_image_name, fobj_q, all_fobj_r_list,\n",
    "    # all_matched_ref_indices_by_query_obj, all_closest_unmatched_ref_indices_by_query_obj\n",
    "    # should be defined in your execution environment)\n",
    "\n",
    "    print(\"--- INICIO DE PROCESAMIENTO DE ANOMALÍAS ---\")\n",
    "\n",
    "    # Assuming start_time_total is defined here or earlier\n",
    "    # start_time_total = time.time() # Example\n",
    "\n",
    "    print(\"pre1: Moviendo feature objects de query a GPU...\")\n",
    "    if isinstance(fobj_q, list):\n",
    "        fobj_q = [fmap.to('cuda') for fmap in fobj_q]\n",
    "    else:\n",
    "        fobj_q = fobj_q.to('cuda')\n",
    "\n",
    "    print(\"pre2: Moviendo feature objects de referencia a GPU...\")\n",
    "    all_fobj_r_list_gpu = []\n",
    "    for inner_list in all_fobj_r_list:\n",
    "        all_fobj_r_list_gpu.append([fmap.to('cuda') for fmap in inner_list])\n",
    "\n",
    "    all_fobj_r_list = all_fobj_r_list_gpu\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"preparación de GPU completa.\")\n",
    "\n",
    "    print(\"Calculando mapas de puntuación de matching...\")\n",
    "    all_matching_score_maps, matched_maha_range_global = compute_matching_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-2, # Keep your refined regularization value here\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        pixel_batch_size=4096\n",
    "    )\n",
    "    print(f\"Total de mapas de matching válidos: {len(all_matching_score_maps)}\")\n",
    "\n",
    "\n",
    "    print(\"Calculando mapas de puntuación de unmatched...\")\n",
    "    all_unmatched_score_maps = compute_unmatched_score_map(\n",
    "        fobj_q=fobj_q,\n",
    "        all_closest_unmatched_ref_indices_by_query_obj=all_closest_unmatched_ref_indices_by_query_obj,\n",
    "        all_fobj_r_list=all_fobj_r_list,\n",
    "        regularization=1e-2, # Keep your refined regularization value here\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        pixel_batch_size=4096\n",
    "    )\n",
    "    print(f\"Total de mapas de unmatched válidos: {len(all_unmatched_score_maps)}\")\n",
    "\n",
    "    image_original = Image.open(query_image_path)\n",
    "    H, W = image_original.size\n",
    "\n",
    "    print(\"Construyendo mapa agregado de matching...\")\n",
    "    global_matched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_matching_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Matched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_matched_anomaly_raw\")\n",
    "\n",
    "    print(\"Construyendo mapa agregado de unmatched...\")\n",
    "    global_unmatched_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=all_unmatched_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Unmatched Anomaly Map (RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_unmatched_anomaly_raw\")\n",
    "\n",
    "    combined_individual_score_maps = []\n",
    "    num_queries = len(fobj_q)\n",
    "    for i in range(num_queries):\n",
    "        # Retrieve maps from the potentially filtered lists\n",
    "        # Note: The order/count in all_matching_score_maps and all_unmatched_score_maps\n",
    "        # might not perfectly match query_idx if maps were discarded.\n",
    "        # To correctly combine, you might need a more robust way to associate.\n",
    "        # For now, let's assume they are still ordered by query_idx if not discarded.\n",
    "        # This part might need refinement if map discarding leads to mismatch.\n",
    "        \n",
    "        # Let's filter here again based on the original fobj_q indices to be safe\n",
    "        # This is a placeholder for more robust association if needed.\n",
    "        matched_map_for_query = None\n",
    "        if i < len(all_matching_score_maps): # Simple check assuming order\n",
    "            matched_map_for_query = all_matching_score_maps[i]\n",
    "            \n",
    "        unmatched_map_for_query = None\n",
    "        if i < len(all_unmatched_score_maps): # Simple check assuming order\n",
    "            unmatched_map_for_query = all_unmatched_score_maps[i]\n",
    "        \n",
    "        # Only combine if both maps are available and valid for this query_idx\n",
    "        if matched_map_for_query is not None and unmatched_map_for_query is not None and \\\n",
    "        not (torch.isnan(matched_map_for_query).any() or torch.isinf(matched_map_for_query).any()) and \\\n",
    "        not (torch.isnan(unmatched_map_for_query).any() or torch.isinf(unmatched_map_for_query).any()):\n",
    "            \n",
    "            combined_map_for_query_i = matched_map_for_query + unmatched_map_for_query\n",
    "            combined_individual_score_maps.append(combined_map_for_query_i)\n",
    "        else:\n",
    "            print(f\"INFO: Query Object {i} is partially or fully discarded for combined map due to missing/invalid individual maps.\")\n",
    "\n",
    "\n",
    "    print(f\"Number of valid combined individual score maps for aggregation: {len(combined_individual_score_maps)}\")\n",
    "    if combined_individual_score_maps:\n",
    "        all_max_values = [m.max().item() for m in combined_individual_score_maps]\n",
    "        print(f\"Max values across all combined_individual_score_maps: {all_max_values}\")\n",
    "\n",
    "    print(\"Construyendo mapa total de anomalías...\")\n",
    "    global_total_anomaly_score_map = build_aggregated_score_map(\n",
    "        individual_score_maps_list=combined_individual_score_maps,\n",
    "        final_size=(H, W),\n",
    "        title_prefix=\"Global Total Anomaly Map (Sum of RAW Mahalanobis)\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_prefix=\"global_total_anomaly_raw\")\n",
    "\n",
    "    print(\"Generando superposiciones de mapas de anomalías...\")\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_matched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_matched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_unmatched_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_unmatched_overlay_raw\")\n",
    "\n",
    "    overlay_anomaly_map_on_image(\n",
    "        image_rgb_path=query_image_path,\n",
    "        anomaly_map=global_total_anomaly_score_map,\n",
    "        alpha=0.7,\n",
    "        cmap=\"magma\",\n",
    "        plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "        filename_suffix=\"global_total_anomaly_overlay_raw\")\n",
    "\n",
    "    score_map_filename = f\"maha_{base_image_name}.npy\"\n",
    "    score_map_save_path = os.path.join(MAHALANOBIS_SCORE_MAPS_DIR, score_map_filename)\n",
    "\n",
    "    score_map_to_save = global_total_anomaly_score_map.cpu().numpy()\n",
    "\n",
    "    np.save(score_map_save_path, score_map_to_save)\n",
    "    print(\"finalizado iteracion\")\n",
    "\n",
    "    # Assuming start_time_total and start_time_global are defined somewhere\n",
    "    # end_time_total = time.time()\n",
    "    # total_time = end_time_total - start_time_total\n",
    "    # print(f\"Tiempo total de ejecución iteracion: {total_time:.2f} segundos\")\n",
    "\n",
    "    # Check and report NaN/Inf in the final saved map\n",
    "    nan_count = np.isnan(score_map_to_save).sum()\n",
    "    inf_count = np.isinf(score_map_to_save).sum()\n",
    "\n",
    "    if nan_count > 0 or inf_count > 0:\n",
    "        print(f\"\\n--- REPORTE FINAL DE INCONSISTENCIAS ---\")\n",
    "        print(f\"ATENCIÓN: El mapa de Mahalanobis final guardado '{score_map_save_path}' contiene:\")\n",
    "        print(f\"  - {nan_count} valores NaN (Not a Number)\")\n",
    "        print(f\"  - {inf_count} valores Inf (Infinito)\")\n",
    "        print(f\"A pesar de los descartes, si estos valores aparecen aquí, significa que la agregación o una etapa posterior pudo haberlos reintroducido o que un mapa descartado era la única fuente.\")\n",
    "        print(f\"Este mapa final fue limpiado para asegurar que sea numéricamente manejable.\")\n",
    "    else:\n",
    "        print(f\"\\n--- REPORTE FINAL DE INCONSISTENCIAS ---\")\n",
    "        print(f\"No se detectaron valores NaN o Inf en el mapa de Mahalanobis final guardado '{score_map_save_path}'.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Top 10 valores del mapa global de anomalía ---\")\n",
    "    for query_image_path in image_paths:\n",
    "        base_image_name_with_ext = os.path.basename(query_image_path)\n",
    "        base_image_name = os.path.splitext(base_image_name_with_ext)[0]\n",
    "        score_map_filename = f\"maha_{base_image_name}.npy\"\n",
    "        score_map_path = os.path.join(MAHALANOBIS_SCORE_MAPS_DIR, score_map_filename)\n",
    "\n",
    "        try:\n",
    "            score_map = np.load(score_map_path)\n",
    "            top_10_values = np.sort(score_map.flatten())[-10:]\n",
    "            print(f\"Imagen: {base_image_name}\")\n",
    "            print(f\"Top 10 valores: {top_10_values}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: No se encontró el archivo de mapa de puntuación para la imagen '{base_image_name}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Ocurrió un problema al procesar la imagen '{base_image_name}'. Detalles: {e}\")\n",
    "\n",
    "\n",
    "print(\"finalizado\")\n",
    "# end_time_global = time.time()\n",
    "# total_global_time = end_time_global - start_time_global\n",
    "# print(f\"Tiempo total de ejecución global: {total_global_time:.2f} segundos\")\n",
    "\n",
    "# --- Imprimir los 10 valores más altos del mapa global de anomalía para cada imagen ---\n",
    "# --- NUEVA FUNCIÓN: Obtener y mostrar los top N valores más altos ---\n",
    "def get_top_n_values_from_maps(mahalanobis_maps_dict, map_file_ids_dict, n=10):\n",
    "    print(f\"\\n--- Top {n} valores más altos de Mahalanobis para cada mapa ---\")\n",
    "    for cls_name, maps_list in mahalanobis_maps_dict.items():\n",
    "        file_ids = map_file_ids_dict.get(cls_name, [])\n",
    "        if not maps_list:\n",
    "            print(f\"   No hay mapas para la clase '{cls_name}'.\")\n",
    "            continue\n",
    "        print(f\" Clase: '{cls_name}'\")\n",
    "        for i, score_map in enumerate(maps_list):\n",
    "            if score_map.size == 0:\n",
    "                print(f\"     Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'}: Vacío.\")\n",
    "                continue\n",
    "            \n",
    "            flat_scores = score_map.flatten()\n",
    "            # Sort in descending order and take the top N\n",
    "            top_n_values = np.sort(flat_scores)[::-1][:n]\n",
    "            print(f\"     Mapa {file_ids[i] if i < len(file_ids) else f'Index {i}'} (Top {n}): {[f'{val:.4f}' for val in top_n_values]}\")\n",
    "    print(\"--- Fin de la visualización de los top valores ---\")\n",
    "# Load the Mahalanobis score map for the current query image\n",
    "try:\n",
    "    score_map = np.load(score_map_save_path)\n",
    "    top_10_values = np.sort(score_map.flatten())[-10:]\n",
    "    print(f\"Imagen: {os.path.basename(query_image_path)}\")\n",
    "    print(f\"Top 10 valores: {top_10_values}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo de mapa de puntuación para la imagen '{os.path.basename(query_image_path)}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Ocurrió un problema al procesar la imagen '{os.path.basename(query_image_path)}'. Detalles: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_featup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
