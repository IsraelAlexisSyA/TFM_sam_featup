{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos del coreset...\n",
      "Coreset cargado. Dimensión: torch.Size([10009, 384])\n",
      "NearestNeighbors finder inicializado.\n",
      "Cargando modelo DINOv2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/imercatoma/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo DINOv2 cargado.\n",
      "Cargando modelo SAM2 desde /home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt...\n",
      "Modelo SAM2 cargado.\n",
      "\n",
      "--- Procesando imagen: 001.png ---\n",
      "\n",
      "Buscando imágenes similares usando el banco pre-aplanado del Coreset...\n",
      "Tiempo para calcular distancias KNN: 1.0846 segundos\n",
      "Dimensiones imagen SAM: (1024, 1024, 3)\n",
      "Generando máscaras para consulta con grid de 16x16 puntos...\n",
      "Número de máscaras generadas para la imagen de consulta: 7\n",
      "Máscaras generadas para consulta: 6.\n",
      "\n",
      "Generando máscaras SAM para imágenes similares...\n",
      "--- Procesando vecino 1: 036.png ---\n",
      "Máscaras generadas para vecino 1: 2.\n",
      "--- Procesando vecino 2: 064.png ---\n",
      "Máscaras generadas para vecino 2: 2.\n",
      "--- Procesando vecino 3: 092.png ---\n",
      "Máscaras generadas para vecino 3: 2.\n",
      "Tiempo total de ejecución de SAM: 23.4892 segundos.\n",
      "\n",
      "Análisis de detección de anomalías para una sola imagen completado.\n",
      "Máscara procesada 1 guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/processed_masks/query_processed_mask_1.png\n",
      "Máscara procesada 2 guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/processed_masks/query_processed_mask_2.png\n",
      "Máscara procesada 3 guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/processed_masks/query_processed_mask_3.png\n",
      "Máscara procesada 4 guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/processed_masks/query_processed_mask_4.png\n",
      "Máscara procesada 5 guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/processed_masks/query_processed_mask_5.png\n",
      "Máscara procesada 6 guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/processed_masks/query_processed_mask_6.png\n",
      "Shape de masks_data_query_image: 6\n",
      "\n",
      "--- Generando Mapas de Características de Objeto ---\n",
      "TARGET_MASK_H: 128\n",
      "TARGET_MASK_W: 128\n",
      "Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): torch.Size([6, 384, 128, 128])\n",
      "Dimensiones de fobj_r para vecino 1: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 2: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Dimensiones de fobj_r para vecino 3: torch.Size([2, 384, 128, 128])\n",
      "\n",
      "Tipos de los elementos en all_fobj_r_list:\n",
      "Vecino 1: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 2: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "Vecino 3: Tipo de fobj_r: <class 'torch.Tensor'>\n",
      "\n",
      "Proceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\n",
      "\n",
      "Los plots de Mapas de Características de Objeto se guardarán en: /home/imercatoma/FeatUp/plots_single_3/cut_001/object_feature_map_plots\n",
      "\n",
      "Generando visualizaciones de Mapas de Características de Objeto para la consulta...\n",
      "\n",
      "Generando visualizaciones de Mapas de Características de Objeto para los vecinos...\n",
      "\n",
      "Visualización de Mapas de Características de Objeto completada.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "\n",
    "# FeatUp utilities\n",
    "from featup.util import norm, unnorm\n",
    "from featup.plotting import plot_feats\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Anomaly region detection and visualization\n",
    "from skimage import measure\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# SAM2 imports\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import cv2\n",
    "\n",
    "# PCA for manual visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Set the CUDA device to GPU 4\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# --- Configuración ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224 # DINOv2 input size\n",
    "BACKBONE_PATCH_SIZE = 14 # DINOv2 ViT-S/14 patch size\n",
    "use_norm = True\n",
    "\n",
    "H_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "W_prime = input_size // BACKBONE_PATCH_SIZE\n",
    "\n",
    "# Directorios\n",
    "TRAIN_GOOD_DIR = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/train/good'\n",
    "PLOT_SAVE_ROOT_DIR = '/home/imercatoma/FeatUp/plots_single_3_1/cut_001'\n",
    "# --- Imagen de Consulta ---\n",
    "query_image_path = '/home/imercatoma/FeatUp/datasets/mvtec_anomaly_detection/hazelnut/test/cut/001.png'\n",
    "os.makedirs(PLOT_SAVE_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "HEATMAPS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'individual_heatmaps')\n",
    "os.makedirs(HEATMAPS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "ANOMALY_REGIONS_SAVE_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'detected_anomaly_regions')\n",
    "os.makedirs(ANOMALY_REGIONS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "FEATUP_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, 'featup_feature_plots')\n",
    "os.makedirs(FEATUP_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Coreset file paths\n",
    "core_bank_filenames_file = os.path.join(TRAIN_GOOD_DIR, 'core_bank_filenames.pt')\n",
    "coreset_relevant_flat_features_bank_file = os.path.join(TRAIN_GOOD_DIR, 'coreset_relevant_flat_features_bank.pt')\n",
    "template_features_bank_coreset_file = os.path.join(TRAIN_GOOD_DIR, 'template_features_bank_coreset.pt')\n",
    "\n",
    "# --- Cargar Datos del Coreset ---\n",
    "print(\"Cargando datos del coreset...\")\n",
    "try:\n",
    "    coreset_relevant_filenames = torch.load(core_bank_filenames_file)\n",
    "    coreset_relevant_flat_features_bank = torch.load(coreset_relevant_flat_features_bank_file).to(device)\n",
    "    coreset_features = torch.load(template_features_bank_coreset_file).to(device)\n",
    "    print(f\"Coreset cargado. Dimensión: {coreset_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar archivos del coreset: {e}. Asegúrate de que la Etapa 1 se ejecutó.\")\n",
    "    exit()\n",
    "\n",
    "# Mover coreset a CPU para sklearn's NearestNeighbors\n",
    "coreset_features_cpu = coreset_features.cpu().numpy()\n",
    "# se calcula la distancia coseno == 1 - similitud coseno [0,1] 0 identico, 1 completamente diferente\n",
    "nn_finder = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='cosine').fit(coreset_features_cpu)\n",
    "print(\"NearestNeighbors finder inicializado.\")\n",
    "\n",
    "# --- Cargar Modelo DINOv2 ---\n",
    "print(\"Cargando modelo DINOv2...\")\n",
    "#featup_local_path = \"/home/imercatoma/FeatUp\"\n",
    "#upsampler = torch.hub.load(\"mhamilton723/FeatUp\", 'dinov2', use_norm=use_norm, source='local').to(device)\n",
    "#upsampler = torch.hub.load(\"mhamilton723/FeatUp\", 'dinov2', use_norm=use_norm).to(device)\n",
    "featup_local_path = \"/home/imercatoma/FeatUp\"\n",
    "upsampler = torch.hub.load(featup_local_path, 'dinov2', use_norm=use_norm, source='local').to(device)\n",
    "\n",
    "dinov2_model = upsampler.model\n",
    "dinov2_model.eval()\n",
    "print(\"Modelo DINOv2 cargado.\")\n",
    "\n",
    "# --- Transformación de Imagen ---\n",
    "transform = T.Compose([\n",
    "    T.Resize(input_size),\n",
    "    T.CenterCrop((input_size, input_size)),\n",
    "    T.ToTensor(),\n",
    "    norm\n",
    "])\n",
    "\n",
    "# --- Carga del Modelo SAM2 (Ámbito Global) ---\n",
    "checkpoint = \"/home/imercatoma/sam2_repo_independent/checkpoints/sam2.1_hiera_small.pt\"\n",
    "model_cfg_name = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_model = None\n",
    "\n",
    "# --- Cargar Modelo SAM2 ---\n",
    "print(f\"Cargando modelo SAM2 desde {checkpoint}...\")\n",
    "sam2_model = build_sam2(model_cfg_name, checkpoint, device=device, apply_postprocessing=True)\n",
    "sam2_model.eval()\n",
    "print(\"Modelo SAM2 cargado.\")\n",
    "\n",
    "\n",
    "# ###########inicio DInoAnomaly adaptado #######\n",
    "\n",
    "# # --- Función Principal para Puntuaciones de Anomalía ---\n",
    "# def get_anomaly_scores_for_image(image_path, model, image_transform, nn_finder_instance, H_prime, W_prime, device):\n",
    "#     try:\n",
    "#         query_img_pil = Image.open(image_path).convert(\"RGB\")\n",
    "#         input_tensor = image_transform(query_img_pil).unsqueeze(0).to(device)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error cargando/transformando imagen {os.path.basename(image_path)}: {e}\")\n",
    "#         return None, None, None, None, None\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         features_lr = model(input_tensor)\n",
    "        \n",
    "#     print(\"Shape de features_lr:\", features_lr.shape)\n",
    "#     query_patches_flat = features_lr.squeeze(0).permute(1, 2, 0).reshape(-1, features_lr.shape[1]) # shape (H_prime * W_prime, C)\n",
    "#     print(\"Primeros 5 patches_flat:\")\n",
    "#     print(query_patches_flat[:5])\n",
    "#     query_patches_flat_cpu = query_patches_flat.cpu().numpy()\n",
    "    \n",
    "#     distances_to_nn, _ = nn_finder_instance.kneighbors(query_patches_flat_cpu)\n",
    "    \n",
    "#     print(\"Shape de distances_to_nn:\", distances_to_nn.shape)\n",
    "#     print(\"Distancias:\", distances_to_nn[5:].flatten())\n",
    "#     print(\"Índices:\", np.argsort(distances_to_nn, axis=0)[:5].flatten())\n",
    "#     print(\"Máximo de distances_to_nn:\", np.max(distances_to_nn))\n",
    "#     print(\"Mínimo de distances_to_nn:\", np.min(distances_to_nn))\n",
    "    \n",
    "    \n",
    "#     patch_anomaly_scores = distances_to_nn.flatten()\n",
    "#     print(\"Primeros 5 patch_anomaly_scores:\", patch_anomaly_scores[:5])\n",
    "#     sorted_patch_anomaly_scores = np.sort(patch_anomaly_scores)[::-1]\n",
    "#     print(\"Primeros 5 sorted_patch_anomaly_scores:\", sorted_patch_anomaly_scores[:20])\n",
    "#     print(\"Máximo de sorted_patch_anomaly_scores:\", np.max(sorted_patch_anomaly_scores))\n",
    "#     print(\"Mínimo de sorted_patch_anomaly_scores:\", np.min(sorted_patch_anomaly_scores))\n",
    "    \n",
    "#     anomaly_map_lr = patch_anomaly_scores.reshape(H_prime, W_prime)\n",
    "#     anomaly_map_lr_tensor = torch.from_numpy(anomaly_map_lr).unsqueeze(0).unsqueeze(0).to(device)\n",
    "#     anomaly_map_upsampled = F.interpolate(anomaly_map_lr_tensor, size=(input_size, input_size), mode='bilinear', align_corners=False)\n",
    "#     print(\"Shape de anomaly_map_upsampled:\", anomaly_map_upsampled.shape)\n",
    "#     anomaly_map_upsampled = anomaly_map_upsampled.squeeze().cpu().numpy()\n",
    "#     print(\"Primeros 5 valores de anomaly_map_upsampled (aplanado):\")\n",
    "#     print(anomaly_map_upsampled.flatten()[:5])\n",
    "#     print(\"Máximo de anomaly_map_upsampled:\", np.max(anomaly_map_upsampled))\n",
    "#     print(\"Mínimo de anomaly_map_upsampled:\", np.min(anomaly_map_upsampled))\n",
    "    \n",
    "#     anomaly_map_smoothed = gaussian_filter(anomaly_map_upsampled, sigma=4.0)\n",
    "\n",
    "#     if anomaly_map_smoothed.max() == anomaly_map_smoothed.min():\n",
    "#         anomaly_map_final = np.zeros_like(anomaly_map_smoothed, dtype=float)\n",
    "#     else:\n",
    "#         anomaly_map_final = (anomaly_map_smoothed - anomaly_map_smoothed.min()) / (anomaly_map_smoothed.max() - anomaly_map_smoothed.min() + 1e-8)\n",
    "\n",
    "#     return patch_anomaly_scores, sorted_patch_anomaly_scores, query_img_pil, anomaly_map_final, features_lr\n",
    "\n",
    "# # --- Funciones de Métricas ---\n",
    "# def calculate_rms(data):\n",
    "#     return np.sqrt(np.mean(data**2))\n",
    "\n",
    "# def calculate_mad(data):\n",
    "#     return median_abs_deviation(data)\n",
    "\n",
    "# def calculate_median(data):\n",
    "#     return np.median(data)\n",
    "\n",
    "# def calculate_quartile(data, q=25):\n",
    "#     return np.percentile(data, q)\n",
    "\n",
    "# # --- Funciones de Filtrado de Anomalías ---\n",
    "# def calculate_spatial_variance_of_top_patches(patch_anomaly_scores, top_percentage=5.5):\n",
    "#     if patch_anomaly_scores is None or patch_anomaly_scores.size == 0:\n",
    "#         return np.nan\n",
    "\n",
    "#     num_patches = patch_anomaly_scores.size\n",
    "#     num_top = max(1, int(num_patches * top_percentage / 100))\n",
    "#     top_patch_indices = np.argsort(patch_anomaly_scores)[-num_top:]\n",
    "#     row_coords = top_patch_indices // W_prime\n",
    "#     col_coords = top_patch_indices % W_prime\n",
    "\n",
    "#     std_rows = np.std(row_coords) if len(row_coords) > 1 else 0.0\n",
    "#     std_cols = np.std(col_coords) if len(col_coords) > 1 else 0.0\n",
    "#     return std_rows + std_cols\n",
    "\n",
    "# def calculate_active_patches_count_relative_threshold(patch_anomaly_scores, relative_threshold_percentage):\n",
    "#     if patch_anomaly_scores is None or patch_anomaly_scores.size == 0: return 0\n",
    "#     max_val_in_image = np.max(patch_anomaly_scores)\n",
    "#     if max_val_in_image == 0: return 0\n",
    "#     threshold_val = max_val_in_image * relative_threshold_percentage\n",
    "#     return len(patch_anomaly_scores[patch_anomaly_scores > threshold_val])\n",
    "\n",
    "# def calculate_top_percent_average_anomaly(patch_anomaly_scores, top_percent=1):\n",
    "#     if patch_anomaly_scores is None or patch_anomaly_scores.size == 0: return 0.0\n",
    "#     num_patches = patch_anomaly_scores.size\n",
    "#     num_top = max(1, int(num_patches * top_percent / 100))\n",
    "#     sorted_scores = np.sort(patch_anomaly_scores)[::-1]\n",
    "#     return np.mean(sorted_scores[:num_top])\n",
    "\n",
    "# # --- Generar y Guardar Mapas de Calor ---\n",
    "# def generate_and_save_heatmap(image_original_pil, anomaly_map_final, sorted_patch_anomaly_scores, save_path, image_name_for_title):\n",
    "#     num_patches = len(sorted_patch_anomaly_scores)\n",
    "#     num_top_for_q_score = max(1, int(num_patches * 0.01))\n",
    "#     q_score = np.mean(sorted_patch_anomaly_scores[:num_top_for_q_score])\n",
    "#     anomalia_estructural = q_score > 0.27\n",
    "\n",
    "#     print(f\"Q-score: {q_score:.4f}. Anomalía estructural: {'Sí' if anomalia_estructural else 'No'}\")\n",
    "\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(image_original_pil)\n",
    "#     plt.title(f'Imagen Original: {image_name_for_title}')\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(anomaly_map_final, cmap='jet')\n",
    "#     plt.title(f'Mapa de Anomalía (Q-score: {q_score:.2f})')\n",
    "#     plt.colorbar(label='Puntuación de Anomalía Normalizada')\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(save_path)\n",
    "#     print(f\"Mapa de calor de anomalías guardado en: {save_path}\")\n",
    "#     plt.close()\n",
    "#     return anomaly_map_final, q_score, anomalia_estructural\n",
    "\n",
    "base_image_name = os.path.basename(query_image_path)\n",
    "print(f\"\\n--- Procesando imagen: {base_image_name} ---\")\n",
    "\n",
    "# RELATIVE_ACTIVE_PATCH_THRESHOLD_PERCENTAGE = 0.80\n",
    "\n",
    "#current_patch_anomaly_scores, current_sorted_patch_anomaly_scores, query_img_pil, anomaly_map_final_for_regions, query_lr_features = get_anomaly_scores_for_image(\n",
    "#     query_image_path, dinov2_model, transform, nn_finder, H_prime, W_prime, device\n",
    "# )\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "query_img_pil = Image.open(query_image_path).convert(\"RGB\")\n",
    "input_tensor = transform(query_img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    features_lr = dinov2_model(input_tensor)\n",
    "    \n",
    "query_lr_features = features_lr\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Variables obtenidas:\")\n",
    "# # Imprimir los 5 primeros valores de los términos solicitados\n",
    "# if current_patch_anomaly_scores is not None:\n",
    "#     print(\"Primeros 5 valores de current_patch_anomaly_scores:\")\n",
    "#     print(current_patch_anomaly_scores[:5])\n",
    "\n",
    "# if current_sorted_patch_anomaly_scores is not None:\n",
    "#     print(\"Primeros 5 valores de current_sorted_patch_anomaly_scores:\")\n",
    "#     print(current_sorted_patch_anomaly_scores[:5])\n",
    "\n",
    "# if query_img_pil is not None:\n",
    "#     print(\"Shape de query_img_pil:\")\n",
    "#     print(query_img_pil.size)  # PIL images use (width, height)\n",
    "\n",
    "# if anomaly_map_final_for_regions is not None:\n",
    "#     print(\"Primeros 5 valores de anomaly_map_final_for_regions (aplanado):\")\n",
    "#     print(anomaly_map_final_for_regions.flatten()[:5])\n",
    "\n",
    "# if query_lr_features is not None:\n",
    "#     print(\"Primeras 5 características de query_lr_features:\")\n",
    "#     print(query_lr_features.reshape(-1, query_lr_features.shape[-1])[:5])\n",
    "\n",
    "# # Mostrar las 5 primeras características de query_lr_features\n",
    "# print(\"Primeras 5 características de query_lr_features:\")\n",
    "# print(query_lr_features.reshape(-1, query_lr_features.shape[-1])[:5])\n",
    "# print(\"Máximo de query_lr_features:\", torch.max(query_lr_features).item())\n",
    "# print(\"Mínimo de query_lr_features:\", torch.min(query_lr_features).item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Generar y guardar heatmap\n",
    "# heatmap_filename = f\"heat_{base_image_name}\"\n",
    "# individual_heatmap_save_path = os.path.join(HEATMAPS_SAVE_DIR, heatmap_filename)\n",
    "# current_anomaly_map_final, current_q_score, current_anomalia_estructural = \\\n",
    "#     generate_and_save_heatmap(query_img_pil, anomaly_map_final_for_regions,\n",
    "#                                 current_sorted_patch_anomaly_scores,\n",
    "#                                 individual_heatmap_save_path, base_image_name.replace(\".png\", \"\"))\n",
    "\n",
    "# # Calcular métricas para la imagen actual\n",
    "# min_val = np.min(current_sorted_patch_anomaly_scores)\n",
    "# max_val = np.max(current_sorted_patch_anomaly_scores)\n",
    "# normalized_data = (current_sorted_patch_anomaly_scores - min_val) / (max_val - min_val + 1e-8) if max_val != min_val else np.zeros_like(current_sorted_patch_anomaly_scores)\n",
    "\n",
    "# A_rms = calculate_rms(normalized_data)\n",
    "# B_mad = calculate_mad(normalized_data)\n",
    "# C_median = calculate_median(normalized_data)\n",
    "# D_q1_normalized = calculate_quartile(normalized_data, q=25)\n",
    "\n",
    "# dist_rms_mad = A_rms - B_mad\n",
    "# dist_rms_median = A_rms - C_median\n",
    "# dist_rms_q1 = A_rms - D_q1_normalized\n",
    "# spatial_var = calculate_spatial_variance_of_top_patches(current_patch_anomaly_scores)\n",
    "# active_count = calculate_active_patches_count_relative_threshold(current_patch_anomaly_scores, relative_threshold_percentage=RELATIVE_ACTIVE_PATCH_THRESHOLD_PERCENTAGE)\n",
    "# top_1_avg = calculate_top_percent_average_anomaly(current_patch_anomaly_scores, top_percent=1)\n",
    "\n",
    "# # Lógica de clasificación\n",
    "# classification = 0\n",
    "# if top_1_avg >= 0.30:\n",
    "#     classification = 1\n",
    "#     print(f\"Clasificación: ANOMALÍA GRANDE (Top 1% Avg: {top_1_avg:.4f} >= 0.30)\")\n",
    "# elif 0.17 <= top_1_avg < 0.30:\n",
    "#     print(f\"Clasificación: Evaluación de anomalía leve/buena (Top 1% Avg: {top_1_avg:.4f})\")\n",
    "#     initial_classification_based_on_active_patches = 0\n",
    "#     if active_count > 5:\n",
    "#         initial_classification_based_on_active_patches = 1\n",
    "#         print(f\"-> ANOMALÍA LEVE (Parches Activos: {active_count} > 5)\")\n",
    "#         classification = 1\n",
    "#     else:\n",
    "#         print(f\"-> Parches Activos ({active_count}) <= 5. Evaluando 'buena'.\")\n",
    "#         initial_classification_based_on_active_patches = 0\n",
    "#         if dist_rms_median <= 0.055:\n",
    "#             print(f\"-> Condición Buena II (RMS - Mediana <= 0.055): True ({dist_rms_median:.4f})\")\n",
    "#             cond_I_met = spatial_var >= 5.5\n",
    "#             print(f\"-> Condición Buena I (Varianza Espacial >= 5.5): {'True' if cond_I_met else 'False'} ({spatial_var:.2f})\")\n",
    "#             cond_III_met = dist_rms_mad >= 0.21\n",
    "#             print(f\"-> Condición Buena III (RMS - MAD >= 0.21): {'True' if cond_III_met else 'False'} ({dist_rms_mad:.4f})\")\n",
    "#             if cond_I_met or cond_III_met:\n",
    "#                 classification = 0\n",
    "#                 print(f\"-> IMAGEN BUENA\")\n",
    "#             else:\n",
    "#                 classification = initial_classification_based_on_active_patches\n",
    "#                 print(f\"-> {'ANOMALÍA LEVE' if classification == 1 else 'IMAGEN BUENA'} (Revertiendo a Parches Activos)\")\n",
    "#         else:\n",
    "#             classification = 1\n",
    "#             print(f\"-> ANOMALÍA LEVE\")\n",
    "\n",
    "# print(f\"Clasificación Final para {base_image_name}: {'Anómala' if classification == 1 else 'Buena'}\")\n",
    "\n",
    "# # --- Detección y visualización de regiones de anomalía \"fuertes\" ---\n",
    "# if classification == 1:\n",
    "#     start_time_region_detection = time.time()\n",
    "#     print(\"\\n  ** Clasificada como ANÓMALA. Buscando regiones fuertes... **\")\n",
    "#     strong_anomaly_region_threshold = 0.75\n",
    "#     binary_strong_anomaly_map = anomaly_map_final_for_regions > strong_anomaly_region_threshold\n",
    "    \n",
    "#     if not np.any(binary_strong_anomaly_map):\n",
    "#         print(f\"    No se encontraron píxeles por encima del umbral de {strong_anomaly_region_threshold}.\")\n",
    "#     else:\n",
    "#         labeled_anomaly_regions = measure.label(binary_strong_anomaly_map)\n",
    "#         region_properties = measure.regionprops(labeled_anomaly_regions)\n",
    "#         detected_strong_anomaly_regions = []\n",
    "#         min_region_pixel_area = 50\n",
    "#         original_img_width, original_img_height = query_img_pil.size\n",
    "#         scale_x = original_img_width / input_size\n",
    "#         scale_y = original_img_height / input_size\n",
    "\n",
    "#         for region in region_properties:\n",
    "#             if region.area >= min_region_pixel_area:\n",
    "#                 min_y, min_x, max_y, max_x = region.bbox\n",
    "#                 scaled_min_x = int(np.clip(min_x * scale_x, 0, original_img_width))\n",
    "#                 scaled_min_y = int(np.clip(min_y * scale_y, 0, original_img_height))\n",
    "#                 scaled_max_x = int(np.clip(max_x * scale_x, 0, original_img_width))\n",
    "#                 scaled_max_y = int(np.clip(max_y * scale_y, 0, original_img_height))\n",
    "#                 region_width = scaled_max_x - scaled_min_x\n",
    "#                 region_height = scaled_max_y - scaled_min_y\n",
    "#                 if region_width > 0 and region_height > 0:\n",
    "#                     detected_strong_anomaly_regions.append({\n",
    "#                         'bbox': (scaled_min_x, scaled_min_y, region_width, region_height),\n",
    "#                         'area_pixels': region.area\n",
    "#                     })\n",
    "\n",
    "#         if detected_strong_anomaly_regions:\n",
    "#             plt.figure(figsize=(10, 8))\n",
    "#             plt.imshow(query_img_pil)\n",
    "#             plt.title(f'Imagen Anómala con Regiones Fuertes: {base_image_name.replace(\".png\", \"\")}')\n",
    "#             plt.axis('off')\n",
    "#             ax = plt.gca()\n",
    "#             for region_info in detected_strong_anomaly_regions:\n",
    "#                 bbox = region_info['bbox']\n",
    "#                 if bbox[2] > 0 and bbox[3] > 0:\n",
    "#                     rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3],\n",
    "#                                              linewidth=3, edgecolor='lime', facecolor='none', linestyle='-', alpha=0.9)\n",
    "#                     ax.add_patch(rect)\n",
    "#             ax.add_patch(patches.Rectangle((0,0), 0.1, 0.1, linewidth=3, edgecolor='lime', facecolor='none', linestyle='-', alpha=0.9, label=f'Regiones Anómalas Fuertes'))\n",
    "#             plt.legend()\n",
    "#             strong_regions_overlay_output_filename = os.path.join(ANOMALY_REGIONS_SAVE_DIR, f'anomaly_regions_{base_image_name}')\n",
    "#             plt.tight_layout()\n",
    "#             plt.savefig(strong_regions_overlay_output_filename)\n",
    "#             plt.close()\n",
    "#             print(f\"    Plot de regiones anómalas fuertes guardado en: {strong_regions_overlay_output_filename}\")\n",
    "#         else:\n",
    "#             print(\"    No se detectaron regiones válidas para dibujar.\")\n",
    "#     end_time_region_detection = time.time()\n",
    "#     print(f\"  Tiempo para detección de regiones: {end_time_region_detection - start_time_region_detection:.4f} segundos.\")\n",
    "# else:\n",
    "#     print(f\"  Clasificada como BUENA. No se dibujarán regiones anómalas.\")\n",
    "\n",
    "########### FIn AnomalyDIno\n",
    "\n",
    "directorio_imagenes = TRAIN_GOOD_DIR\n",
    "plot_save_directory_on_server = PLOT_SAVE_ROOT_DIR\n",
    "\n",
    "# --- Función para buscar imágenes similares usando KNN ---\n",
    "def buscar_imagenes_similares_knn(query_feature_map, pre_flattened_features_bank, k=3, nombres_archivos=None):\n",
    "    query_feat_flatten = query_feature_map.flatten().cpu().numpy()\n",
    "    features_bank_for_knn = pre_flattened_features_bank.cpu().numpy() if isinstance(pre_flattened_features_bank, torch.Tensor) else pre_flattened_features_bank\n",
    "\n",
    "    start_time_knn_dist = time.time()\n",
    "    distances = euclidean_distances([query_feat_flatten], features_bank_for_knn)\n",
    "    nearest_indices = np.argsort(distances[0])[:k]\n",
    "    end_time_knn_dist = time.time()\n",
    "    print(f\"Tiempo para calcular distancias KNN: {end_time_knn_dist - start_time_knn_dist:.4f} segundos\")\n",
    "\n",
    "    imagenes_similares = []\n",
    "    rutas_imagenes_similares = []\n",
    "    if nombres_archivos:\n",
    "        for idx in nearest_indices:\n",
    "            imagenes_similares.append(nombres_archivos[idx])\n",
    "            rutas_imagenes_similares.append(os.path.join(directorio_imagenes, nombres_archivos[idx]))\n",
    "    else: # Fallback if no filenames provided (less common for this use case)\n",
    "        for idx in nearest_indices:\n",
    "            imagenes_similares.append(f\"Imagen_Banco_{idx:03d}.png\")\n",
    "            rutas_imagenes_similares.append(os.path.join(directorio_imagenes, f\"Imagen_Banco_{idx:03d}.png\"))\n",
    "    return imagenes_similares, rutas_imagenes_similares, end_time_knn_dist\n",
    "\n",
    "# --- Búsqueda KNN ---\n",
    "print(\"\\nBuscando imágenes similares usando el banco pre-aplanado del Coreset...\")\n",
    "imagenes_similares, rutas_imagenes_similares, time_knn_dist = buscar_imagenes_similares_knn(\n",
    "    query_lr_features, coreset_relevant_flat_features_bank, nombres_archivos=coreset_relevant_filenames\n",
    ")\n",
    "\n",
    "# print(\"Imágenes similares:\", imagenes_similares)\n",
    "\n",
    "# # --- Visualización de imágenes similares ---\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.subplot(1, len(rutas_imagenes_similares) + 1, 1)\n",
    "# plt.imshow(query_img_pil)\n",
    "# plt.title(f'Consulta:\\n{base_image_name}')\n",
    "# plt.axis('off')\n",
    "\n",
    "# for j, ruta_imagen_similar in enumerate(rutas_imagenes_similares):\n",
    "#     try:\n",
    "#         img_similar = Image.open(ruta_imagen_similar).convert('RGB')\n",
    "#         plt.subplot(1, len(rutas_imagenes_similares) + 1, j + 2)\n",
    "#         plt.imshow(img_similar)\n",
    "#         plt.title(f'Vecino {j + 1}\\n({os.path.basename(ruta_imagen_similar)})')\n",
    "#         plt.axis('off')\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error al cargar imagen similar {os.path.basename(ruta_imagen_similar)}: {e}\")\n",
    "#         plt.subplot(1, len(rutas_imagenes_similares) + 1, j + 2)\n",
    "#         plt.text(0.5, 0.5, \"Error de Carga\", ha='center', va='center', transform=plt.gca().transAxes)\n",
    "#         plt.title(f'Vecino {j + 1}\\n(Error)')\n",
    "#         plt.axis('off')\n",
    "\n",
    "# output_similar_plot_filename = os.path.join(plot_save_directory_on_server, f'similar_images_plot_{base_image_name}')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(output_similar_plot_filename)\n",
    "# plt.close()\n",
    "# print(f\"Plot de imágenes similares guardado en: {output_similar_plot_filename}\")\n",
    "\n",
    "\n",
    "# --- Aplicar FeatUp para obtener características de alta resolución ---\n",
    "def apply_featup_hr(image_path, featup_upsampler, image_transform, device):\n",
    "    image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = image_transform(image_pil).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        lr_feats = featup_upsampler.model(image_tensor)\n",
    "        hr_feats = featup_upsampler(image_tensor)\n",
    "    return lr_feats.cpu(), hr_feats.cpu()\n",
    "\n",
    "# Características de la imagen de consulta\n",
    "input_query_tensor_original = transform(Image.open(query_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "query_lr_feats_featup, query_hr_feats = apply_featup_hr(query_image_path, upsampler, transform, device)\n",
    "\n",
    "# plot_feats(unnorm(input_query_tensor_original)[0], query_lr_feats_featup[0], query_hr_feats[0])\n",
    "# fig_query_feats = plt.gcf()\n",
    "# fig_query_feats.suptitle(f'Características FeatUp: {base_image_name.replace(\".png\", \"\")}')\n",
    "# output_query_feat_plot_filename = os.path.join(FEATUP_PLOTS_DIR, f'featup_query_image_features_plot_{base_image_name}')\n",
    "# plt.tight_layout()\n",
    "# fig_query_feats.savefig(output_query_feat_plot_filename)\n",
    "# plt.close(fig_query_feats)\n",
    "# print(f\"Plot de características FeatUp (consulta) guardado en: {output_query_feat_plot_filename}\")\n",
    "\n",
    "# Características de las imágenes similares\n",
    "similar_hr_feats_list = []\n",
    "for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "    input_similar_tensor_original = transform(Image.open(similar_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    similar_lr_feats, similar_hr_feats = apply_featup_hr(similar_image_path, upsampler, transform, device)\n",
    "    similar_hr_feats_list.append(similar_hr_feats)\n",
    "\n",
    "    # plot_feats(unnorm(input_similar_tensor_original)[0], similar_lr_feats[0], similar_hr_feats[0])\n",
    "    # fig_similar_feats = plt.gcf()\n",
    "    # fig_similar_feats.suptitle(f'Características FeatUp Vecino {j + 1}: {os.path.basename(similar_image_path).replace(\".png\", \"\")}')\n",
    "    # output_similar_feat_plot_filename = os.path.join(FEATUP_PLOTS_DIR, f'featup_similar_image_{j + 1}_features_plot_{base_image_name}')\n",
    "    # plt.tight_layout()\n",
    "    # fig_similar_feats.savefig(output_similar_feat_plot_filename)\n",
    "    # plt.close(fig_similar_feats)\n",
    "    # print(f\"Plot de características FeatUp (vecino {j + 1}) guardado en: {output_similar_feat_plot_filename}\")\n",
    "\n",
    "################################\n",
    "### Aplicando Máscaras SAM query y similares\n",
    "\n",
    "#print(f\"\\nIniciando SAM para la imagen anómala: {base_image_name}\")\n",
    "start_time_sam = time.time()\n",
    "\n",
    "# --- Funciones Auxiliares de Visualización ---\n",
    "def show_mask(mask, ax, random_color=False, borders=True):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image_alpha = np.zeros((h, w, 4), dtype=np.float32)\n",
    "    mask_image_alpha[mask > 0] = color\n",
    "    if borders:\n",
    "        mask_uint8 = mask.astype(np.uint8) * 255\n",
    "        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        contour_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=2)\n",
    "        contour_mask = (contour_image.astype(np.float32) / 255.0).sum(axis=-1) > 0\n",
    "        mask_image_alpha[contour_mask > 0, :3] = 1.0\n",
    "        mask_image_alpha[contour_mask > 0, 3] = 0.5\n",
    "    ax.imshow(mask_image_alpha)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    ax.scatter(coords[labels==1][:, 0], coords[labels==1][:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(coords[labels==0][:, 0], coords[labels[0]==0][:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_masks_grid(image, masks, points=None, plot_title=\"Generated Masks\", ax=None, num_masks=0):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    if points is not None:\n",
    "        show_points(points, np.ones(points.shape[0], dtype=int), ax, marker_size=50)\n",
    "    for mask_data in masks:\n",
    "        show_mask(mask_data[\"segmentation\"], ax, random_color=True)\n",
    "    ax.set_title(f\"{plot_title} (Masks: {num_masks})\", fontsize=18)\n",
    "    ax.axis('off')\n",
    "# --- Fin Funciones Auxiliares ---\n",
    "\n",
    "try:\n",
    "    image_for_sam_np = np.array(Image.open(query_image_path).convert(\"RGB\"))\n",
    "    print(f\"Dimensiones imagen SAM: {image_for_sam_np.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error procesando imagen para SAM: {e}. Saltando SAM.\")\n",
    "    sam2_model = None\n",
    "\n",
    "if sam2_model is not None:\n",
    "    points_grid_density = 16\n",
    "    min_mask_area_pixels = 200.0\n",
    "    max_mask_area_pixels = 450000.0\n",
    "\n",
    "    mask_generator_query = SAM2AutomaticMaskGenerator(\n",
    "        model=sam2_model,\n",
    "        points_per_side=points_grid_density,\n",
    "        points_per_batch=256,\n",
    "        pred_iou_thresh=0.48,\n",
    "        stability_score_thresh=0.7,\n",
    "        crop_n_layers=0,\n",
    "        min_mask_region_area=min_mask_area_pixels,\n",
    "    )\n",
    "\n",
    "    print(f\"Generando máscaras para consulta con grid de {points_grid_density}x{points_grid_density} puntos...\")\n",
    "    masks_data_query_image = mask_generator_query.generate(image_for_sam_np)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # --- Visualización de Máscaras Individuales ---\n",
    "    # def visualize_individual_masks(image, masks, output_dir, filename_prefix):\n",
    "    #     \"\"\"\n",
    "    #     Genera y guarda una gráfica que muestra las máscaras individuales superpuestas en la imagen original.\n",
    "    #     \"\"\"\n",
    "    #     os.makedirs(output_dir, exist_ok=True)\n",
    "    #     for i, mask_data in enumerate(masks):\n",
    "    #         plt.figure(figsize=(8, 8))\n",
    "    #         plt.imshow(image)\n",
    "    #         show_mask(mask_data[\"segmentation\"], plt.gca(), random_color=True)\n",
    "    #         plt.axis('off')\n",
    "    #         plt.title(f'Máscara Individual {i + 1}')\n",
    "            \n",
    "    #         # Guardar la gráfica\n",
    "    #         output_path = os.path.join(output_dir, f\"{filename_prefix}_mask_{i + 1}.png\")\n",
    "    #         plt.savefig(output_path, bbox_inches='tight')\n",
    "    #         plt.close()\n",
    "    #         print(f\"Máscara individual {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "    # # --- Generar y guardar las máscaras individuales ---\n",
    "    # #PLOT_SAVE_ROOT_DIR = \"/home/imercatoma/SAM_output/individual_masks\"\n",
    "    # INDIVIDUAL_MASKS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"individual_masks\")\n",
    "    # visualize_individual_masks(image_for_sam_np, masks_data_query_image, INDIVIDUAL_MASKS_DIR, \"query\")\n",
    "        \n",
    "\n",
    "    print(f\"Número de máscaras generadas para la imagen de consulta: {len(masks_data_query_image)}\")\n",
    "    #masks_data_query_image = [m for m in masks_data_query_image if m['area'] <= max_mask_area_pixels] filtrar fondo\n",
    "    #print(f\"Máscaras generadas para consulta: {len(masks_data_query_image)}.\")\n",
    "\n",
    "    mask_generator_similar = SAM2AutomaticMaskGenerator(\n",
    "        model=sam2_model,\n",
    "        points_per_side=points_grid_density,\n",
    "        points_per_batch=256,\n",
    "        pred_iou_thresh=0.48,\n",
    "        stability_score_thresh=0.7,\n",
    "        crop_n_layers=0,\n",
    "        min_mask_region_area=min_mask_area_pixels,\n",
    "    )\n",
    "\n",
    "    print(\"\\nGenerando máscaras SAM para imágenes similares...\")\n",
    "    similar_masks_raw_list = []\n",
    "    for j, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "        try:\n",
    "            image_np_similar_for_sam = np.array(Image.open(similar_image_path).convert('RGB'))\n",
    "            print(f\"--- Procesando vecino {j+1}: {os.path.basename(similar_image_path)} ---\")\n",
    "            current_similar_masks_data = mask_generator_similar.generate(image_np_similar_for_sam)\n",
    "            #current_similar_masks_data = [m for m in current_similar_masks_data if m['area'] <= max_mask_area_pixels] # filtrar area\n",
    "            similar_masks_raw_list.append(current_similar_masks_data)\n",
    "            print(f\"Máscaras generadas para vecino {j+1}: {len(current_similar_masks_data)}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando imagen similar {os.path.basename(similar_image_path)} para SAM: {e}\")\n",
    "\n",
    "    end_time_sam = time.time()\n",
    "    print(f\"Tiempo total de ejecución de SAM: {end_time_sam - start_time_sam:.4f} segundos.\")\n",
    "\n",
    "    # print(\"\\nGenerando visualización combinada de imágenes segmentadas...\")\n",
    "    # combined_plots_directory = os.path.join(PLOT_SAVE_ROOT_DIR, \"combined_segmented_plots\")\n",
    "    # os.makedirs(combined_plots_directory, exist_ok=True)\n",
    "\n",
    "    # def plot_combined_segmented(query_original_path, query_masks, similar_original_paths, similar_masks_list, output_dir, current_image_name):\n",
    "    #     num_similar = len(similar_original_paths)\n",
    "    #     if num_similar == 0: return\n",
    "\n",
    "    #     total_subplots = 2 + num_similar\n",
    "    #     fig, axes = plt.subplots(1, total_subplots, figsize=(5 * total_subplots, 6))\n",
    "\n",
    "    #     try:\n",
    "    #         query_img_orig = Image.open(query_original_path).convert('RGB')\n",
    "    #         axes[0].imshow(query_img_orig)\n",
    "    #         axes[0].set_title(f'Consulta Original:\\n{current_image_name.replace(\".png\", \"\")}')\n",
    "    #         axes[0].axis('off')\n",
    "    #         show_masks_grid(np.array(query_img_orig), query_masks, plot_title=f'Consulta Segmentada', ax=axes[1], num_masks=len(query_masks))\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error al graficar imagen de consulta original/segmentada: {e}\")\n",
    "    #         axes[0].text(0.5, 0.5, \"Error\", ha='center', va='center', transform=axes[0].transAxes)\n",
    "    #         axes[0].set_title('Consulta Original (Error)'); axes[0].axis('off')\n",
    "    #         axes[1].text(0.5, 0.5, \"Error\", ha='center', va='center', transform=axes[1].transAxes)\n",
    "    #         axes[1].set_title('Consulta Segmentada (Error)'); axes[1].axis('off')\n",
    "\n",
    "    #     for j, similar_path in enumerate(similar_original_paths):\n",
    "    #         if j + 2 >= total_subplots: break\n",
    "    #         try:\n",
    "    #             similar_img_orig = Image.open(similar_path).convert('RGB')\n",
    "    #             current_similar_masks = similar_masks_list[j] if j < len(similar_masks_list) else []\n",
    "    #             show_masks_grid(np.array(similar_img_orig), current_similar_masks,\n",
    "    #                             plot_title=f'Vecino {j+1} Segmentado\\n({os.path.basename(similar_path)})',\n",
    "    #                             ax=axes[j + 2], num_masks=len(current_similar_masks))\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"Error al graficar imagen similar {os.path.basename(similar_path)}: {e}\")\n",
    "    #             axes[j + 2].text(0.5, 0.5, \"Error\", ha='center', va='center', transform=axes[j + 2].transAxes)\n",
    "    #             axes[j + 2].set_title(f'Vecino {j+1} (Error)'); axes[j + 2].axis('off')\n",
    "\n",
    "    #     plt.tight_layout()\n",
    "    #     output_filename = os.path.join(output_dir, f'combined_query_and_similar_segmented_{current_image_name}')\n",
    "    #     plt.savefig(output_filename)\n",
    "    #     plt.close(fig)\n",
    "    #     print(f\"Plot combinado de imágenes segmentadas guardado en: {output_filename}\")\n",
    "\n",
    "    # plot_combined_segmented(\n",
    "    #     query_image_path,\n",
    "    #     masks_data_query_image,\n",
    "    #     rutas_imagenes_similares,\n",
    "    #     similar_masks_raw_list,\n",
    "    #     combined_plots_directory,\n",
    "    #     base_image_name\n",
    "    # )\n",
    "    \n",
    "#print(f\"La imagen {base_image_name} fue clasificada como BUENA o el modelo SAM no se pudo cargar. No se generarán máscaras SAM.\")\n",
    "print(\"\\nAnálisis de detección de anomalías para una sola imagen completado.\")\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "\n",
    "def process_masks_with_hierarchy(image, masks, output_dir, filename_prefix, overlap_threshold=0.8):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    processed_masks = []\n",
    "    original_mask_segments = [mask_data[\"segmentation\"] for mask_data in masks]\n",
    "\n",
    "    for i, mask_data_a in enumerate(masks):\n",
    "        mask_a_current_processing = np.copy(mask_data_a[\"segmentation\"]) # Copia para evitar modificar el original\n",
    "        is_completely_internal_to_another = False # Si la máscara A está completamente contenida en otra\n",
    "        potential_holes_for_mask_a = [] # Máscaras que podrían crear un \"hueco\" en A\n",
    "\n",
    "        for j, mask_data_b in enumerate(masks):\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            mask_b = original_mask_segments[j]\n",
    "\n",
    "            # Si la máscara A está totalmente dentro de la máscara B\n",
    "            if np.all(np.logical_and(mask_a_current_processing, mask_b) == mask_a_current_processing):\n",
    "                is_completely_internal_to_another = True\n",
    "                break # A es interna, no necesita ahuecarse\n",
    "\n",
    "            # Si la máscara B está contenida o superpone significativamente a la máscara A\n",
    "            intersection_ab = np.logical_and(mask_b, mask_a_current_processing)\n",
    "            area_b = np.sum(mask_b)\n",
    "            area_intersection_ab = np.sum(intersection_ab)\n",
    "\n",
    "            # Considera B como un hueco si está contenida o si la superposición es significativa\n",
    "            if area_b > 0 and (np.all(intersection_ab == mask_b) or (area_intersection_ab / area_b > overlap_threshold and area_intersection_ab > 0)):\n",
    "                potential_holes_for_mask_a.append(mask_b)\n",
    "\n",
    "        if is_completely_internal_to_another:\n",
    "            # Si A es interna a otra, la añadimos sin cambios\n",
    "            processed_masks.append(mask_data_a[\"segmentation\"])\n",
    "            display_title = f'Máscara {i + 1} (Interna - Sin cambios)'\n",
    "        else:\n",
    "            # Si A es externa, aplicamos los \"huecos\"\n",
    "            hollowed = False\n",
    "            for hole_mask in potential_holes_for_mask_a:\n",
    "                mask_a_current_processing = np.logical_and(mask_a_current_processing, np.logical_not(hole_mask))\n",
    "                hollowed = True\n",
    "            \n",
    "            processed_masks.append(mask_a_current_processing)\n",
    "            if hollowed:\n",
    "                display_title = f'Máscara {i + 1} (Externa - Hueca)'\n",
    "            else:\n",
    "                display_title = f'Máscara {i + 1} (Externa - Sin huecos significativos)'\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        show_mask(processed_masks[-1], plt.gca(), random_color=True)\n",
    "        plt.axis('off')\n",
    "        plt.title(display_title)\n",
    "            \n",
    "        output_path = os.path.join(output_dir, f\"{filename_prefix}_processed_mask_{i + 1}.png\")\n",
    "        plt.savefig(output_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Máscara procesada {i + 1} guardada en: {output_path}\")\n",
    "\n",
    "    return [{\"segmentation\": mask.astype(np.float32)} for mask in processed_masks]\n",
    "\n",
    "# Directorio para guardar las máscaras procesadas\n",
    "PROCESSED_MASKS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"processed_masks\")\n",
    "\n",
    "# Llamar a la función para procesar las máscaras\n",
    "processed_masks = process_masks_with_hierarchy(image_for_sam_np, masks_data_query_image, PROCESSED_MASKS_DIR, \"query\")\n",
    "\n",
    "masks_data_query_image = processed_masks\n",
    "print(\"Shape de masks_data_query_image:\", len(masks_data_query_image))\n",
    "###############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Implementación del punto 3.4.3. Object Feature Map ---\n",
    "import torch.nn.functional as F # Importa F para F.interpolate\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "\n",
    "def process_masks_to_object_feature_maps(raw_masks, hr_feature_map, target_h, target_w, sam_processed_image_shape):\n",
    "    \"\"\"\n",
    "    Procesa una lista de máscaras de SAM para obtener mapas de características de objeto.\n",
    "    Args:\n",
    "        raw_masks (list): Lista de diccionarios de máscaras crudas de SAM.\n",
    "                          Cada dict tiene una clave 'segmentation' (np.ndarray booleana).\n",
    "        hr_feature_map (torch.Tensor): Mapa de características de alta resolución (C, 8H', 8W').\n",
    "                                        Debe ser de la imagen correspondiente (query o reference).\n",
    "                                        Asegúrate de que ya esté en el dispositivo correcto.\n",
    "        target_h (int): Altura objetivo para la máscara escalada (8H').\n",
    "        target_w (int): Ancho objetivo para la máscara escalada (8W').\n",
    "        sam_processed_image_shape (tuple): La forma (H, W, C) de la imagen a la que SAM se aplicó\n",
    "                                            para generar las máscaras (ej. (1024, 1024, 3)).\n",
    "                                            Esto es crucial para escalar correctamente la máscara.\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor de mapas de características de objeto (M, C, 8H', 8W').\n",
    "                      Si no hay máscaras, devuelve un tensor vacío (0, C, 8H', 8W').\n",
    "    \"\"\"\n",
    "    if not raw_masks:\n",
    "        print(\"Advertencia: No se encontraron máscaras para procesar. Devolviendo tensor vacío.\")\n",
    "        C_dim = hr_feature_map.shape[0] if hr_feature_map.ndim >=3 else 0\n",
    "        return torch.empty(0, C_dim, target_h, target_w, device=hr_feature_map.device)\n",
    "\n",
    "    object_feature_maps_list = []\n",
    "    scaled_mask_append = []\n",
    "    C_dim = hr_feature_map.shape[0] # Número de canales de las características HR\n",
    "\n",
    "    for mask_info in raw_masks:\n",
    "        # Convertir la máscara booleana de numpy a tensor float y añadir dimensiones de lote y canal\n",
    "        mask_np = mask_info['segmentation'].astype(np.float32)\n",
    "        mask_tensor_original_res = torch.from_numpy(mask_np).unsqueeze(0).unsqueeze(0) # (1, 1, H_orig, W_orig)\n",
    "        # Mover la máscara al mismo dispositivo que el mapa de características HR\n",
    "        mask_tensor_original_res = mask_tensor_original_res.to(hr_feature_map.device)\n",
    "\n",
    "        # 1. Escalar la máscara a (8H', 8W') usando interpolación bilineal\n",
    "        scaled_mask = F.interpolate(mask_tensor_original_res,\n",
    "                                     size=(target_h, target_w),\n",
    "                                     mode='bilinear',\n",
    "                                     align_corners=False)\n",
    "        # Opcional: Binarizar la máscara después del escalado si se requiere una máscara estricta (0 o 1)\n",
    "        scaled_mask = (scaled_mask > 0.5).float()\n",
    "        # Append scaled mask to the list\n",
    "        scaled_mask_append.append(scaled_mask)\n",
    "        \n",
    "        # 2. Multiplicación elemento a elemento con el mapa de características HR\n",
    "        if hr_feature_map.ndim == 3:\n",
    "            hr_feature_map_with_batch = hr_feature_map.unsqueeze(0) # -> (1, C, H, W)\n",
    "        else: # Si ya es (1, C, H, W)\n",
    "            hr_feature_map_with_batch = hr_feature_map\n",
    "\n",
    "        object_feature_map_i = scaled_mask * hr_feature_map_with_batch\n",
    "        object_feature_maps_list.append(object_feature_map_i)\n",
    "\n",
    "    # Concatenar todos los mapas de características de objeto\n",
    "    final_object_feature_maps = torch.cat(object_feature_maps_list, dim=0) # (M, C, 8H', 8W')\n",
    "    final_scaled_masks = torch.cat(scaled_mask_append, dim=0)\n",
    "    # Save scaled masks outside the function\n",
    "    global saved_scaled_masks\n",
    "    saved_scaled_masks = final_scaled_masks\n",
    "    return final_object_feature_maps, final_scaled_masks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Visualización de Mapas de Características de Objeto ---\n",
    "def visualize_object_feature_map(original_image_path, sam_mask_info, hr_feature_map_tensor,\n",
    "                                   object_feature_map_tensor, target_h, target_w,\n",
    "                                   plot_save_dir, plot_filename_prefix, mask_idx,\n",
    "                                   sam_processed_image_shape):\n",
    "    \"\"\"\n",
    "    Genera y guarda una visualización de un mapa de características de objeto.\n",
    "    Muestra la imagen original, la máscara de SAM y el mapa de características de objeto.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_img = Image.open(original_image_path).convert(\"RGB\")\n",
    "        sam_mask_np = sam_mask_info['segmentation']\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        # Plot 1: Imagen Original\n",
    "        axes[0].imshow(original_img)\n",
    "        axes[0].set_title(f'Imagen Original\\n{os.path.basename(original_image_path)}')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # Plot 2: Máscara SAM (escalada para visualización si es necesario, pero manteniendo la forma original)\n",
    "        # We need to scale the SAM mask to the input_size for direct overlay if original_img is resized,\n",
    "        # but the mask itself comes from the SAM processed image which might be 1024x1024.\n",
    "        # For display simplicity, we'll just show the original mask over the original image,\n",
    "        # ensuring the aspect ratio aligns.\n",
    "        mask_display = sam_mask_np # Boolean mask\n",
    "        axes[1].imshow(original_img) # Overlay on original\n",
    "        # For plotting mask, we scale it to match the original image's aspect ratio/size if necessary for correct overlay\n",
    "        # Since SAM masks are usually for specific input sizes (e.g., 1024x1024), we should ensure it fits.\n",
    "        # However, for simplicity here, we assume the mask is compatible or will be interpolated by imshow.\n",
    "        show_mask(mask_display, axes[1], random_color=False, borders=True) # Use the show_mask helper\n",
    "        axes[1].set_title(f'Máscara SAM {mask_idx}')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        # Plot 3: Object Feature Map (visualización de PCA)\n",
    "        # Reshape C, H, W to (H*W, C) for PCA\n",
    "        if object_feature_map_tensor.numel() == 0:\n",
    "            axes[2].text(0.5, 0.5, \"No hay características de objeto\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "            axes[2].set_title('Mapa de Características de Objeto (Vacío)')\n",
    "            axes[2].axis('off')\n",
    "        else:\n",
    "            ofm_cpu = object_feature_map_tensor.squeeze().cpu().numpy() # Remove batch dim if present\n",
    "            if ofm_cpu.ndim == 3: # C, H, W\n",
    "                C, H, W = ofm_cpu.shape\n",
    "                ofm_reshaped = ofm_cpu.transpose(1, 2, 0).reshape(-1, C) # H*W, C\n",
    "\n",
    "                if C > 3: # Apply PCA if more than 3 channels\n",
    "                    pca = PCA(n_components=3)\n",
    "                    ofm_pca = pca.fit_transform(ofm_reshaped)\n",
    "                    # Normalize PCA results to [0, 1] for image display\n",
    "                    ofm_pca_normalized = (ofm_pca - ofm_pca.min()) / (ofm_pca.max() - ofm_pca.min() + 1e-8)\n",
    "                    ofm_display = ofm_pca_normalized.reshape(H, W, 3)\n",
    "                    axes[2].imshow(ofm_display)\n",
    "                    axes[2].set_title(f'Mapa de Características de Objeto (PCA)\\nMáscara {mask_idx}')\n",
    "                else: # If 1, 2, or 3 channels, display directly (grayscale or RGB)\n",
    "                    if C == 1:\n",
    "                        ofm_display = ofm_cpu.squeeze()\n",
    "                        axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                    elif C == 3:\n",
    "                        ofm_display = ofm_cpu.transpose(1, 2, 0) # H, W, C\n",
    "                        ofm_display_norm = (ofm_display - ofm_display.min()) / (ofm_display.max() - ofm_display.min() + 1e-8)\n",
    "                        axes[2].imshow(ofm_display_norm)\n",
    "                    else: # 2 channels, or other, might not display well as RGB. Use grayscale of first channel.\n",
    "                        ofm_display = ofm_cpu[0]\n",
    "                        axes[2].imshow(ofm_display, cmap='viridis')\n",
    "                    axes[2].set_title(f'Mapa de Características de Objeto\\nMáscara {mask_idx}')\n",
    "            else: # If the object_feature_map_tensor somehow resulted in a non-3D tensor for a single mask\n",
    "                axes[2].text(0.5, 0.5, \"Formato de características de objeto inesperado\", ha='center', va='center', transform=axes[2].transAxes)\n",
    "                axes[2].set_title('Mapa de Características de Objeto (Error)')\n",
    "\n",
    "            axes[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(plot_save_dir, f\"{plot_filename_prefix}_mask_{mask_idx}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "        # print(f\"Visualización del mapa de características de objeto guardada en: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al visualizar el mapa de características de objeto para máscara {mask_idx} de {os.path.basename(original_image_path)}: {e}\")\n",
    "\n",
    "# --- Aplicar el proceso a la imagen de consulta y a las imágenes de referencia ---\n",
    "\n",
    "print(\"\\n--- Generando Mapas de Características de Objeto ---\")\n",
    "\n",
    "# Dimensiones objetivo para las máscaras después de escalar (8H', 8W')\n",
    "TARGET_MASK_H = 8 * H_prime # 8 * 16 = 128\n",
    "TARGET_MASK_W = 8 * W_prime # 8 * 16 = 128\n",
    "print(f\"TARGET_MASK_H: {TARGET_MASK_H}\")\n",
    "print(f\"TARGET_MASK_W: {TARGET_MASK_W}\")\n",
    "\n",
    "# # Para la imagen de consulta (Iq)\n",
    "# fobj_q = process_masks_to_object_feature_maps(\n",
    "#     masks_data_query_image,\n",
    "#     query_hr_feats.squeeze(0), # Pasamos (C, 8H', 8W') para que la función maneje el batch\n",
    "#     TARGET_MASK_H,\n",
    "#     TARGET_MASK_W,\n",
    "#     image_for_sam_np.shape # Pasamos la forma real de la imagen que SAM procesó\n",
    "# ).to(device) # Mover a la GPU si no está ya\n",
    "\n",
    "fobj_q, scaled_masks = process_masks_to_object_feature_maps(\n",
    "    masks_data_query_image,\n",
    "    query_hr_feats.squeeze(0), # Pasamos (C, 8H', 8W') para que la función maneje el batch\n",
    "    TARGET_MASK_H,\n",
    "    TARGET_MASK_W,\n",
    "    image_for_sam_np.shape # Pasamos la forma real de la imagen que SAM procesó\n",
    ")\n",
    "\n",
    "# Mover el tensor `fobj_q` a la GPU si no está ya\n",
    "fobj_q = fobj_q.to(device)\n",
    "\n",
    "\n",
    "print(f\"Dimensiones de fobj_q (Mapas de Características de Objeto de Iq): {fobj_q.shape}\") # Esperado (M, 384, 128, 128)\n",
    "\n",
    "# Para las imágenes de referencia (Ir)\n",
    "all_fobj_r_list = [] # Para almacenar fobj_r para cada imagen similar\n",
    "for i, similar_hr_feats in enumerate(similar_hr_feats_list):\n",
    "    current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "    # Necesitamos obtener la forma original de la imagen similar para SAM\n",
    "    img_similar_pil = Image.open(rutas_imagenes_similares[i]).convert('RGB') # Cargar de nuevo para obtener su forma\n",
    "    image_np_similar_for_sam_shape = np.array(img_similar_pil).shape\n",
    "\n",
    "    fobj_r_current, scaled_masks = process_masks_to_object_feature_maps(\n",
    "        current_similar_masks_raw,\n",
    "        similar_hr_feats.squeeze(0), # Pasamos (C, 8H', 8W')\n",
    "        TARGET_MASK_H,\n",
    "        TARGET_MASK_W,\n",
    "        image_np_similar_for_sam_shape # Pasamos la forma real de la imagen que SAM procesó\n",
    "    )\n",
    "    fobj_r_current = fobj_r_current.to(device)\n",
    "    \n",
    "    all_fobj_r_list.append(fobj_r_current)\n",
    "    print(f\"Dimensiones de fobj_r para vecino {i+1}: {fobj_r_current.shape}\") # Esperado (N, 384, 128, 128)\n",
    "    # Imprimir el tipo de cada elemento en all_fobj_r_list\n",
    "    print(\"\\nTipos de los elementos en all_fobj_r_list:\")\n",
    "    for idx, fobj_r in enumerate(all_fobj_r_list):\n",
    "        print(f\"Vecino {idx + 1}: Tipo de fobj_r:\", type(fobj_r))\n",
    "print(\"\\nProceso de 'Object Feature Map' completado. ¡Ahora tienes los fobj_q y fobj_r listos!\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Directorio para guardar plots de Mapas de Características de Objeto ---\n",
    "OFM_PLOTS_DIR = os.path.join(PLOT_SAVE_ROOT_DIR, \"object_feature_map_plots\")\n",
    "os.makedirs(OFM_PLOTS_DIR, exist_ok=True)\n",
    "print(f\"\\nLos plots de Mapas de Características de Objeto se guardarán en: {OFM_PLOTS_DIR}\")\n",
    "\n",
    "# Visualización para la imagen de consulta (Iq)\n",
    "print(\"\\nGenerando visualizaciones de Mapas de Características de Objeto para la consulta...\")\n",
    "for i, mask_info in enumerate(masks_data_query_image):\n",
    "    # fobj_q es (M, C, H, W). Necesitamos una máscara a la vez.\n",
    "    if i < fobj_q.shape[0]: # Asegurarse de que tenemos un OFM para esta máscara\n",
    "        visualize_object_feature_map(\n",
    "            query_image_path,\n",
    "            mask_info,\n",
    "            query_hr_feats, # Pasamos el HR feature map completo\n",
    "            fobj_q[i].unsqueeze(0), # Pasamos solo el OFM de la máscara actual, con batch dim para la función\n",
    "            TARGET_MASK_H,\n",
    "            TARGET_MASK_W,\n",
    "            OFM_PLOTS_DIR,\n",
    "            f\"query_{base_image_name.replace('.png', '')}\",\n",
    "            i,\n",
    "            image_for_sam_np.shape\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontró OFM para la máscara de consulta {i}.\")\n",
    "\n",
    "# Visualización para las imágenes de referencia (Ir)\n",
    "print(\"\\nGenerando visualizaciones de Mapas de Características de Objeto para los vecinos...\")\n",
    "for i, similar_image_path in enumerate(rutas_imagenes_similares):\n",
    "    current_similar_masks_raw = similar_masks_raw_list[i]\n",
    "    current_similar_hr_feats = similar_hr_feats_list[i]\n",
    "    current_fobj_r = all_fobj_r_list[i]\n",
    "    img_similar_pil_for_shape = Image.open(similar_image_path).convert('RGB')\n",
    "    image_np_similar_for_sam_shape = np.array(img_similar_pil_for_shape).shape\n",
    "\n",
    "    if not current_fobj_r.numel() == 0: # Solo procesar si hay OFMs generados para este vecino\n",
    "        for j, mask_info in enumerate(current_similar_masks_raw):\n",
    "            if j < current_fobj_r.shape[0]: # Asegurarse de que tenemos un OFM para esta máscara\n",
    "                visualize_object_feature_map(\n",
    "                    similar_image_path,\n",
    "                    mask_info,\n",
    "                    current_similar_hr_feats,\n",
    "                    current_fobj_r[j].unsqueeze(0), # OFM de la máscara actual\n",
    "                    TARGET_MASK_H,\n",
    "                    TARGET_MASK_W,\n",
    "                    OFM_PLOTS_DIR,\n",
    "                    f\"neighbor_{i+1}_{os.path.basename(similar_image_path).replace('.png', '')}\",\n",
    "                    j,\n",
    "                    image_np_similar_for_sam_shape\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Advertencia: No se encontró OFM para la máscara {j} del vecino {i+1}.\")\n",
    "    else:\n",
    "        print(f\"No se generaron OFMs para el vecino {i+1} ({os.path.basename(similar_image_path)}), saltando visualización.\")\n",
    "\n",
    "print(\"\\nVisualización de Mapas de Características de Objeto completada.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de fobj_q_pooled: torch.Size([6, 384])\n",
      "Máximo de fobj_q_pooled: 5.209421157836914\n",
      "Mínimo de fobj_q_pooled: 0.0\n",
      "Máximo de d_M_q: 0.23235014081001282\n",
      "Mínimo de d_M_q: 0.0\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8560, 0.9546, 2.3600],\n",
      "        [0.9638, 0.8476, 2.3600],\n",
      "        [0.7423, 0.8525, 2.3600],\n",
      "        [0.7580, 0.8661, 2.3600],\n",
      "        [0.8452, 0.9654, 2.3600],\n",
      "        [0.7624, 0.8751, 2.3600],\n",
      "        [2.3600, 2.3600, 2.3600]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[5.2205e+03, 1.3982e+04, 1.7756e+10],\n",
      "        [1.5342e+04, 4.7985e+03, 1.7756e+10],\n",
      "        [1.6743e+03, 5.0400e+03, 1.7756e+10],\n",
      "        [1.9594e+03, 5.7723e+03, 1.7756e+10],\n",
      "        [4.6826e+03, 1.5591e+04, 1.7756e+10],\n",
      "        [2.0477e+03, 6.3175e+03, 1.7756e+10],\n",
      "        [1.7756e+10, 1.7756e+10, 1.7756e+10]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.8748, 0.9343, 2.3600],\n",
      "        [0.9416, 0.8438, 2.3600],\n",
      "        [0.7668, 0.8355, 2.3600],\n",
      "        [0.7794, 0.8541, 2.3600],\n",
      "        [0.8645, 0.9437, 2.3600],\n",
      "        [0.7870, 0.8607, 2.3600],\n",
      "        [2.3600, 2.3600, 2.3600]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[6.2967e+03, 1.1420e+04, 1.7756e+10],\n",
      "        [1.2279e+04, 4.6203e+03, 1.7756e+10],\n",
      "        [2.1382e+03, 4.2514e+03, 1.7756e+10],\n",
      "        [2.4257e+03, 5.1229e+03, 1.7756e+10],\n",
      "        [5.6823e+03, 1.2543e+04, 1.7756e+10],\n",
      "        [2.6168e+03, 5.4684e+03, 1.7756e+10],\n",
      "        [1.7756e+10, 1.7756e+10, 1.7756e+10]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "S_augmented antes de Sinkhorn:\n",
      " tensor([[0.9453, 0.8438, 2.3600],\n",
      "        [0.8787, 0.9521, 2.3600],\n",
      "        [0.8358, 0.7369, 2.3600],\n",
      "        [0.8503, 0.7499, 2.3600],\n",
      "        [0.9545, 0.8237, 2.3600],\n",
      "        [0.8597, 0.7537, 2.3600],\n",
      "        [2.3600, 2.3600, 2.3600]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "K (antes de Sinkhorn):\n",
      " tensor([[1.2752e+04, 4.6201e+03, 1.7756e+10],\n",
      "        [6.5516e+03, 1.3643e+04, 1.7756e+10],\n",
      "        [4.2641e+03, 1.5862e+03, 1.7756e+10],\n",
      "        [4.9280e+03, 1.8069e+03, 1.7756e+10],\n",
      "        [1.3981e+04, 3.7800e+03, 1.7756e+10],\n",
      "        [5.4149e+03, 1.8758e+03, 1.7756e+10],\n",
      "        [1.7756e+10, 1.7756e+10, 1.7756e+10]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "\n",
      "--- Matrices P y P_augmented_full generadas ---\n",
      "\n",
      "--- Resultados Consolidados ---\n",
      "all_matched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "  Objeto de Consulta 2: []\n",
      "  Objeto de Consulta 3: []\n",
      "  Objeto de Consulta 4: []\n",
      "  Objeto de Consulta 5: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj:\n",
      "  Objeto de Consulta 0: []\n",
      "  Objeto de Consulta 1: []\n",
      "  Objeto de Consulta 2: []\n",
      "  Objeto de Consulta 3: []\n",
      "  Objeto de Consulta 4: []\n",
      "  Objeto de Consulta 5: []\n",
      "\n",
      "--- Vecino Vecino_1 ---\n",
      "Matriz P (MxN) para el vecino Vecino_1:\n",
      "tensor([[0.1188, 0.1861],\n",
      "        [0.2788, 0.0510],\n",
      "        [0.0713, 0.1256],\n",
      "        [0.0779, 0.1343],\n",
      "        [0.1043, 0.2032],\n",
      "        [0.0785, 0.1417]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_1:\n",
      "tensor([[1.1877e-01, 1.8609e-01, 1.2371e-01],\n",
      "        [2.7877e-01, 5.1004e-02, 9.8799e-02],\n",
      "        [7.1328e-02, 1.2560e-01, 2.3164e-01],\n",
      "        [7.7944e-02, 1.3432e-01, 2.1630e-01],\n",
      "        [1.0430e-01, 2.0315e-01, 1.2112e-01],\n",
      "        [7.8490e-02, 1.4166e-01, 2.0842e-01],\n",
      "        [2.7039e-01, 1.5818e-01, 8.2804e-08]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[1.1877e-01, 1.8609e-01, 1.2371e-01, 4.2857e-01],\n",
      "        [2.7877e-01, 5.1004e-02, 9.8799e-02, 4.2857e-01],\n",
      "        [7.1328e-02, 1.2560e-01, 2.3164e-01, 4.2857e-01],\n",
      "        [7.7944e-02, 1.3432e-01, 2.1630e-01, 4.2857e-01],\n",
      "        [1.0430e-01, 2.0315e-01, 1.2112e-01, 4.2857e-01],\n",
      "        [7.8490e-02, 1.4166e-01, 2.0842e-01, 4.2857e-01],\n",
      "        [2.7039e-01, 1.5818e-01, 8.2804e-08, 4.2857e-01],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00, 3.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_1 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.1861 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.1237\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.2788 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.0988\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 2:\n",
      "     Probabilidad máxima en P: 0.1256 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2316\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 1\n",
      "   Objeto de Consulta 3:\n",
      "     Probabilidad máxima en P: 0.1343 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2163\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 1\n",
      "   Objeto de Consulta 4:\n",
      "     Probabilidad máxima en P: 0.2032 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.1211\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "   Objeto de Consulta 5:\n",
      "     Probabilidad máxima en P: 0.1417 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2084\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 1\n",
      "\n",
      "--- Vecino Vecino_2 ---\n",
      "Matriz P (MxN) para el vecino Vecino_2:\n",
      "tensor([[0.1316, 0.1740],\n",
      "        [0.2444, 0.0670],\n",
      "        [0.0824, 0.1194],\n",
      "        [0.0863, 0.1329],\n",
      "        [0.1176, 0.1892],\n",
      "        [0.0898, 0.1368]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_2:\n",
      "tensor([[1.3160e-01, 1.7398e-01, 1.2299e-01],\n",
      "        [2.4441e-01, 6.7036e-02, 1.1713e-01],\n",
      "        [8.2397e-02, 1.1942e-01, 2.2676e-01],\n",
      "        [8.6311e-02, 1.3287e-01, 2.0939e-01],\n",
      "        [1.1759e-01, 1.8920e-01, 1.2178e-01],\n",
      "        [8.9809e-02, 1.3680e-01, 2.0196e-01],\n",
      "        [2.4788e-01, 1.8069e-01, 8.2150e-08]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[1.3160e-01, 1.7398e-01, 1.2299e-01, 4.2857e-01],\n",
      "        [2.4441e-01, 6.7036e-02, 1.1713e-01, 4.2857e-01],\n",
      "        [8.2397e-02, 1.1942e-01, 2.2676e-01, 4.2857e-01],\n",
      "        [8.6311e-02, 1.3287e-01, 2.0939e-01, 4.2857e-01],\n",
      "        [1.1759e-01, 1.8920e-01, 1.2178e-01, 4.2857e-01],\n",
      "        [8.9809e-02, 1.3680e-01, 2.0196e-01, 4.2857e-01],\n",
      "        [2.4788e-01, 1.8069e-01, 8.2150e-08, 4.2857e-01],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00, 3.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_2 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.1740 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.1230\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.2444 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.1171\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 2:\n",
      "     Probabilidad máxima en P: 0.1194 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2268\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 1\n",
      "   Objeto de Consulta 3:\n",
      "     Probabilidad máxima en P: 0.1329 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2094\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 1\n",
      "   Objeto de Consulta 4:\n",
      "     Probabilidad máxima en P: 0.1892 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.1218\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "   Objeto de Consulta 5:\n",
      "     Probabilidad máxima en P: 0.1368 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.2020\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 1\n",
      "\n",
      "--- Vecino Vecino_3 ---\n",
      "Matriz P (MxN) para el vecino Vecino_3:\n",
      "tensor([[0.1863, 0.1194],\n",
      "        [0.0718, 0.2646],\n",
      "        [0.1180, 0.0777],\n",
      "        [0.1277, 0.0829],\n",
      "        [0.2060, 0.0986],\n",
      "        [0.1354, 0.0830]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Matriz P_augmented_full (M+1 x N+1) para el vecino Vecino_3:\n",
      "tensor([[1.8628e-01, 1.1943e-01, 1.2286e-01],\n",
      "        [7.1803e-02, 2.6460e-01, 9.2172e-02],\n",
      "        [1.1804e-01, 7.7706e-02, 2.3282e-01],\n",
      "        [1.2772e-01, 8.2874e-02, 2.1797e-01],\n",
      "        [2.0605e-01, 9.8581e-02, 1.2394e-01],\n",
      "        [1.3536e-01, 8.2978e-02, 2.1023e-01],\n",
      "        [1.5474e-01, 2.7383e-01, 7.3292e-08]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Matriz P_augmented_full con totales (M+2 x N+2):\n",
      "tensor([[1.8628e-01, 1.1943e-01, 1.2286e-01, 4.2857e-01],\n",
      "        [7.1803e-02, 2.6460e-01, 9.2172e-02, 4.2857e-01],\n",
      "        [1.1804e-01, 7.7706e-02, 2.3282e-01, 4.2857e-01],\n",
      "        [1.2772e-01, 8.2874e-02, 2.1797e-01, 4.2857e-01],\n",
      "        [2.0605e-01, 9.8581e-02, 1.2394e-01, 4.2857e-01],\n",
      "        [1.3536e-01, 8.2978e-02, 2.1023e-01, 4.2857e-01],\n",
      "        [1.5474e-01, 2.7383e-01, 7.3292e-08, 4.2857e-01],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00, 3.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "\n",
      "--- Decisiones de Emparejamiento para el Vecino Vecino_3 ---\n",
      "   Objeto de Consulta 0:\n",
      "     Probabilidad máxima en P: 0.1863 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.1229\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 1:\n",
      "     Probabilidad máxima en P: 0.2646 en el índice 1\n",
      "     Probabilidad en el 'Trash Bin': 0.0922\n",
      "     Decisión: EMPAREJADO con objeto de imagen 1\n",
      "   Objeto de Consulta 2:\n",
      "     Probabilidad máxima en P: 0.1180 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.2328\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "   Objeto de Consulta 3:\n",
      "     Probabilidad máxima en P: 0.1277 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.2180\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "   Objeto de Consulta 4:\n",
      "     Probabilidad máxima en P: 0.2060 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.1239\n",
      "     Decisión: EMPAREJADO con objeto de imagen 0\n",
      "   Objeto de Consulta 5:\n",
      "     Probabilidad máxima en P: 0.1354 en el índice 0\n",
      "     Probabilidad en el 'Trash Bin': 0.2102\n",
      "     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto 0\n",
      "\n",
      "--- Resultados Finales Consolidados (Índices) ---\n",
      "all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\n",
      "  Query 0: [(0, 1), (1, 1), (2, 0)]\n",
      "  Query 1: [(0, 0), (1, 0), (2, 1)]\n",
      "  Query 2: []\n",
      "  Query 3: []\n",
      "  Query 4: [(0, 1), (1, 1), (2, 0)]\n",
      "  Query 5: []\n",
      "\n",
      "all_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\n",
      "  Query 0: []\n",
      "  Query 1: []\n",
      "  Query 2: [(0, 1), (1, 1), (2, 0)]\n",
      "  Query 3: [(0, 1), (1, 1), (2, 0)]\n",
      "  Query 4: []\n",
      "  Query 5: [(0, 1), (1, 1), (2, 0)]\n"
     ]
    }
   ],
   "source": [
    "# -----------3.5.2 Object matching module-----------------\n",
    "## Matching\n",
    "# --- Definición de la función show_anomalies_on_image ---\n",
    "def show_anomalies_on_image(image_np, masks, anomalous_info, alpha=0.5, save_path=None):\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_np)\n",
    "\n",
    "    for obj_id, similarity in anomalous_info: # Iterate through (id, similarity) tuples\n",
    "        # Extraer la máscara binaria real\n",
    "        mask = masks[obj_id]['segmentation']\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.cpu().numpy()\n",
    "\n",
    "        # Crear máscara en rojo\n",
    "        colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "        colored_mask[mask > 0] = [255, 0, 0]\n",
    "        plt.imshow(colored_mask, alpha=alpha)\n",
    "\n",
    "        # Calcular centroide para colocar el texto\n",
    "        ys, xs = np.where(mask > 0)\n",
    "        if len(xs) > 0 and len(ys) > 0:\n",
    "            cx = int(xs.mean())\n",
    "            cy = int(ys.mean())\n",
    "            \n",
    "            # Create text with index and percentage\n",
    "            text_label = f\"{obj_id} ({similarity*100:.2f}%)\"\n",
    "            plt.text(cx, cy, text_label, color='white', fontsize=10, fontweight='bold', ha='center', va='center',\n",
    "                     bbox=dict(facecolor='red', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "    plt.title(\"Objetos Anómalos en Rojo con Índice y Similitud\") # Updated title for clarity\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Plot de anomalías guardado en: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "# --- Fin de la definición de la función show_anomalies_on_image ---\n",
    "# --- Nuevas funciones de ploteo para la matriz P y P_augmented_full ---\n",
    "def plot_assignment_matrix(P_matrix, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación P\"):\n",
    "    \"\"\"\n",
    "    Visualiza la matriz de asignación P como un mapa de calor.\n",
    "\n",
    "    Args:\n",
    "        P_matrix (torch.Tensor or np.array): La matriz de asignación (M x N).\n",
    "        query_labels (list): Etiquetas para los objetos de consulta (eje Y).\n",
    "        reference_labels (list): Etiquetas para los objetos de referencia (eje X).\n",
    "        save_path (str, optional): Ruta para guardar la imagen del plot.\n",
    "        title (str): Título del plot.\n",
    "    \"\"\"\n",
    "    if isinstance(P_matrix, torch.Tensor):\n",
    "        #P_matrix = P_matrix.cpu().numpy()\n",
    "        P_matrix = P_matrix.detach().cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(P_matrix.shape[1] * 0.8 + 2, P_matrix.shape[0] * 0.8 + 2))\n",
    "    plt.imshow(P_matrix, cmap='viridis', origin='upper', aspect='auto')\n",
    "    plt.colorbar(label='Probabilidad de Asignación')\n",
    "    plt.xticks(np.arange(len(reference_labels)), reference_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(np.arange(len(query_labels)), query_labels)\n",
    "    plt.xlabel('Objetos de Referencia')\n",
    "    plt.ylabel('Objetos de Consulta')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Plot de la matriz de asignación guardado en: {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_augmented_assignment_matrix(P_augmented_full, query_labels, reference_labels, save_path=None, title=\"Matriz de Asignación Aumentada (con Trash Bin)\"):\n",
    "    \"\"\"\n",
    "    Visualiza la matriz de asignación aumentada (incluyendo los trash bins) como un mapa de calor.\n",
    "\n",
    "    Args:\n",
    "        P_augmented_full (torch.Tensor or np.array): La matriz de asignación aumentada ((M+1) x (N+1)).\n",
    "        query_labels (list): Etiquetas para los objetos de consulta.\n",
    "        reference_labels (list): Etiquetas para los objetos de referencia.\n",
    "        save_path (str, optional): Ruta para guardar la imagen del plot.\n",
    "        title (str): Título del plot.\n",
    "    \"\"\"\n",
    "    if isinstance(P_augmented_full, torch.Tensor):\n",
    "        #P_augmented_full = P_augmented_full.cpu().numpy()\n",
    "        P_augmented_full = P_augmented_full.detach().cpu().numpy()\n",
    "\n",
    "    # Añadir etiquetas para los trash bins\n",
    "    full_query_labels = [f\"Q_{i}\" for i in query_labels] + [\"Trash Bin (Q)\"]\n",
    "    full_reference_labels = [f\"R_{i}\" for i in reference_labels] + [\"Trash Bin (R)\"]\n",
    "\n",
    "    plt.figure(figsize=(P_augmented_full.shape[1] * 0.8 + 2, P_augmented_full.shape[0] * 0.8 + 2))\n",
    "    plt.imshow(P_augmented_full, cmap='viridis', origin='upper', aspect='auto')\n",
    "    plt.colorbar(label='Probabilidad de Asignación')\n",
    "    plt.xticks(np.arange(len(full_reference_labels)), full_reference_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(np.arange(len(full_query_labels)), full_query_labels)\n",
    "    plt.xlabel('Objetos de Referencia y Trash Bin')\n",
    "    plt.ylabel('Objetos de Consulta y Trash Bin')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Plot de la matriz de asignación aumentada guardado en: {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# --- Fin de las nuevas funciones de ploteo ---\n",
    "\n",
    "## Matching-continue---\n",
    "## Matching\n",
    "start_time_sam_matching = time.time()\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def apply_global_max_pool(feat_map):\n",
    "    return F.adaptive_max_pool2d(feat_map, output_size=1).squeeze(-1).squeeze(-1)\n",
    "\n",
    "class SimpleObjectMatchingModule(nn.Module):\n",
    "    def __init__(self, sinkhorn_iterations=100, sinkhorn_epsilon=0.1, bin_score_value=0.5):\n",
    "        super(SimpleObjectMatchingModule, self).__init__()\n",
    "        self.sinkhorn_iterations = sinkhorn_iterations\n",
    "        self.sinkhorn_epsilon = sinkhorn_epsilon\n",
    "        self.z = nn.Parameter(torch.tensor(bin_score_value, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, d_M_q, d_N_r):\n",
    "        M = d_M_q.shape[0]\n",
    "        N = d_N_r.shape[0]\n",
    "\n",
    "        if M == 0 or N == 0:\n",
    "            return torch.empty(M, N, device=d_M_q.device), \\\n",
    "                   torch.empty(M+1, N+1, device=d_M_q.device)\n",
    "\n",
    "        score_matrix = torch.mm(d_M_q, d_N_r.T)\n",
    "        #print(\"score_matrix (antes de Sinkhorn):\\n\", score_matrix)\n",
    "\n",
    "        S_augmented = torch.zeros((M + 1, N + 1), device=d_M_q.device, dtype=d_M_q.dtype)\n",
    "        S_augmented[:M, :N] = score_matrix\n",
    "        S_augmented[:M, N] = self.z\n",
    "        S_augmented[M, :N] = self.z\n",
    "        S_augmented[M, N] = self.z\n",
    "        print(\"S_augmented antes de Sinkhorn:\\n\", S_augmented)\n",
    "\n",
    "        K = torch.exp(S_augmented / self.sinkhorn_epsilon)\n",
    "        print(\"K (antes de Sinkhorn):\\n\", K)\n",
    "        \n",
    "\n",
    "        for i in range(self.sinkhorn_iterations):\n",
    "            K = K / K.sum(dim=1, keepdim=True)\n",
    "            K = K / K.sum(dim=0, keepdim=True)\n",
    "            #print(f\"Iteración {i+1}: K.shape = {K}\")\n",
    "\n",
    "        P_augmented_full = K\n",
    "        P = P_augmented_full[:M, :N]\n",
    "\n",
    "        return P, P_augmented_full\n",
    "\n",
    "fobj_q_pooled = apply_global_max_pool(fobj_q)\n",
    "print(\"Shape de fobj_q_pooled:\", fobj_q_pooled.shape)\n",
    "print(\"Máximo de fobj_q_pooled:\", torch.max(fobj_q_pooled).item())\n",
    "print(\"Mínimo de fobj_q_pooled:\", torch.min(fobj_q_pooled).item())\n",
    "\n",
    "all_fobj_r_pooled_list = []\n",
    "for fobj_r_current in all_fobj_r_list:\n",
    "    pooled_r = apply_global_max_pool(fobj_r_current)\n",
    "    all_fobj_r_pooled_list.append(pooled_r)\n",
    "    \n",
    "d_M_q = F.normalize(fobj_q_pooled, p=2, dim=1) #shape (M, C)\n",
    "d_N_r_list = [F.normalize(fobj_r_pooled, p=2, dim=1) \n",
    "                              for fobj_r_pooled in all_fobj_r_pooled_list]\n",
    "print(\"Máximo de d_M_q:\", torch.max(d_M_q).item())\n",
    "print(\"Mínimo de d_M_q:\", torch.min(d_M_q).item())\n",
    "\n",
    "object_matching_module = SimpleObjectMatchingModule(\n",
    "    sinkhorn_iterations=50,\n",
    "    sinkhorn_epsilon=0.1,\n",
    "    bin_score_value=2.36\n",
    ").to(device)\n",
    "\n",
    "P_matrices = []\n",
    "P_augmented_full_matrices = []\n",
    "\n",
    "for i, d_N_r_current_image in enumerate(d_N_r_list):\n",
    "    d_M_q_cuda = d_M_q.to(device)\n",
    "    d_N_r_current_image_cuda = d_N_r_current_image.to(device)\n",
    "\n",
    "    P_current, P_augmented_current = object_matching_module(d_M_q_cuda, d_N_r_current_image_cuda)\n",
    "    P_matrices.append(P_current)\n",
    "    P_augmented_full_matrices.append(P_augmented_current)\n",
    "\n",
    "\n",
    "print(\"\\n--- Matrices P y P_augmented_full generadas ---\")\n",
    "# --- NUEVOS DICCIONARIOS CONSOLIDADOS ---\n",
    "# Almacenarán para cada query_idx, las referencias que le corresponden de TODOS los vecinos.\n",
    "M = d_M_q.shape[0]\n",
    "all_matched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)} # M es el número de objetos de consulta (Iq)\n",
    "all_closest_unmatched_ref_indices_by_query_obj = {q_idx: [] for q_idx in range(M)}\n",
    "# Imprimir shapes de los diccionarios consolidados\n",
    "#//////\n",
    "print(\"\\n--- Resultados Consolidados ---\")\n",
    "print(\"all_matched_ref_indices_by_query_obj:\")\n",
    "for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Objeto de Consulta {q_idx}: {matches}\")\n",
    "\n",
    "print(\"\\nall_closest_unmatched_ref_indices_by_query_obj:\")\n",
    "for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Objeto de Consulta {q_idx}: {closest_unmatches}\")\n",
    "#/////////////////\n",
    "# Procesar matrices P y P_augmented_full para obtener índices\n",
    "for i, (P, P_augmented_full) in enumerate(zip(P_matrices, P_augmented_full_matrices)):\n",
    "    current_neighbor_key = f\"Vecino_{i+1}\"\n",
    "    N_current = P.shape[1] \n",
    "\n",
    "    print(f\"\\n--- Vecino {current_neighbor_key} ---\")\n",
    "    print(f\"Matriz P (MxN) para el vecino {current_neighbor_key}:\")\n",
    "    print(P)\n",
    "    print(f\"Matriz P_augmented_full (M+1 x N+1) para el vecino {current_neighbor_key}:\")\n",
    "    print(P_augmented_full)\n",
    "\n",
    "    # Imprimir sumas de filas y columnas de P_augmented_full\n",
    "    augmented_with_totals = torch.cat([\n",
    "        torch.cat([P_augmented_full, P_augmented_full.sum(dim=0, keepdim=True)], dim=0),\n",
    "        torch.cat([P_augmented_full.sum(dim=1, keepdim=True), P_augmented_full.sum().unsqueeze(0).unsqueeze(0)], dim=0)\n",
    "    ], dim=1)\n",
    "    print(f\"Matriz P_augmented_full con totales (M+2 x N+2):\\n{augmented_with_totals}\")\n",
    "\n",
    "    print(f\"\\n--- Decisiones de Emparejamiento para el Vecino {current_neighbor_key} ---\")\n",
    "    for obj_idx in range(P.shape[0]):\n",
    "        \n",
    "        # Obtener la probabilidad más alta dentro de P y su índice\n",
    "        if N_current > 0:\n",
    "            max_prob_P = P[obj_idx].max().item()\n",
    "            max_idx_P = P[obj_idx].argmax().item()\n",
    "        else:\n",
    "            max_prob_P = -float('inf')\n",
    "            max_idx_P = -1\n",
    "\n",
    "\n",
    "        trash_bin_prob = P_augmented_full[obj_idx, -1].item() \n",
    "\n",
    "        print(f\"   Objeto de Consulta {obj_idx}:\")\n",
    "        print(f\"     Probabilidad máxima en P: {max_prob_P:.4f} en el índice {max_idx_P}\")\n",
    "        print(f\"     Probabilidad en el 'Trash Bin': {trash_bin_prob:.4f}\")\n",
    "\n",
    "\n",
    "       # Decisión y almacenamiento en los diccionarios consolidados\n",
    "        if trash_bin_prob > max_prob_P:\n",
    "            # Desemparejado: ahora añadimos el 'primer máximo' a la lista de ese objeto de consulta\n",
    "            if max_idx_P != -1: # Solo añadir si hay un 'primer máximo' válido\n",
    "                all_closest_unmatched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "            print(f\"     Decisión: DESEMPAREJADO. 'Casi-par' (PRIMER más similar en P): objeto {max_idx_P}\")\n",
    "        else:\n",
    "            # Emparejado: añadir el emparejamiento real a la lista de ese objeto de consulta\n",
    "            all_matched_ref_indices_by_query_obj[obj_idx].append((i, max_idx_P)) # (índice_vecino, índice_referencia)\n",
    "            print(f\"     Decisión: EMPAREJADO con objeto de imagen {max_idx_P}\")\n",
    "\n",
    "\n",
    "# --- Resultados Finales Consolidados ---\n",
    "print(\"\\n--- Resultados Finales Consolidados (Índices) ---\")\n",
    "print(\"all_matched_ref_indices_by_query_obj (query_idx: [(vecino_idx, ref_idx), ...]):\")\n",
    "for q_idx, matches in all_matched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Query {q_idx}: {matches}\")\n",
    "\n",
    "print(\"\\nall_closest_unmatched_ref_indices_by_query_obj (query_idx: [(vecino_idx, second_ref_idx), ...]):\")\n",
    "for q_idx, closest_unmatches in all_closest_unmatched_ref_indices_by_query_obj.items():\n",
    "    print(f\"  Query {q_idx}: {closest_unmatches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gráfico guardado en: /home/imercatoma/FeatUp/plots_single_3/cut_001/matched_unmatched_plots/object_Q0_matched_unmatched.png\n",
      "✅ Gráfico guardado en: /home/imercatoma/FeatUp/plots_single_3/cut_001/matched_unmatched_plots/object_Q1_matched_unmatched.png\n",
      "✅ Gráfico guardado en: /home/imercatoma/FeatUp/plots_single_3/cut_001/matched_unmatched_plots/object_Q2_matched_unmatched.png\n",
      "✅ Gráfico guardado en: /home/imercatoma/FeatUp/plots_single_3/cut_001/matched_unmatched_plots/object_Q3_matched_unmatched.png\n",
      "✅ Gráfico guardado en: /home/imercatoma/FeatUp/plots_single_3/cut_001/matched_unmatched_plots/object_Q4_matched_unmatched.png\n",
      "✅ Gráfico guardado en: /home/imercatoma/FeatUp/plots_single_3/cut_001/matched_unmatched_plots/object_Q5_matched_unmatched.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Función para graficar objetos de consulta y sus coincidencias ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_matched_and_unmatched_objects(query_image_path, neighbor_image_paths, query_masks, neighbor_masks_list, matched_indices, unmatched_indices, output_dir):\n",
    "    \"\"\"\n",
    "    Grafica los objetos de consulta y sus coincidencias (matched/unmatched) con los vecinos.\n",
    "\n",
    "    Args:\n",
    "        query_image_path (str): Ruta de la imagen de consulta.\n",
    "        neighbor_image_paths (list): Lista de rutas de imágenes de vecinos.\n",
    "        query_masks (list): Máscaras de objetos de consulta.\n",
    "        neighbor_masks_list (list): Lista de listas de máscaras de objetos de vecinos.\n",
    "        matched_indices (dict): Diccionario con índices de objetos emparejados.\n",
    "        unmatched_indices (dict): Diccionario con índices de objetos no emparejados.\n",
    "        output_dir (str): Directorio para guardar los gráficos.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Cargar imagen de consulta\n",
    "    query_image = np.array(Image.open(query_image_path).convert(\"RGB\"))\n",
    "\n",
    "    # Cargar imágenes de vecinos\n",
    "    neighbor_images = [np.array(Image.open(path).convert(\"RGB\")) for path in neighbor_image_paths]\n",
    "\n",
    "    # Iterar sobre cada objeto de consulta\n",
    "    for obj_idx, query_mask in enumerate(query_masks):\n",
    "        fig, axes = plt.subplots(1, len(neighbor_images) + 1, figsize=(15, 5))\n",
    "\n",
    "        # Color único para el objeto actual\n",
    "        color = np.random.random(3)\n",
    "\n",
    "        # Graficar la imagen de consulta con el objeto actual\n",
    "        axes[0].imshow(query_image)\n",
    "        axes[0].set_title(f\"Consulta - Objeto Q{obj_idx}\")\n",
    "        axes[0].axis(\"off\")\n",
    "        show_mask(query_mask[\"segmentation\"], axes[0], random_color=False)\n",
    "        axes[0].text(query_mask[\"segmentation\"].shape[1] // 2, query_mask[\"segmentation\"].shape[0] // 2, f\"Q{obj_idx}\", color=color, fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "        # Graficar las imágenes de vecinos con los objetos emparejados o no emparejados\n",
    "        for neighbor_idx, (neighbor_image, neighbor_masks) in enumerate(zip(neighbor_images, neighbor_masks_list)):\n",
    "            axes[neighbor_idx + 1].imshow(neighbor_image)\n",
    "            axes[neighbor_idx + 1].axis(\"off\")\n",
    "\n",
    "            # Título dependiendo de si es matched o unmatched\n",
    "            if any(match[0] == neighbor_idx for match in matched_indices[obj_idx]):\n",
    "                axes[neighbor_idx + 1].set_title(f\"Vecino {neighbor_idx + 1} - Matched\")\n",
    "                for match in matched_indices[obj_idx]:\n",
    "                    if match[0] == neighbor_idx:\n",
    "                        neighbor_mask = neighbor_masks[match[1]]\n",
    "                        show_mask(neighbor_mask[\"segmentation\"], axes[neighbor_idx + 1], random_color=False)\n",
    "                        axes[neighbor_idx + 1].text(neighbor_mask[\"segmentation\"].shape[1] // 2, neighbor_mask[\"segmentation\"].shape[0] // 2, f\"N{match[1]}\", color=color, fontsize=12, fontweight=\"bold\")\n",
    "            else:\n",
    "                axes[neighbor_idx + 1].set_title(f\"Vecino {neighbor_idx + 1} - Unmatched\")\n",
    "                for unmatch in unmatched_indices[obj_idx]:\n",
    "                    if unmatch[0] == neighbor_idx:\n",
    "                        neighbor_mask = neighbor_masks[unmatch[1]]\n",
    "                        show_mask(neighbor_mask[\"segmentation\"], axes[neighbor_idx + 1], random_color=False)\n",
    "                        axes[neighbor_idx + 1].text(neighbor_mask[\"segmentation\"].shape[1] // 2, neighbor_mask[\"segmentation\"].shape[0] // 2, f\"N{unmatch[1]}\", color=color, fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "        # Guardar el gráfico\n",
    "        output_path = os.path.join(output_dir, f\"object_Q{obj_idx}_matched_unmatched.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path)\n",
    "        print(f\"✅ Gráfico guardado en: {output_path}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "# --- Llamada a la función ---\n",
    "output_dir = os.path.join(PLOT_SAVE_ROOT_DIR, \"matched_unmatched_plots\")\n",
    "plot_matched_and_unmatched_objects(\n",
    "    query_image_path=query_image_path,\n",
    "    neighbor_image_paths=rutas_imagenes_similares,\n",
    "    query_masks=masks_data_query_image,\n",
    "    neighbor_masks_list=similar_masks_raw_list,\n",
    "    matched_indices=all_matched_ref_indices_by_query_obj,\n",
    "    unmatched_indices=all_closest_unmatched_ref_indices_by_query_obj,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "## AMM\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_mahalanobis_map_single(query_fmap, ref_fmaps, regularization=1e-5):\n",
    "    \"\"\"\n",
    "    Calcula el mapa de distancia de Mahalanobis por píxel entre un objeto de consulta\n",
    "    y k objetos de referencia emparejados.\n",
    "\n",
    "    Args:\n",
    "        query_fmap (Tensor): (C, H, W) feature map del objeto de consulta.\n",
    "        ref_fmaps (List[Tensor]): lista de k tensores (C, H, W) de objetos emparejados.\n",
    "        regularization (float): término epsilon * I para la inversa numéricamente estable.\n",
    "\n",
    "    Returns:\n",
    "        maha_map (Tensor): (H, W) mapa escalar con distancia de Mahalanobis por píxel.\n",
    "    \"\"\"\n",
    "    device = query_fmap.device\n",
    "    k = len(ref_fmaps)\n",
    "    C, H, W = query_fmap.shape\n",
    "    \n",
    "    if k < 2: # Necesitamos al menos 2 referencias para calcular covarianza\n",
    "        return torch.zeros(H, W, device=device)\n",
    "\n",
    "    # Stack: (k, C, H, W)\n",
    "    ref_stack = torch.stack(ref_fmaps, dim=0)  # (k, C, H, W)\n",
    "\n",
    "    maha_map = torch.zeros(H, W, device=device)\n",
    "\n",
    "    for x in range(H):\n",
    "        for y in range(W):\n",
    "            vectors = ref_stack[:, :, x, y]         # (k, C)\n",
    "            mu = vectors.mean(dim=0)                # (C,)\n",
    "            delta = vectors - mu                    # (k, C)\n",
    "            cov = delta.T @ delta / (k - 1)         # (C, C) \n",
    "            cov += regularization * torch.eye(C, device=device)\n",
    "\n",
    "            try:\n",
    "                cov_inv = torch.linalg.inv(cov)     # (C, C)\n",
    "            except RuntimeError:\n",
    "                maha_map[x, y] = 0.0\n",
    "                continue\n",
    "\n",
    "            v_query = query_fmap[:, x, y]           # (C,)\n",
    "            diff = (v_query - mu).unsqueeze(0)      # (1, C)\n",
    "\n",
    "            # Mahalanobis distance squared\n",
    "            maha_val_squared = (diff @ cov_inv @ diff.T).item()\n",
    "            # Aplicar la raíz cuadrada para obtener la distancia\n",
    "            maha_val = torch.sqrt(torch.tensor(maha_val_squared, device=device)).item() # Asegurarse de que sea un tensor para sqrt\n",
    "            maha_map[x, y] = maha_val\n",
    "\n",
    "    return maha_map\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_matching_score_map(\n",
    "    fobj_q,\n",
    "    all_matched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list,\n",
    "    regularization=1e-5,\n",
    "    plot_save_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calcula los mapas de distancia de Mahalanobis para objetos de consulta\n",
    "    que tienen referencias emparejadas. Los mapas se normalizan a [0,1].\n",
    "    \"\"\"\n",
    "    matching_maha_maps = []\n",
    "    all_raw_maha_values = [] \n",
    "    print(\"\\n--- Calculando Matching Score Maps (Normalizados) ---\")\n",
    "\n",
    "    for query_idx in range(len(fobj_q)):\n",
    "        query_fmap = fobj_q[query_idx] # (C, H, W)\n",
    "\n",
    "        matched_ref_fmaps_list = []\n",
    "        for neighbor_idx, ref_idx in all_matched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "            ref_fmap = all_fobj_r_list[neighbor_idx][ref_idx] # (C, H, W)\n",
    "            matched_ref_fmaps_list.append(ref_fmap)\n",
    "\n",
    "        if len(matched_ref_fmaps_list) >= 2:\n",
    "            maha_map = compute_mahalanobis_map_single(\n",
    "                query_fmap=query_fmap,\n",
    "                ref_fmaps=matched_ref_fmaps_list,\n",
    "                regularization=regularization\n",
    "            )\n",
    "            \n",
    "            # Agrega los valores brutos a la lista global para min/max\n",
    "            all_raw_maha_values.append(maha_map.flatten().cpu()) \n",
    "            \n",
    "            # --- NUEVA Lógica de Normalización ---\n",
    "            # Normalizar la distancia Mahalanobis a [0, 1].\n",
    "            # Esto hará que los valores más altos (mayor anomalía) brillen más.\n",
    "            if maha_map.max() > 1e-8: # Evitar división por cero para mapas planos\n",
    "                normalized_maha = (maha_map - maha_map.min()) / (maha_map.max() - maha_map.min() + 1e-8)\n",
    "            else:\n",
    "                normalized_maha = torch.zeros_like(maha_map) # Si es plano, sigue siendo cero\n",
    "\n",
    "            print(f\"✅ Objeto de consulta {query_idx} emparejado con {len(matched_ref_fmaps_list)} referencias.\")\n",
    "        else:\n",
    "            # Si no hay suficientes pares coincidentes, el mapa es cero\n",
    "            normalized_maha = torch.zeros_like(query_fmap[0])\n",
    "            print(f\"ℹ️ Objeto de consulta {query_idx} NO tiene suficientes referencias emparejadas para un Matching Score.\")\n",
    "        \n",
    "        matching_maha_maps.append(normalized_maha.cpu()) # Agrega el mapa normalizado\n",
    "\n",
    "       # Visualización (opcional)\n",
    "        if plot_save_dir:\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            plt.imshow(normalized_maha.cpu().numpy(), cmap=\"hot\") # Usa el mapa normalizado\n",
    "            plt.title(f\"Matching Score Map (Normalized) - Obj {query_idx}\") # Cambia el título\n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Normalized Mahalanobis Distance\") # Cambia la etiqueta de la barra de color\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"matching_score_obj_{query_idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "\n",
    "    # Calcular el min y max global de TODOS los valores brutos recolectados\n",
    "    global_min_maha = 0.0\n",
    "    global_max_maha = 1.0 # Valores por defecto si no hay ningún matched válido\n",
    "\n",
    "    if all_raw_maha_values:\n",
    "        combined_raw_values = torch.cat(all_raw_maha_values)\n",
    "        global_min_maha = combined_raw_values.min().item()\n",
    "        global_max_maha = combined_raw_values.max().item()\n",
    "        # Asegurar que el rango no sea cero para evitar división por cero más tarde\n",
    "        if global_max_maha <= global_min_maha:\n",
    "            global_max_maha = global_min_maha + 1e-8 \n",
    "\n",
    "    print(f\"Rango global de Mahalanobis RAW para 'Matched': Min={global_min_maha:.4f}, Max={global_max_maha:.4f}\")\n",
    "\n",
    "    return matching_maha_maps, (global_min_maha, global_max_maha) # Devolvemos la tupla con min/max\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_unmatched_score_map(\n",
    "    fobj_q,\n",
    "    all_closest_unmatched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list,\n",
    "    regularization=1e-5,\n",
    "    plot_save_dir=None,\n",
    "    all_matched_ref_indices_by_query_obj=None,\n",
    "    # --- RECIBE LA TUPLA CON MIN/MAX ---\n",
    "    matched_maha_range_global=(0.0, 1.0) \n",
    "):\n",
    "    \"\"\"\n",
    "    Calcula los mapas de distancia de Mahalanobis para objetos de consulta\n",
    "    que NO tienen referencias emparejadas. Los valores se normalizan primero\n",
    "    usando el rango global de los mapas 'matched', y luego a [0,1] e invierten para mostrar similitud.\n",
    "    \"\"\"\n",
    "    print(f\"matched_maha_range_global recibidos: {matched_maha_range_global}\")\n",
    "    \n",
    "    unmatched_maha_maps = []\n",
    "    print(\"\\n--- Calculando Unmatched Score Maps (Normalizados a rango Matched e Invertidos para Similitud) ---\")\n",
    "\n",
    "    min_matched_maha_global, max_matched_maha_global = matched_maha_range_global\n",
    "\n",
    "    # Ya tenemos la validación del rango hecha en compute_matching_score_map,\n",
    "    # pero podemos añadir una pequeña comprobación aquí por seguridad.\n",
    "    if max_matched_maha_global <= min_matched_maha_global:\n",
    "        # Esto debería haber sido ajustado ya, pero por si acaso.\n",
    "        max_matched_maha_global = min_matched_maha_global + 1e-8 \n",
    "\n",
    "    for query_idx in range(len(fobj_q)):\n",
    "        query_fmap = fobj_q[query_idx] \n",
    "\n",
    "        matched_refs = all_matched_ref_indices_by_query_obj.get(query_idx, []) if all_matched_ref_indices_by_query_obj else []\n",
    "        \n",
    "        if len(matched_refs) >= 2: \n",
    "            unmatched_maha_maps.append(torch.zeros_like(query_fmap[0]).cpu())\n",
    "            print(f\"✅ Objeto de consulta {query_idx} ya emparejado. Unmatched map puesto a cero y saltado.\")\n",
    "            continue \n",
    "\n",
    "        closest_ref_fmaps = []\n",
    "        for neighbor_idx, ref_idx in all_closest_unmatched_ref_indices_by_query_obj.get(query_idx, []):\n",
    "            ref_fmap_closest = all_fobj_r_list[neighbor_idx][ref_idx] \n",
    "            closest_ref_fmaps.append(ref_fmap_closest)\n",
    "\n",
    "        if len(closest_ref_fmaps) >= 2:\n",
    "            maha_map_raw = compute_mahalanobis_map_single( # Obtén el mapa de Mahalanobis bruto\n",
    "                query_fmap=query_fmap,\n",
    "                ref_fmaps=closest_ref_fmaps,\n",
    "                regularization=regularization\n",
    "            )\n",
    "            \n",
    "            # --- Lógica Clave: Normalización usando el rango global de Matched ---\n",
    "            # Primero, clip los valores al rango global de los matched.\n",
    "            # Esto evita que valores extremos en unmatched distorsionen la escala.\n",
    "            clipped_maha_map = torch.clamp(maha_map_raw, min=min_matched_maha_global, max=max_matched_maha_global)\n",
    "            print(f\"Máximo valor de clipped_maha_map: {clipped_maha_map.max().item()}\")\n",
    "            print(f\"Mínimo valor de clipped_maha_map: {clipped_maha_map.min().item()}\")\n",
    "            # Luego, normaliza estos valores clipados al rango [0,1] usando el rango GLOBAL de los matched.\n",
    "            # Esto alinea la escala de \"anomalía\" entre matched y unmatched.\n",
    "            normalized_by_matched_range = (clipped_maha_map - min_matched_maha_global) / (max_matched_maha_global - min_matched_maha_global + 1e-8)\n",
    "            print(f\"Máximo valor de normalized_by_matched_range: {normalized_by_matched_range.max().item()}\")\n",
    "            print(f\"Mínimo valor de normalized_by_matched_range: {normalized_by_matched_range.min().item()}\")\n",
    "            # Finalmente, invierte para la visualización de \"similitud\"\n",
    "            maha_map_for_display = 1.0 - normalized_by_matched_range \n",
    "\n",
    "            print(f\"🟡 Objeto de consulta {query_idx} NO emparejado, Mahalanobis (normalizado a rango Matched e invertido) con {len(closest_ref_fmaps)} 'casi-pares'.\")\n",
    "        else:\n",
    "            maha_map_for_display = torch.zeros_like(query_fmap[0])\n",
    "            print(f\"⚠️ Objeto de consulta {query_idx} no emparejado y sin suficientes 'casi-pares', se pone mapa vacío.\")\n",
    "        \n",
    "        unmatched_maha_maps.append(maha_map_for_display.cpu()) \n",
    "\n",
    "        # Visualización (opcional)\n",
    "        if plot_save_dir:\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            plt.imshow(maha_map_for_display.cpu().numpy(), cmap=\"hot\") \n",
    "            plt.title(f\"Unmatched Similarity Map (Scaled to Matched Range) - Obj {query_idx}\") \n",
    "            plt.axis(\"off\")\n",
    "            plt.colorbar(label=\"Inverse Normalized Mahalanobis Score (Similarity)\") \n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(plot_save_dir, f\"unmatched_similarity_scaled_to_matched_obj_{query_idx}.png\") \n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "\n",
    "    return unmatched_maha_maps\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def build_aggregated_score_map(individual_score_maps_list, final_size=(1024, 1024), title_prefix=\"Global Score Map\", plot_save_dir=None, filename_prefix=\"global_score_map\"):\n",
    "    \"\"\"\n",
    "    Construye un mapa de puntuación agregado (global) a partir de una lista de mapas individuales.\n",
    "\n",
    "    Args:\n",
    "        individual_score_maps_list (List[Tensor]): Lista de tensores (H', W') de mapas de puntuación individuales.\n",
    "                                                   Estos ya deberían estar en CPU.\n",
    "        final_size (tuple): Tamaño final deseado para el mapa agregado (H, W).\n",
    "        title_prefix (str): Prefijo para el título del gráfico.\n",
    "        plot_save_dir (str, optional): Directorio para guardar las visualizaciones.\n",
    "        filename_prefix (str): Prefijo para el nombre del archivo guardado.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Tensor (H, W) con el mapa de calor total de puntuación.\n",
    "    \"\"\"\n",
    "    H_out, W_out = final_size\n",
    "    aggregated_score_map = torch.zeros((H_out, W_out), device='cpu')\n",
    "\n",
    "    print(f\"\\n--- Construyendo el {title_prefix} ---\")\n",
    "    if not individual_score_maps_list:\n",
    "        print(f\"No hay mapas individuales para {title_prefix}. Retornando un mapa vacío.\")\n",
    "        return aggregated_score_map\n",
    "\n",
    "    for i, score_map in enumerate(individual_score_maps_list):\n",
    "        if score_map.dim() == 2:\n",
    "            score_map_tensor = score_map.unsqueeze(0).unsqueeze(0) # (1,1,H',W')\n",
    "        else:\n",
    "            print(f\"Advertencia: El mapa de puntuación {i} tiene dimensiones inesperadas: {score_map.shape}. Saltando.\")\n",
    "            continue\n",
    "\n",
    "        score_resized = F.interpolate(\n",
    "            score_map_tensor,\n",
    "            size=(H_out, W_out),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        ).squeeze()\n",
    "\n",
    "        aggregated_score_map += score_resized\n",
    "\n",
    "    print(f\"Dimensiones del {title_prefix} final: {aggregated_score_map.shape}\")\n",
    "\n",
    "    if plot_save_dir:\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.imshow(aggregated_score_map.numpy(), cmap=\"hot\")\n",
    "        plt.title(title_prefix)\n",
    "        plt.axis(\"off\")\n",
    "        plt.colorbar(label=\"Score Acumulado\")\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(plot_save_dir, f\"{filename_prefix}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"✅ Visualización del {title_prefix} guardada en: {save_path}\")\n",
    "\n",
    "    return aggregated_score_map\n",
    "\n",
    "\n",
    "def overlay_anomaly_map_on_image(image_rgb_path, anomaly_map, alpha=0.7, cmap='magma', plot_save_dir=None, filename_suffix=\"overlay\"):\n",
    "    \"\"\"\n",
    "    Superpone el mapa de anomalía sobre la imagen original RGB como un heatmap.\n",
    "\n",
    "    Args:\n",
    "        image_rgb_path (str): Ruta a la imagen original RGB.\n",
    "        anomaly_map (Tensor o ndarray): mapa de anomalía (H, W) — debe estar reescalado a 1024×1024.\n",
    "        alpha (float): transparencia del mapa (0=solo imagen, 1=solo heatmap)\n",
    "        cmap (str): mapa de color matplotlib a usar (\"hot\", \"jet\", etc.)\n",
    "        plot_save_dir (str, optional): Directorio para guardar la visualización.\n",
    "        filename_suffix (str): Sufijo para el nombre del archivo guardado.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Superponiendo el mapa de anomalía final sobre la imagen original ---\")\n",
    "    try:\n",
    "        image_original_loaded = Image.open(image_rgb_path).convert(\"RGB\")\n",
    "        image_np = np.array(image_original_loaded)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró la imagen en {image_rgb_path}. No se puede superponer.\")\n",
    "        return\n",
    "\n",
    "    if isinstance(anomaly_map, torch.Tensor):\n",
    "        anomaly_np = anomaly_map.cpu().numpy()\n",
    "    else:\n",
    "        anomaly_np = anomaly_map\n",
    "\n",
    "    # Normalizamos el mapa a [0, 1] para visualización\n",
    "    # Añadimos un pequeño epsilon para evitar división por cero si max == min\n",
    "    anomaly_min = anomaly_np.min()\n",
    "    anomaly_max = anomaly_np.max()\n",
    "    if (anomaly_max - anomaly_min) < 1e-8: # Si todos los valores son iguales\n",
    "        anomaly_norm = np.zeros_like(anomaly_np)\n",
    "    else:\n",
    "        anomaly_norm = (anomaly_np - anomaly_min) / (anomaly_max - anomaly_min)\n",
    "\n",
    "    # Redimensionamos si las resoluciones no coinciden con la imagen original\n",
    "    if anomaly_norm.shape[:2] != image_np.shape[:2]:\n",
    "        anomaly_norm = np.array(Image.fromarray(anomaly_norm).resize(\n",
    "            (image_np.shape[1], image_np.shape[0]), resample=Image.BILINEAR\n",
    "        ))\n",
    "\n",
    "    # Visualización\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image_np)\n",
    "    plt.imshow(anomaly_norm, cmap=cmap, alpha=alpha)\n",
    "    plt.title(\"Anomaly Heatmap Overlay\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if plot_save_dir:\n",
    "        save_path = os.path.join(plot_save_dir, f\"{filename_suffix}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"✅ Visualización superpuesta guardada en: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculando Matching Score Maps (Normalizados) ---\n",
      "✅ Objeto de consulta 0 emparejado con 3 referencias.\n",
      "✅ Objeto de consulta 1 emparejado con 3 referencias.\n",
      "ℹ️ Objeto de consulta 2 NO tiene suficientes referencias emparejadas para un Matching Score.\n",
      "ℹ️ Objeto de consulta 3 NO tiene suficientes referencias emparejadas para un Matching Score.\n",
      "✅ Objeto de consulta 4 emparejado con 3 referencias.\n",
      "ℹ️ Objeto de consulta 5 NO tiene suficientes referencias emparejadas para un Matching Score.\n",
      "Rango global de Mahalanobis RAW para 'Matched': Min=0.0000, Max=6921.1719\n"
     ]
    }
   ],
   "source": [
    "# --- Ejecución del Proceso ---\n",
    "\n",
    "# --- 1. Calcular Matching Score Maps y obtener el rango global ---\n",
    "all_matching_score_maps, matched_maha_range_global = compute_matching_score_map(\n",
    "    fobj_q=fobj_q,\n",
    "    all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list=all_fobj_r_list,\n",
    "    regularization=1e-5,\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_maha_range_global recibidos: (0.0, 6921.171875)\n",
      "\n",
      "--- Calculando Unmatched Score Maps (Normalizados a rango Matched e Invertidos para Similitud) ---\n",
      "✅ Objeto de consulta 0 ya emparejado. Unmatched map puesto a cero y saltado.\n",
      "✅ Objeto de consulta 1 ya emparejado. Unmatched map puesto a cero y saltado.\n",
      "Máximo valor de clipped_maha_map: 6921.171875\n",
      "Mínimo valor de clipped_maha_map: 0.0\n",
      "Máximo valor de normalized_by_matched_range: 1.0\n",
      "Mínimo valor de normalized_by_matched_range: 0.0\n",
      "🟡 Objeto de consulta 2 NO emparejado, Mahalanobis (normalizado a rango Matched e invertido) con 3 'casi-pares'.\n",
      "Máximo valor de clipped_maha_map: 6921.171875\n",
      "Mínimo valor de clipped_maha_map: 0.0\n",
      "Máximo valor de normalized_by_matched_range: 1.0\n",
      "Mínimo valor de normalized_by_matched_range: 0.0\n",
      "🟡 Objeto de consulta 3 NO emparejado, Mahalanobis (normalizado a rango Matched e invertido) con 3 'casi-pares'.\n",
      "✅ Objeto de consulta 4 ya emparejado. Unmatched map puesto a cero y saltado.\n",
      "Máximo valor de clipped_maha_map: 6921.171875\n",
      "Mínimo valor de clipped_maha_map: 0.0\n",
      "Máximo valor de normalized_by_matched_range: 1.0\n",
      "Mínimo valor de normalized_by_matched_range: 0.0\n",
      "🟡 Objeto de consulta 5 NO emparejado, Mahalanobis (normalizado a rango Matched e invertido) con 3 'casi-pares'.\n"
     ]
    }
   ],
   "source": [
    "# matched_maha_range_global ahora es una tupla (min_value, max_value)\n",
    "\n",
    "# --- 2. Calcular Unmatched Score Maps (usando el rango global de Matched) ---\n",
    "all_unmatched_score_maps = compute_unmatched_score_map(\n",
    "    fobj_q=fobj_q,\n",
    "    all_closest_unmatched_ref_indices_by_query_obj=all_closest_unmatched_ref_indices_by_query_obj,\n",
    "    all_fobj_r_list=all_fobj_r_list,\n",
    "    regularization=1e-5,\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    all_matched_ref_indices_by_query_obj=all_matched_ref_indices_by_query_obj,\n",
    "    matched_maha_range_global=matched_maha_range_global # Pasar la tupla aquí\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Construyendo el Global Matched Score Map ---\n",
      "Dimensiones del Global Matched Score Map final: torch.Size([1024, 1024])\n",
      "✅ Visualización del Global Matched Score Map guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/global_matched_score_map.png\n"
     ]
    }
   ],
   "source": [
    "# 3. Construir el Global Matched Score Map\n",
    "# Obtener las dimensiones de la imagen original\n",
    "image_original = Image.open(query_image_path)\n",
    "H, W = image_original.size\n",
    "\n",
    "# Construir el Global Matched Score Map\n",
    "global_matched_score_map = build_aggregated_score_map(\n",
    "    individual_score_maps_list=all_matching_score_maps,\n",
    "    final_size=(H, W),\n",
    "    title_prefix=\"Global Matched Score Map\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_prefix=\"global_matched_score_map\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Construyendo el Global Unmatched Score Map ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del Global Unmatched Score Map final: torch.Size([1024, 1024])\n",
      "✅ Visualización del Global Unmatched Score Map guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/global_unmatched_score_map.png\n"
     ]
    }
   ],
   "source": [
    "# 4. Construir el Global Unmatched Score Map\n",
    "global_unmatched_score_map = build_aggregated_score_map(\n",
    "    individual_score_maps_list=all_unmatched_score_maps,\n",
    "    final_size=(H, W),\n",
    "    title_prefix=\"Global Unmatched Score Map\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_prefix=\"global_unmatched_score_map\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Proceso completado. Revisa la carpeta 'plots_anomalia' para las visualizaciones. ---\n"
     ]
    }
   ],
   "source": [
    "# 5. Combinar ambos tipos de mapas individuales para el Mapa Global Final (Total)\n",
    "# Asegúrate de que las listas tengan el mismo número de elementos y en el mismo orden (por query_idx)\n",
    "combined_individual_score_maps = []\n",
    "num_queries = len(fobj_q)\n",
    "for i in range(num_queries):\n",
    "    # Suma elemento a elemento los mapas de matching y unmatched para cada query\n",
    "    # Si alguna lista es más corta, se asume que los elementos restantes son cero\n",
    "    matched_map_for_query = all_matching_score_maps[i] if i < len(all_matching_score_maps) else torch.zeros((H, W), device='cpu')\n",
    "    unmatched_map_for_query = all_unmatched_score_maps[i] if i < len(all_unmatched_score_maps) else torch.zeros((H, W), device='cpu')\n",
    "    \n",
    "    combined_map_for_query_i = matched_map_for_query + unmatched_map_for_query\n",
    "    combined_individual_score_maps.append(combined_map_for_query_i)\n",
    "\n",
    "\n",
    "print(\"\\n--- Proceso completado. Revisa la carpeta 'plots_anomalia' para las visualizaciones. ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Construyendo el Global Total Anomaly Score Map ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del Global Total Anomaly Score Map final: torch.Size([1024, 1024])\n",
      "✅ Visualización del Global Total Anomaly Score Map guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/global_total_anomaly_score_map.png\n"
     ]
    }
   ],
   "source": [
    "# 6. Construir el Global Total Anomaly Score Map (el que combina ambos)\n",
    "global_total_anomaly_score_map = build_aggregated_score_map(\n",
    "    individual_score_maps_list=combined_individual_score_maps,\n",
    "    final_size=(1024, 1024),\n",
    "    title_prefix=\"Global Total Anomaly Score Map\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_prefix=\"global_total_anomaly_score_map\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Superponiendo el mapa de anomalía final sobre la imagen original ---\n",
      "✅ Visualización superpuesta guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/global_matched_overlay.png\n"
     ]
    }
   ],
   "source": [
    "# 7. Superponer los mapas globales en la imagen original\n",
    "overlay_anomaly_map_on_image(\n",
    "    image_rgb_path=query_image_path,\n",
    "    anomaly_map=global_matched_score_map,\n",
    "    alpha=0.7,\n",
    "    cmap=\"magma\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_suffix=\"global_matched_overlay\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Superponiendo el mapa de anomalía final sobre la imagen original ---\n",
      "✅ Visualización superpuesta guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/global_unmatched_overlay.png\n",
      "\n",
      "--- Superponiendo el mapa de anomalía final sobre la imagen original ---\n",
      "✅ Visualización superpuesta guardada en: /home/imercatoma/FeatUp/plots_single_3/cut_001/global_total_anomaly_overlay.png\n",
      "\n",
      "--- Proceso de generación y visualización de todos los mapas globales completado. ---\n",
      "Revisa la carpeta '/home/imercatoma/FeatUp/plots_single_3/cut_001' para las visualizaciones.\n"
     ]
    }
   ],
   "source": [
    "overlay_anomaly_map_on_image(\n",
    "    image_rgb_path=query_image_path,\n",
    "    anomaly_map=global_unmatched_score_map,\n",
    "    alpha=0.7,\n",
    "    cmap=\"magma\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_suffix=\"global_unmatched_overlay\"\n",
    ")\n",
    "\n",
    "overlay_anomaly_map_on_image(\n",
    "    image_rgb_path=query_image_path,\n",
    "    anomaly_map=global_total_anomaly_score_map,\n",
    "    alpha=0.7,\n",
    "    cmap=\"magma\",\n",
    "    plot_save_dir=PLOT_SAVE_ROOT_DIR,\n",
    "    filename_suffix=\"global_total_anomaly_overlay\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Proceso de generación y visualización de todos los mapas globales completado. ---\")\n",
    "print(f\"Revisa la carpeta '{PLOT_SAVE_ROOT_DIR}' para las visualizaciones.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_featup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
